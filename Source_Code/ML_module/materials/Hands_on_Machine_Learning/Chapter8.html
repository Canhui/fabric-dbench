<!DOCTYPE html>
<!-- saved from url=(0091)https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html -->
<html class=" js flexbox flexboxlegacy no-touch websqldatabase indexeddb history csscolumns csstransforms localstorage sessionstorage applicationcache svg inlinesvg zoom" lang="en" prefix="og: http://ogp.me/ns/# og:book: http://ogp.me/ns/book# og:video: http://ogp.me/ns/video#" itemscope="" itemtype="http://schema.org/Book http://schema.org/ItemPage" data-login-url="/accounts/login/" data-offline-url="/" data-url="/library/view/hands-on-machine-learning/9781492032632/part01.html" data-csrf-cookie="csrfsafari" data-highlight-privacy="" data-user-id="4626953" data-user-uuid="d59baa21-c0cd-4fcf-9c68-a2b8d4f52a79" data-username="17481074" data-account-type="B2B" data-activated-trial-date="" data-archive="9781492032632" data-publishers="O&#39;Reilly Media, Inc." data-htmlfile-name="part01.html" data-epub-title="Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition" data-debug="0" data-testing="0" style=""><!--<![endif]--><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="author" content="Safari Books Online"><meta name="format-detection" content="telephone=no"><meta http-equiv="cleartype" content="on"><meta name="HandheldFriendly" content="True"><meta name="MobileOptimized" content="320"><meta name="apple-itunes-app" content="app-id=881697395, app-argument=safaridetail://9781492032632"><meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, maximum-scale=1.0"><meta property="twitter:account_id" content="4503599627559754"><script type="text/javascript" async="" src="./Chapter8_files/cool-2.1.15.min.js.download"></script><script type="text/javascript" src="./Chapter8_files/510f1a6865"></script><script id="twitter-wjs" src="./Chapter8_files/widgets.js.download"></script><script src="./Chapter8_files/nr-1130.min.js.download"></script><script type="text/javascript" async="" src="./Chapter8_files/2508.js.download"></script><script async="" src="./Chapter8_files/fbevents.js.download"></script><script type="text/javascript" async="" src="./Chapter8_files/f.txt"></script><script type="text/javascript" async="" src="./Chapter8_files/f.txt"></script><script type="text/javascript" async="" src="./Chapter8_files/f.txt"></script><script type="text/javascript" async="" src="./Chapter8_files/analytics.js.download"></script><script type="text/javascript" async="" src="./Chapter8_files/ec.js.download"></script><script type="text/javascript" async="" src="./Chapter8_files/bat.js.download"></script><script type="text/javascript" async="" src="./Chapter8_files/f.txt"></script><script type="text/javascript" async="" src="./Chapter8_files/insight.min.js.download"></script><script type="text/javascript" async="" src="./Chapter8_files/f.txt"></script><script type="text/javascript" async="" src="./Chapter8_files/linkid.js.download"></script><script async="" src="./Chapter8_files/gtm.js.download"></script><script async="" src="./Chapter8_files/analytics.js.download"></script><script type="text/javascript">window.NREUM||(NREUM={}),__nr_require=function(e,n,t){function r(t){if(!n[t]){var o=n[t]={exports:{}};e[t][0].call(o.exports,function(n){var o=e[t][1][n];return r(o||n)},o,o.exports)}return n[t].exports}if("function"==typeof __nr_require)return __nr_require;for(var o=0;o<t.length;o++)r(t[o]);return r}({1:[function(e,n,t){function r(){}function o(e,n,t){return function(){return i(e,[c.now()].concat(u(arguments)),n?null:this,t),n?void 0:this}}var i=e("handle"),a=e(3),u=e(4),f=e("ee").get("tracer"),c=e("loader"),s=NREUM;"undefined"==typeof window.newrelic&&(newrelic=s);var p=["setPageViewName","setCustomAttribute","setErrorHandler","finished","addToTrace","inlineHit","addRelease"],d="api-",l=d+"ixn-";a(p,function(e,n){s[n]=o(d+n,!0,"api")}),s.addPageAction=o(d+"addPageAction",!0),s.setCurrentRouteName=o(d+"routeName",!0),n.exports=newrelic,s.interaction=function(){return(new r).get()};var m=r.prototype={createTracer:function(e,n){var t={},r=this,o="function"==typeof n;return i(l+"tracer",[c.now(),e,t],r),function(){if(f.emit((o?"":"no-")+"fn-start",[c.now(),r,o],t),o)try{return n.apply(this,arguments)}catch(e){throw f.emit("fn-err",[arguments,this,e],t),e}finally{f.emit("fn-end",[c.now()],t)}}}};a("actionText,setName,setAttribute,save,ignore,onEnd,getContext,end,get".split(","),function(e,n){m[n]=o(l+n)}),newrelic.noticeError=function(e,n){"string"==typeof e&&(e=new Error(e)),i("err",[e,c.now(),!1,n])}},{}],2:[function(e,n,t){function r(e,n){if(!o)return!1;if(e!==o)return!1;if(!n)return!0;if(!i)return!1;for(var t=i.split("."),r=n.split("."),a=0;a<r.length;a++)if(r[a]!==t[a])return!1;return!0}var o=null,i=null,a=/Version\/(\S+)\s+Safari/;if(navigator.userAgent){var u=navigator.userAgent,f=u.match(a);f&&u.indexOf("Chrome")===-1&&u.indexOf("Chromium")===-1&&(o="Safari",i=f[1])}n.exports={agent:o,version:i,match:r}},{}],3:[function(e,n,t){function r(e,n){var t=[],r="",i=0;for(r in e)o.call(e,r)&&(t[i]=n(r,e[r]),i+=1);return t}var o=Object.prototype.hasOwnProperty;n.exports=r},{}],4:[function(e,n,t){function r(e,n,t){n||(n=0),"undefined"==typeof t&&(t=e?e.length:0);for(var r=-1,o=t-n||0,i=Array(o<0?0:o);++r<o;)i[r]=e[n+r];return i}n.exports=r},{}],5:[function(e,n,t){n.exports={exists:"undefined"!=typeof window.performance&&window.performance.timing&&"undefined"!=typeof window.performance.timing.navigationStart}},{}],ee:[function(e,n,t){function r(){}function o(e){function n(e){return e&&e instanceof r?e:e?f(e,u,i):i()}function t(t,r,o,i){if(!d.aborted||i){e&&e(t,r,o);for(var a=n(o),u=v(t),f=u.length,c=0;c<f;c++)u[c].apply(a,r);var p=s[y[t]];return p&&p.push([b,t,r,a]),a}}function l(e,n){h[e]=v(e).concat(n)}function m(e,n){var t=h[e];if(t)for(var r=0;r<t.length;r++)t[r]===n&&t.splice(r,1)}function v(e){return h[e]||[]}function g(e){return p[e]=p[e]||o(t)}function w(e,n){c(e,function(e,t){n=n||"feature",y[t]=n,n in s||(s[n]=[])})}var h={},y={},b={on:l,addEventListener:l,removeEventListener:m,emit:t,get:g,listeners:v,context:n,buffer:w,abort:a,aborted:!1};return b}function i(){return new r}function a(){(s.api||s.feature)&&(d.aborted=!0,s=d.backlog={})}var u="nr@context",f=e("gos"),c=e(3),s={},p={},d=n.exports=o();d.backlog=s},{}],gos:[function(e,n,t){function r(e,n,t){if(o.call(e,n))return e[n];var r=t();if(Object.defineProperty&&Object.keys)try{return Object.defineProperty(e,n,{value:r,writable:!0,enumerable:!1}),r}catch(i){}return e[n]=r,r}var o=Object.prototype.hasOwnProperty;n.exports=r},{}],handle:[function(e,n,t){function r(e,n,t,r){o.buffer([e],r),o.emit(e,n,t)}var o=e("ee").get("handle");n.exports=r,r.ee=o},{}],id:[function(e,n,t){function r(e){var n=typeof e;return!e||"object"!==n&&"function"!==n?-1:e===window?0:a(e,i,function(){return o++})}var o=1,i="nr@id",a=e("gos");n.exports=r},{}],loader:[function(e,n,t){function r(){if(!E++){var e=x.info=NREUM.info,n=l.getElementsByTagName("script")[0];if(setTimeout(s.abort,3e4),!(e&&e.licenseKey&&e.applicationID&&n))return s.abort();c(y,function(n,t){e[n]||(e[n]=t)}),f("mark",["onload",a()+x.offset],null,"api");var t=l.createElement("script");t.src="https://"+e.agent,n.parentNode.insertBefore(t,n)}}function o(){"complete"===l.readyState&&i()}function i(){f("mark",["domContent",a()+x.offset],null,"api")}function a(){return O.exists&&performance.now?Math.round(performance.now()):(u=Math.max((new Date).getTime(),u))-x.offset}var u=(new Date).getTime(),f=e("handle"),c=e(3),s=e("ee"),p=e(2),d=window,l=d.document,m="addEventListener",v="attachEvent",g=d.XMLHttpRequest,w=g&&g.prototype;NREUM.o={ST:setTimeout,SI:d.setImmediate,CT:clearTimeout,XHR:g,REQ:d.Request,EV:d.Event,PR:d.Promise,MO:d.MutationObserver};var h=""+location,y={beacon:"bam.nr-data.net",errorBeacon:"bam.nr-data.net",agent:"js-agent.newrelic.com/nr-1130.min.js"},b=g&&w&&w[m]&&!/CriOS/.test(navigator.userAgent),x=n.exports={offset:u,now:a,origin:h,features:{},xhrWrappable:b,userAgent:p};e(1),l[m]?(l[m]("DOMContentLoaded",i,!1),d[m]("load",r,!1)):(l[v]("onreadystatechange",o),d[v]("onload",r)),f("mark",["firstbyte",u],null,"api");var E=0,O=e(5)},{}]},{},["loader"]);</script><link rel="apple-touch-icon" href="https://learning.oreilly.com/static/images/apple-touch-icon.0c29511d2d72.png"><link rel="shortcut icon" href="https://learning.oreilly.com/favicon.ico" type="image/x-icon"><link href="./Chapter8_files/css" rel="stylesheet" type="text/css"><title>8. Dimensionality Reduction - Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition</title><link rel="stylesheet" href="./Chapter8_files/output.68851547a55f.css" type="text/css"><link rel="stylesheet" type="text/css" href="./Chapter8_files/annotator.e3b0c44298fc.css"><link rel="stylesheet" href="./Chapter8_files/font-awesome.min.css"><style type="text/css" title="ibis-book">@charset "utf-8";#sbo-rt-content html,#sbo-rt-content div,#sbo-rt-content div,#sbo-rt-content span,#sbo-rt-content applet,#sbo-rt-content object,#sbo-rt-content iframe,#sbo-rt-content h1,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5,#sbo-rt-content h6,#sbo-rt-content p,#sbo-rt-content blockquote,#sbo-rt-content pre,#sbo-rt-content a,#sbo-rt-content abbr,#sbo-rt-content acronym,#sbo-rt-content address,#sbo-rt-content big,#sbo-rt-content cite,#sbo-rt-content code,#sbo-rt-content del,#sbo-rt-content dfn,#sbo-rt-content em,#sbo-rt-content img,#sbo-rt-content ins,#sbo-rt-content kbd,#sbo-rt-content q,#sbo-rt-content s,#sbo-rt-content samp,#sbo-rt-content small,#sbo-rt-content strike,#sbo-rt-content strong,#sbo-rt-content sub,#sbo-rt-content sup,#sbo-rt-content tt,#sbo-rt-content var,#sbo-rt-content b,#sbo-rt-content u,#sbo-rt-content i,#sbo-rt-content center,#sbo-rt-content dl,#sbo-rt-content dt,#sbo-rt-content dd,#sbo-rt-content ol,#sbo-rt-content ul,#sbo-rt-content li,#sbo-rt-content fieldset,#sbo-rt-content form,#sbo-rt-content label,#sbo-rt-content legend,#sbo-rt-content table,#sbo-rt-content caption,#sbo-rt-content tdiv,#sbo-rt-content tfoot,#sbo-rt-content thead,#sbo-rt-content tr,#sbo-rt-content th,#sbo-rt-content td,#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content canvas,#sbo-rt-content details,#sbo-rt-content embed,#sbo-rt-content figure,#sbo-rt-content figcaption,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content output,#sbo-rt-content ruby,#sbo-rt-content section,#sbo-rt-content summary,#sbo-rt-content time,#sbo-rt-content mark,#sbo-rt-content audio,#sbo-rt-content video{margin:0;padding:0;border:0;font-size:100%;font:inherit;vertical-align:baseline}#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content details,#sbo-rt-content figcaption,#sbo-rt-content figure,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content section{display:block}#sbo-rt-content div{line-height:1}#sbo-rt-content ol,#sbo-rt-content ul{list-style:none}#sbo-rt-content blockquote,#sbo-rt-content q{quotes:none}#sbo-rt-content blockquote:before,#sbo-rt-content blockquote:after,#sbo-rt-content q:before,#sbo-rt-content q:after{content:none}#sbo-rt-content table{border-collapse:collapse;border-spacing:0}@page{margin:5px !important}#sbo-rt-content p{margin:10px 0 0;line-height:125%;text-align:left}#sbo-rt-content p.byline{text-align:left;margin:-33px auto 35px;font-style:italic;font-weight:bold}#sbo-rt-content div.preface p+p.byline{margin:1em 0 0 !important}#sbo-rt-content div.preface p.byline+p.byline{margin:0 !important}#sbo-rt-content div.sect1>p.byline{margin:-.25em 0 1em}#sbo-rt-content div.sect1>p.byline+p.byline{margin-top:-1em}#sbo-rt-content em{font-style:italic;font-family:inherit}#sbo-rt-content em strong,#sbo-rt-content strong em{font-weight:bold;font-style:italic;font-family:inherit}#sbo-rt-content strong,#sbo-rt-content span.bold{font-weight:bold}#sbo-rt-content em.replaceable{font-style:italic}#sbo-rt-content strong.userinput{font-weight:bold;font-style:normal}#sbo-rt-content span.bolditalic{font-weight:bold;font-style:italic}#sbo-rt-content a.ulink,#sbo-rt-content a.xref,#sbo-rt-content a.email,#sbo-rt-content a.link,#sbo-rt-content a{text-decoration:none;color:#8e0012}#sbo-rt-content span.lineannotation{font-style:italic;color:#a62a2a;font-family:serif}#sbo-rt-content span.underline{text-decoration:underline}#sbo-rt-content span.strikethrough{text-decoration:line-through}#sbo-rt-content span.smallcaps{font-variant:small-caps}#sbo-rt-content span.cursor{background:#000;color:#fff}#sbo-rt-content span.smaller{font-size:75%}#sbo-rt-content .boxedtext,#sbo-rt-content .keycap{border-style:solid;border-width:1px;border-color:#000;padding:1px}#sbo-rt-content span.gray50{color:#7F7F7F;}#sbo-rt-content h1,#sbo-rt-content div.toc-title,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5{-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;font-weight:bold;text-align:left;page-break-after:avoid !important;font-family:sans-serif,"DejaVuSans"}#sbo-rt-content div.toc-title{font-size:1.5em;margin-top:20px !important;margin-bottom:30px !important}#sbo-rt-content section[data-type="sect1"] h1{font-size:1.3em;color:#8e0012;margin:40px 0 8px 0}#sbo-rt-content section[data-type="sect2"] h2{font-size:1.1em;margin:30px 0 8px 0 !important}#sbo-rt-content section[data-type="sect3"] h3{font-size:1em;color:#555;margin:20px 0 8px 0 !important}#sbo-rt-content section[data-type="sect4"] h4{font-size:1em;font-weight:normal;font-style:italic;margin:15px 0 6px 0 !important}#sbo-rt-content section[data-type="chapter"]>div>h1,#sbo-rt-content section[data-type="preface"]>div>h1,#sbo-rt-content section[data-type="appendix"]>div>h1,#sbo-rt-content section[data-type="glossary"]>div>h1,#sbo-rt-content section[data-type="bibliography"]>div>h1,#sbo-rt-content section[data-type="index"]>div>h1{font-size:2em;line-height:1;margin-bottom:50px;color:#000;padding-bottom:10px;border-bottom:1px solid #000}#sbo-rt-content span.label,#sbo-rt-content span.keep-together{font-size:inherit;font-weight:inherit}#sbo-rt-content div[data-type="part"] h1{font-size:2em;text-align:center;margin-top:0 !important;margin-bottom:50px;padding:50px 0 10px 0;border-bottom:1px solid #000}#sbo-rt-content img.width-ninety{width:90%}#sbo-rt-content img{max-width:95%;margin:0 auto;padding:0}#sbo-rt-content div.figure{background-color:transparent;text-align:center !important;margin:15px 0 15px 0 !important;page-break-inside:avoid}#sbo-rt-content figure{margin:15px 0 15px 0 !important;page-break-inside:avoid}#sbo-rt-content div.figure h6,#sbo-rt-content figure h6,#sbo-rt-content figure figcaption{font-size:.9rem !important;text-align:center;font-weight:normal !important;font-style:italic;font-family:serif !important;text-transform:none !important;letter-spacing:normal !important;color:#000 !important;padding-top:10px !important;page-break-before:avoid}#sbo-rt-content div.informalfigure{text-align:center !important;padding:5px 0 !important}#sbo-rt-content div.sidebar{margin:15px 0 10px 0 !important;border:1px solid #DCDCDC;background-color:#F7F7F7;padding:15px !important;page-break-inside:avoid}#sbo-rt-content aside[data-type="sidebar"]{margin:15px 0 10px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar-title,#sbo-rt-content aside[data-type="sidebar"] h5{font-weight:bold;font-size:1em;font-family:sans-serif;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar ol,#sbo-rt-content div.sidebar ul,#sbo-rt-content aside[data-type="sidebar"] ol,#sbo-rt-content aside[data-type="sidebar"] ul{margin-left:1.25em !important}#sbo-rt-content div.sidebar div.figure p.title,#sbo-rt-content aside[data-type="sidebar"] figcaption,#sbo-rt-content div.sidebar div.informalfigure div.caption{font-size:90%;text-align:center;font-weight:normal;font-style:italic;font-family:serif !important;color:#000;padding:5px !important;page-break-before:avoid;page-break-after:avoid}#sbo-rt-content div.sidebar div.tip,#sbo-rt-content div.sidebar div[data-type="tip"],#sbo-rt-content div.sidebar div.note,#sbo-rt-content div.sidebar div[data-type="note"],#sbo-rt-content div.sidebar div.warning,#sbo-rt-content div.sidebar div[data-type="warning"],#sbo-rt-content div.sidebar div[data-type="caution"],#sbo-rt-content div.sidebar div[data-type="important"]{margin:20px auto 20px auto !important;font-size:90%;width:85%}#sbo-rt-content aside[data-type="sidebar"] p.byline{font-size:90%;font-weight:bold;font-style:italic;text-align:center;text-indent:0;margin:5px auto 6px;page-break-after:avoid}#sbo-rt-content pre{white-space:pre-wrap;font-family:"Ubuntu Mono",monospace;margin:25px 0 25px 20px;font-size:85%;display:block;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content div.note pre.programlisting,#sbo-rt-content div.tip pre.programlisting,#sbo-rt-content div.warning pre.programlisting,#sbo-rt-content div.caution pre.programlisting,#sbo-rt-content div.important pre.programlisting{margin-bottom:0}#sbo-rt-content code{font-family:"Ubuntu Mono",monospace;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content code strong em,#sbo-rt-content code em strong,#sbo-rt-content pre em strong,#sbo-rt-content pre strong em,#sbo-rt-content strong code em code,#sbo-rt-content em code strong code,#sbo-rt-content span.bolditalic code{font-weight:bold;font-style:italic;font-family:"Ubuntu Mono BoldItal",monospace}#sbo-rt-content code em,#sbo-rt-content em code,#sbo-rt-content pre em,#sbo-rt-content em.replaceable{font-family:"Ubuntu Mono Ital",monospace;font-style:italic}#sbo-rt-content code strong,#sbo-rt-content strong code,#sbo-rt-content pre strong,#sbo-rt-content strong.userinput{font-family:"Ubuntu Mono Bold",monospace;font-weight:bold}#sbo-rt-content div[data-type="example"]{margin:10px 0 15px 0 !important}#sbo-rt-content div[data-type="example"] h1,#sbo-rt-content div[data-type="example"] h2,#sbo-rt-content div[data-type="example"] h3,#sbo-rt-content div[data-type="example"] h4,#sbo-rt-content div[data-type="example"] h5,#sbo-rt-content div[data-type="example"] h6{font-style:italic;font-weight:normal;text-align:left !important;text-transform:none !important;font-family:serif !important;margin:10px 0 5px 0 !important;border-bottom:1px solid #000}#sbo-rt-content li pre.example{padding:10px 0 !important}#sbo-rt-content div[data-type="example"] pre[data-type="programlisting"],#sbo-rt-content div[data-type="example"] pre[data-type="screen"]{margin:0}#sbo-rt-content section[data-type="titlepage"]>div>h1{font-size:2em;margin:50px 0 10px 0 !important;line-height:1;text-align:center}#sbo-rt-content section[data-type="titlepage"] h2,#sbo-rt-content section[data-type="titlepage"] p.subtitle,#sbo-rt-content section[data-type="titlepage"] p[data-type="subtitle"]{font-size:1.3em;font-weight:normal;text-align:center;margin-top:.5em;color:#555}#sbo-rt-content section[data-type="titlepage"]>div>h2[data-type="author"],#sbo-rt-content section[data-type="titlepage"] p.author{font-size:1.3em;font-family:serif !important;font-weight:bold;margin:50px 0 !important;text-align:center}#sbo-rt-content section[data-type="titlepage"] p.edition{text-align:center;text-transform:uppercase;margin-top:2em}#sbo-rt-content section[data-type="titlepage"]{text-align:center}#sbo-rt-content section[data-type="titlepage"]:after{content:url(css_assets/titlepage_footer_ebook.png);margin:0 auto;max-width:80%}#sbo-rt-content div.book div.titlepage div.publishername{margin-top:60%;margin-bottom:20px;text-align:center;font-size:1.25em}#sbo-rt-content div.book div.titlepage div.locations p{margin:0;text-align:center}#sbo-rt-content div.book div.titlepage div.locations p.cities{font-size:80%;text-align:center;margin-top:5px}#sbo-rt-content section.preface[title="Dedication"]>div.titlepage h2.title{text-align:center;text-transform:uppercase;font-size:1.5em;margin-top:50px;margin-bottom:50px}#sbo-rt-content ul.stafflist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.stafflist li{list-style-type:none;padding:5px 0}#sbo-rt-content ul.printings li{list-style-type:none}#sbo-rt-content section.preface[title="Dedication"] p{font-style:italic;text-align:center}#sbo-rt-content div.colophon h1.title{font-size:1.3em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon h2.subtitle{margin:0 !important;color:#000;font-family:serif !important;font-size:1em;font-weight:normal}#sbo-rt-content div.colophon div.author h3.author{font-size:1.1em;font-family:serif !important;margin:10px 0 0 !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h4,#sbo-rt-content div.colophon div.editor h3.editor{color:#000;font-size:.8em;margin:15px 0 0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h3.editor{font-size:.8em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.publisher{margin-top:10px}#sbo-rt-content div.colophon div.publisher p,#sbo-rt-content div.colophon div.publisher span.publishername{margin:0;font-size:.8em}#sbo-rt-content div.legalnotice p,#sbo-rt-content div.timestamp p{font-size:.8em}#sbo-rt-content div.timestamp p{margin-top:10px}#sbo-rt-content div.colophon[title="About the Author"] h1.title,#sbo-rt-content div.colophon[title="Colophon"] h1.title{font-size:1.5em;margin:0 !important;font-family:sans-serif !important}#sbo-rt-content section.chapter div.titlepage div.author{margin:10px 0 10px 0}#sbo-rt-content section.chapter div.titlepage div.author div.affiliation{font-style:italic}#sbo-rt-content div.attribution{margin:5px 0 0 50px !important}#sbo-rt-content h3.author span.orgname{display:none}#sbo-rt-content div.epigraph{margin:10px 0 10px 20px !important;page-break-inside:avoid;font-size:90%}#sbo-rt-content div.epigraph p{font-style:italic}#sbo-rt-content blockquote,#sbo-rt-content div.blockquote{margin:10px !important;page-break-inside:avoid;font-size:95%}#sbo-rt-content blockquote p,#sbo-rt-content div.blockquote p{font-style:italic;margin:.75em 0 0 !important}#sbo-rt-content blockquote div.attribution,#sbo-rt-content blockquote p[data-type="attribution"]{margin:5px 0 10px 30px !important;text-align:right;width:80%}#sbo-rt-content blockquote div.attribution p,#sbo-rt-content blockquote p[data-type="attribution"]{font-style:normal;margin-top:5px}#sbo-rt-content blockquote div.attribution p:before,#sbo-rt-content blockquote p[data-type="attribution"]:before{font-style:normal;content:"—";-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none}#sbo-rt-content p.right{text-align:right;margin:0}#sbo-rt-content div[data-type="footnotes"]{border-top:1px solid black;margin-top:2em}#sbo-rt-content sub,#sbo-rt-content sup{font-size:75%;line-height:0;position:relative}#sbo-rt-content sup{top:-.5em}#sbo-rt-content sub{bottom:-.25em}#sbo-rt-content p[data-type="footnote"]{font-size:90% !important;line-height:1.2em !important;margin-left:2.5em !important;text-indent:-2.3em !important}#sbo-rt-content p[data-type="footnote"] sup{display:inline-block !important;position:static !important;width:2em !important;text-align:right !important;font-size:100% !important;padding-right:.5em !important}#sbo-rt-content p[data-type="footnote"] a[href$="-marker"]{font-family:sans-serif !important;font-size:90% !important;color:#8e0012 !important}#sbo-rt-content p[data-type="footnote"] a[data-type="xref"]{margin:0 !important;padding:0 !important;text-indent:0 !important}#sbo-rt-content a[data-type="noteref"]{font-family:sans-serif !important;color:#8e0012;margin-left:0;padding-left:0}#sbo-rt-content div.refentry p.refname{font-size:1em;font-family:sans-serif,"DejaVuSans";font-weight:bold;margin-bottom:5px;overflow:auto;width:100%}#sbo-rt-content div.refentry{width:100%;display:block;margin-top:2em}#sbo-rt-content div.refsynopsisdiv{display:block;clear:both}#sbo-rt-content div.refentry header{page-break-inside:avoid !important;display:block;break-inside:avoid !important;padding-top:0;border-bottom:1px solid #000}#sbo-rt-content div.refsect1 h6{font-size:.9em;font-family:sans-serif,"DejaVuSans";font-weight:bold}#sbo-rt-content div.refsect1{margin-top:3em}#sbo-rt-content dt{padding-top:10px !important;padding-bottom:0 !important}#sbo-rt-content dd{margin-left:1.5em !important;margin-bottom:.25em}#sbo-rt-content dd ol,#sbo-rt-content dd ul{padding-left:1em}#sbo-rt-content dd li{margin-top:0;margin-bottom:0}#sbo-rt-content dd,#sbo-rt-content li{text-align:left}#sbo-rt-content ul,#sbo-rt-content ul>li,#sbo-rt-content ol ul,#sbo-rt-content ol ul>li,#sbo-rt-content ul ol ul,#sbo-rt-content ul ol ul>li{list-style-type:disc}#sbo-rt-content ul ul,#sbo-rt-content ul ul>li{list-style-type:square}#sbo-rt-content ul ul ul,#sbo-rt-content ul ul ul>li{list-style-type:circle}#sbo-rt-content ol,#sbo-rt-content ol>li,#sbo-rt-content ol ul ol,#sbo-rt-content ol ul ol>li,#sbo-rt-content ul ol,#sbo-rt-content ul ol>li{list-style-type:decimal}#sbo-rt-content ol ol,#sbo-rt-content ol ol>li{list-style-type:lower-alpha}#sbo-rt-content ol ol ol,#sbo-rt-content ol ol ol>li{list-style-type:lower-roman}#sbo-rt-content ol,#sbo-rt-content ul{list-style-position:outside;margin:15px 0 15px 1.25em;padding-left:2.25em}#sbo-rt-content ol li,#sbo-rt-content ul li{margin:.5em 0 .65em;line-height:125%}#sbo-rt-content div.orderedlistalpha{list-style-type:upper-alpha}#sbo-rt-content table.simplelist,#sbo-rt-content ul.simplelist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.simplelist li{list-style-type:none;padding:5px 0}#sbo-rt-content table.simplelist td{border:none}#sbo-rt-content table.simplelist tr{border-bottom:none}#sbo-rt-content table.simplelist tr:nth-of-type(even){background-color:transparent}#sbo-rt-content dl.calloutlist p:first-child{margin-top:-25px !important}#sbo-rt-content dl.calloutlist dd{padding-left:0;margin-top:-25px}#sbo-rt-content dl.calloutlist img,#sbo-rt-content a.co img{padding:0}#sbo-rt-content div.toc ol{margin-top:8px !important;margin-bottom:8px !important;margin-left:0 !important;padding-left:0 !important}#sbo-rt-content div.toc ol ol{margin-left:30px !important;padding-left:0 !important}#sbo-rt-content div.toc ol li{list-style-type:none}#sbo-rt-content div.toc a{color:#8e0012}#sbo-rt-content div.toc ol a{font-size:1em;font-weight:bold}#sbo-rt-content div.toc ol>li>ol a{font-weight:bold;font-size:1em}#sbo-rt-content div.toc ol>li>ol>li>ol a{text-decoration:none;font-weight:normal;font-size:1em}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"],#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{margin:30px !important;font-size:90%;padding:10px 8px 20px 8px !important;page-break-inside:avoid}#sbo-rt-content div.tip ol,#sbo-rt-content div.tip ul,#sbo-rt-content div[data-type="tip"] ol,#sbo-rt-content div[data-type="tip"] ul,#sbo-rt-content div.note ol,#sbo-rt-content div.note ul,#sbo-rt-content div[data-type="note"] ol,#sbo-rt-content div[data-type="note"] ul,#sbo-rt-content div.warning ol,#sbo-rt-content div.warning ul,#sbo-rt-content div[data-type="warning"] ol,#sbo-rt-content div[data-type="warning"] ul,#sbo-rt-content div[data-type="caution"] ol,#sbo-rt-content div[data-type="caution"] ul,#sbo-rt-content div[data-type="important"] ol,#sbo-rt-content div[data-type="important"] ul{margin-left:1.5em !important}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"]{border:1px solid #BEBEBE;background-color:transparent}#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{border:1px solid #BC8F8F}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="note"] h1,#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1,#sbo-rt-content div[data-type="important"] h6{font-weight:bold;font-size:110%;font-family:sans-serif !important;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px !important}#sbo-rt-content div[data-type="tip"] figure h6,#sbo-rt-content div[data-type="note"] figure h6,#sbo-rt-content div[data-type="warning"] figure h6,#sbo-rt-content div[data-type="caution"] figure h6,#sbo-rt-content div[data-type="important"] figure h6{font-family:serif !important}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div[data-type="note"] h1{color:#737373}#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="important"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1{color:#C67171}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note,#sbo-rt-content div.safarienabled{background-color:transparent;margin:8px 0 0 !important;border:0 solid #BEBEBE;font-size:100%;padding:0 !important;page-break-inside:avoid}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note h3,#sbo-rt-content div.safarienabled h6{display:none}#sbo-rt-content div.table,#sbo-rt-content table{margin:15px 0 30px 0 !important;max-width:95%;border:none !important;background:none;display:table !important}#sbo-rt-content div.table,#sbo-rt-content div.informaltable,#sbo-rt-content table{page-break-inside:avoid}#sbo-rt-content tr,#sbo-rt-content tr td{border-bottom:1px solid #c3c3c3}#sbo-rt-content thead td,#sbo-rt-content thead th{border-bottom:#9d9d9d 1px solid !important;border-top:#9d9d9d 1px solid !important}#sbo-rt-content tr:nth-of-type(even){background-color:#f1f6fc}#sbo-rt-content thead{font-family:sans-serif;font-weight:bold}#sbo-rt-content td,#sbo-rt-content th{display:table-cell;padding:.3em;text-align:left;vertical-align:middle;font-size:80%}#sbo-rt-content div.informaltable table{margin:10px auto !important}#sbo-rt-content div.informaltable table tr{border-bottom:none}#sbo-rt-content div.informaltable table tr:nth-of-type(even){background-color:transparent}#sbo-rt-content div.informaltable td,#sbo-rt-content div.informaltable th{border:#9d9d9d 1px solid}#sbo-rt-content div.table-title,#sbo-rt-content table caption{font-weight:normal;font-style:italic;font-family:serif;font-size:1em;margin:10px 0 10px 0 !important;padding:0;page-break-after:avoid;text-align:left !important}#sbo-rt-content table code{font-size:smaller}#sbo-rt-content table.border tbody>tr:last-child>td{border-bottom:transparent}#sbo-rt-content div.equation,#sbo-rt-content div[data-type="equation"]{margin:10px 0 15px 0 !important}#sbo-rt-content div.equation-title,#sbo-rt-content div[data-type="equation"] h5{font-style:italic;font-weight:normal;font-family:serif !important;font-size:90%;margin:20px 0 10px 0 !important;page-break-after:avoid}#sbo-rt-content div.equation-contents{margin-left:20px}#sbo-rt-content div[data-type="equation"] math{font-size:calc(.35em + 1vw)}#sbo-rt-content span.inlinemediaobject{height:.85em;display:inline-block;margin-bottom:.2em}#sbo-rt-content span.inlinemediaobject img{margin:0;height:.85em}#sbo-rt-content div.informalequation{margin:20px 0 20px 20px;width:75%}#sbo-rt-content div.informalequation img{width:75%}#sbo-rt-content div.index{text-indent:0}#sbo-rt-content div.index h3{padding:.25em;margin-top:1em !important;background-color:#F0F0F0}#sbo-rt-content div.index li{line-height:130%;list-style-type:none}#sbo-rt-content div.index a.indexterm{color:#8e0012 !important}#sbo-rt-content div.index ul{margin-left:0 !important;padding-left:0 !important}#sbo-rt-content div.index ul ul{margin-left:1em !important;margin-top:0 !important}#sbo-rt-content code.boolean,#sbo-rt-content .navy{color:rgb(0,0,128);}#sbo-rt-content code.character,#sbo-rt-content .olive{color:rgb(128,128,0);}#sbo-rt-content code.comment,#sbo-rt-content .blue{color:rgb(0,0,255);}#sbo-rt-content code.conditional,#sbo-rt-content .limegreen{color:rgb(50,205,50);}#sbo-rt-content code.constant,#sbo-rt-content .darkorange{color:rgb(255,140,0);}#sbo-rt-content code.debug,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.define,#sbo-rt-content .darkgoldenrod,#sbo-rt-content .gold{color:rgb(184,134,11);}#sbo-rt-content code.delimiter,#sbo-rt-content .dimgray{color:rgb(105,105,105);}#sbo-rt-content code.error,#sbo-rt-content .red{color:rgb(255,0,0);}#sbo-rt-content code.exception,#sbo-rt-content .salmon{color:rgb(250,128,11);}#sbo-rt-content code.float,#sbo-rt-content .steelblue{color:rgb(70,130,180);}#sbo-rt-content pre code.function,#sbo-rt-content .green{color:rgb(0,128,0);}#sbo-rt-content code.identifier,#sbo-rt-content .royalblue{color:rgb(65,105,225);}#sbo-rt-content code.ignore,#sbo-rt-content .gray{color:rgb(128,128,128);}#sbo-rt-content code.include,#sbo-rt-content .purple{color:rgb(128,0,128);}#sbo-rt-content code.keyword,#sbo-rt-content .sienna{color:rgb(160,82,45);}#sbo-rt-content code.label,#sbo-rt-content .deeppink{color:rgb(255,20,147);}#sbo-rt-content code.macro,#sbo-rt-content .orangered{color:rgb(255,69,0);}#sbo-rt-content code.number,#sbo-rt-content .brown{color:rgb(165,42,42);}#sbo-rt-content code.operator,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.preCondit,#sbo-rt-content .teal{color:rgb(0,128,128);}#sbo-rt-content code.preProc,#sbo-rt-content .fuschia{color:rgb(255,0,255);}#sbo-rt-content code.repeat,#sbo-rt-content .indigo{color:rgb(75,0,130);}#sbo-rt-content code.special,#sbo-rt-content .saddlebrown{color:rgb(139,69,19);}#sbo-rt-content code.specialchar,#sbo-rt-content .magenta{color:rgb(255,0,255);}#sbo-rt-content code.specialcomment,#sbo-rt-content .seagreen{color:rgb(46,139,87);}#sbo-rt-content code.statement,#sbo-rt-content .forestgreen{color:rgb(34,139,34);}#sbo-rt-content code.storageclass,#sbo-rt-content .plum{color:rgb(221,160,221);}#sbo-rt-content code.string,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.structure,#sbo-rt-content .chocolate{color:rgb(210,106,30);}#sbo-rt-content code.tag,#sbo-rt-content .darkcyan{color:rgb(0,139,139);}#sbo-rt-content code.todo,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.type,#sbo-rt-content .mediumslateblue{color:rgb(123,104,238);}#sbo-rt-content code.typedef,#sbo-rt-content .darkgreen{color:rgb(0,100,0);}#sbo-rt-content code.underlined{text-decoration:underline;}#sbo-rt-content pre code.hll{background-color:#ffc}#sbo-rt-content pre code.c{color:#09F;font-style:italic}#sbo-rt-content pre code.err{color:#A00}#sbo-rt-content pre code.k{color:#069;font-weight:bold}#sbo-rt-content pre code.o{color:#555}#sbo-rt-content pre code.cm{color:#35586C;font-style:italic}#sbo-rt-content pre code.cp{color:#099}#sbo-rt-content pre code.c1{color:#35586C;font-style:italic}#sbo-rt-content pre code.cs{color:#35586C;font-weight:bold;font-style:italic}#sbo-rt-content pre code.gd{background-color:#FCC}#sbo-rt-content pre code.ge{font-style:italic}#sbo-rt-content pre code.gr{color:#F00}#sbo-rt-content pre code.gh{color:#030;font-weight:bold}#sbo-rt-content pre code.gi{background-color:#CFC}#sbo-rt-content pre code.go{color:#000}#sbo-rt-content pre code.gp{color:#009;font-weight:bold}#sbo-rt-content pre code.gs{font-weight:bold}#sbo-rt-content pre code.gu{color:#030;font-weight:bold}#sbo-rt-content pre code.gt{color:#9C6}#sbo-rt-content pre code.kc{color:#069;font-weight:bold}#sbo-rt-content pre code.kd{color:#069;font-weight:bold}#sbo-rt-content pre code.kn{color:#069;font-weight:bold}#sbo-rt-content pre code.kp{color:#069}#sbo-rt-content pre code.kr{color:#069;font-weight:bold}#sbo-rt-content pre code.kt{color:#078;font-weight:bold}#sbo-rt-content pre code.m{color:#F60}#sbo-rt-content pre code.s{color:#C30}#sbo-rt-content pre code.na{color:#309}#sbo-rt-content pre code.nb{color:#366}#sbo-rt-content pre code.nc{color:#0A8;font-weight:bold}#sbo-rt-content pre code.no{color:#360}#sbo-rt-content pre code.nd{color:#99F}#sbo-rt-content pre code.ni{color:#999;font-weight:bold}#sbo-rt-content pre code.ne{color:#C00;font-weight:bold}#sbo-rt-content pre code.nf{color:#C0F}#sbo-rt-content pre code.nl{color:#99F}#sbo-rt-content pre code.nn{color:#0CF;font-weight:bold}#sbo-rt-content pre code.nt{color:#309;font-weight:bold}#sbo-rt-content pre code.nv{color:#033}#sbo-rt-content pre code.ow{color:#000;font-weight:bold}#sbo-rt-content pre code.w{color:#bbb}#sbo-rt-content pre code.mf{color:#F60}#sbo-rt-content pre code.mh{color:#F60}#sbo-rt-content pre code.mi{color:#F60}#sbo-rt-content pre code.mo{color:#F60}#sbo-rt-content pre code.sb{color:#C30}#sbo-rt-content pre code.sc{color:#C30}#sbo-rt-content pre code.sd{color:#C30;font-style:italic}#sbo-rt-content pre code.s2{color:#C30}#sbo-rt-content pre code.se{color:#C30;font-weight:bold}#sbo-rt-content pre code.sh{color:#C30}#sbo-rt-content pre code.si{color:#A00}#sbo-rt-content pre code.sx{color:#C30}#sbo-rt-content pre code.sr{color:#3AA}#sbo-rt-content pre code.s1{color:#C30}#sbo-rt-content pre code.ss{color:#A60}#sbo-rt-content pre code.bp{color:#366}#sbo-rt-content pre code.vc{color:#033}#sbo-rt-content pre code.vg{color:#033}#sbo-rt-content pre code.vi{color:#033}#sbo-rt-content pre code.il{color:#F60}#sbo-rt-content pre code.g{color:#050}#sbo-rt-content pre code.l{color:#C60}#sbo-rt-content pre code.l{color:#F90}#sbo-rt-content pre code.n{color:#008}#sbo-rt-content pre code.nx{color:#008}#sbo-rt-content pre code.py{color:#96F}#sbo-rt-content pre code.p{color:#000}#sbo-rt-content pre code.x{color:#F06}#sbo-rt-content div.blockquote_sampler_toc{width:95%;margin:5px 5px 5px 10px !important}#sbo-rt-content div{font-family:serif;text-align:left}#sbo-rt-content .gray-background,#sbo-rt-content .reverse-video{background:#2E2E2E;color:#FFF}#sbo-rt-content .light-gray-background{background:#A0A0A0}#sbo-rt-content .preserve-whitespace{white-space:pre-wrap}#sbo-rt-content span.gray{color:#4C4C4C}#sbo-rt-content .width-10{width:10vw !important}#sbo-rt-content .width-20{width:20vw !important}#sbo-rt-content .width-30{width:30vw !important}#sbo-rt-content .width-40{width:40vw !important}#sbo-rt-content .width-50{width:50vw !important}#sbo-rt-content .width-60{width:60vw !important}#sbo-rt-content .width-70{width:70vw !important}#sbo-rt-content .width-80{width:80vw !important}#sbo-rt-content .width-90{width:90vw !important}#sbo-rt-content .width-full,#sbo-rt-content .width-100{width:100vw !important}#sbo-rt-content div[data-type="equation"].fifty-percent img{width:50%}</style><script> // <![CDATA[
    var g = {
      position_cache: {
        
          "chapter": "/api/v1/book/9781492032632/chapter/part01.html",
          "book_id": "9781492032632",
          "chapter_uri": "part01.html",
          "position": 100.0,
          "user_uuid": "d59baa21-c0cd-4fcf-9c68-a2b8d4f52a79",
          "next_chapter_uri": "/library/view/hands-on-machine-learning/9781492032632/ch01.html"
        
      },
      title: "Hands\u002Don Machine Learning with Scikit\u002DLearn, Keras, and TensorFlow, 2nd Edition",
      author_list: "Aurélien Géron",
      format: "book",
      source: "application/epub+zip",
      is_system_book: true,
      is_public: false,
      loaded_from_server: true,
      allow_scripts: false,
      has_mathml: true
    };
    // ]]></script><script src="./Chapter8_files/modernizr.8e35451ddb64.js.download"></script><script>
    
      

      
        
          window.PUBLIC_ANNOTATIONS = true;
        
      

      window.MOBILE_PUBLIC_ANNOTATIONS = false;

    

    
      window.PRIVACY_CONTROL_OVERRIDE = false;
    

      window.PRIVACY_CONTROL_SWITCH = true;

      window.PUBLISHER_PAGES = true;

      window.SBO = {
        "constants": {
          "SITB_ENDPOINT": "/api/v2/sitb/",
          "SEARCH_SELECT_ENDPOINT": "https://learning.oreilly.com/api/v2/search/select/",
          "ENABLE_ONLINE_TRAINING": false
        }
      };
  </script><link rel="canonical" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/part01.html"><meta name="description" content=" Part I. The Fundamentals of Machine Learning "><meta property="og:title" content="I. The Fundamentals of Machine Learning"><meta itemprop="isPartOf" content="/library/view/hands-on-machine-learning/9781492032632/"><meta itemprop="name" content="I. The Fundamentals of Machine Learning"><meta property="og:url" itemprop="url" content="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/part01.html"><meta property="og:site_name" content="Safari"><meta property="og:image" itemprop="thumbnailUrl" content="https://learning.oreilly.com/library/cover/9781492032632/"><meta property="og:description" itemprop="description" content=" Part I. The Fundamentals of Machine Learning "><meta itemprop="inLanguage" content="en"><meta itemprop="publisher" content="O&#39;Reilly Media, Inc."><meta property="og:type" content="book"><meta property="og:book:isbn" itemprop="isbn" content="9781492032649"><meta property="og:book:author" itemprop="author" content="Aurélien Géron"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@safari"><style type="text/css" id="font-styles" data-template="#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-size: &lt;%= font_size %&gt; !important; }"></style><style type="text/css" id="font-family" data-template="#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-family: &lt;%= font_family %&gt; !important; }"></style><style type="text/css" id="column-width" data-template="#sbo-rt-content { max-width: &lt;%= column_width %&gt;% !important; margin: 0 auto !important; }"></style><noscript><meta http-equiv="refresh" content="0; url=/library/no-js/" /></noscript><script type="text/javascript">
    (function(i,s,o,g,r,a,m) {
      i['GoogleAnalyticsObject']=r;
      i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();
      a=s.createElement(o),m=s.getElementsByTagName(o)[0];
      a.async=1;
      a.src=g;
      m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    var matches = document.cookie.match(/BrowserCookie\s*=\s*([a-f0-9\-]{36})/),
      user_uuid = null;

    if (matches && matches.length === 2) {
      user_uuid = matches[1];
    }

  
    ga('create', 'UA-39299553-7', {'userId': 'd59baa21-c0cd-4fcf-9c68-a2b8d4f52a79' });
  

  
    
      ga('set', 'dimension1', 'B2B');
    
  

  ga('set', 'dimension6', user_uuid);

  
    ga('set', 'dimension2', 'd59baa21-c0cd-4fcf-9c68-a2b8d4f52a79');
    
      ga('set', 'dimension7', '0012M0000229keZQAQ');
    
  

  

  

  //enable enhanced link tracking
  ga('require', 'linkid', 'linkid.js');

  // reading interface will track pageviews itself
  if (document.location.pathname.indexOf("/library/view") !== 0) {
    ga('send', 'pageview');
  }
  </script><script>
    var dataLayer = window.dataLayer || [];

    
      window.medalliaVsgUserIdentifier = 'd59baa21-c0cd-4fcf-9c68-a2b8d4f52a79';
      dataLayer.push({userIdentifier: 'd59baa21-c0cd-4fcf-9c68-a2b8d4f52a79'});
      dataLayer.push({loggedIn: 'yes'});

      
        window.medalliaVsgAccountIdentifier = '21bed0a7-6b7b-470c-8fa0-40a52db0b491';
        
        dataLayer.push({orgID: '21bed0a7-6b7b-470c-8fa0-40a52db0b491'});
        

        window.medalliaVsgIsIndividual = false;
        
          
          dataLayer.push({learningAccountType: 'enterprise'});
          
        

        
          dataLayer.push({learningPaidAccount: 'yes'});
        
      
    

    (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    '//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-5P4V6Z');
    (function () {
      var VERSION = 'V1.1';
      var AUTHOR = 'Awwad';
      if (!window.GtmHelper)
        window.GtmHelper = function () {
          var instance = this;
          var loc = document.location;
          this.version = VERSION;
          this.author = AUTHOR;
          this.readCookie = function (name) {
            var nameEQ = name + "=";
            var ca = document.cookie.split(';');
            for (var i = 0; i < ca.length; i++) {
              var c = ca[i];
              while (c.charAt(0) == ' ') c = c.substring(1, c.length);
              if (c.indexOf(nameEQ) == 0) return c.substring(nameEQ.length, c.length);
            }
            return null;
          };
          this.createCookie = function (name, value, days, cookieDomain) {
            var domain = "";
            var expires = "";

            if (days) {
              var date = new Date();
              date.setTime(date.getTime() + Math.ceil(days * 24 * 60 * 60 * 1000));
              var expires = " expires=" + date.toGMTString() + ";";
            }

            if (typeof (cookieDomain) != 'undefined')
              domain = " domain=" + cookieDomain + "; ";

            document.cookie = name + "=" + value + ";" + expires + domain + "path=/";
          };

          this.isDuplicated = function (currentTransactionId) {
            // the previous transaction id:
            var previousTransIdValue = this.readCookie("previousTransId");

            if (currentTransactionId === previousTransIdValue) {
              return true; // Duplication
            } else {
              return false;
            }
          };
        }
    })()
  </script><script defer="" src="./Chapter8_files/vendor.a48a756c5182.js.download"></script><script defer="" src="./Chapter8_files/reader.f2a0c6bd2fee.js.download"></script><script src="./Chapter8_files/f(1).txt"></script><script src="./Chapter8_files/f(2).txt"></script><script src="./Chapter8_files/f(3).txt"></script><script src="./Chapter8_files/f(4).txt"></script><script async="" src="./Chapter8_files/MathJax.js.download"></script><style id="annotator-dynamic-style">.annotator-adder, .annotator-outer, .annotator-notice {
  z-index: 2147483020;
}
.annotator-filter {
  z-index: 2147483010;
}</style><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 2px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 2px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: 1em}
.MathJax_MenuRadioCheck.RTL {right: 1em; left: auto}
.MathJax_MenuLabel {padding: 2px 2em 4px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #CCCCCC; margin: 4px 1px 0px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: Highlight; color: HighlightText}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MathJax_Preview .MJXf-math {color: inherit!important}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
</style><script async="true" type="text/javascript" src="./Chapter8_files/roundtrip.js.download"></script><style type="text/css" id="kampyleStyle">.noOutline{outline: none !important;}.wcagOutline:focus{outline: 1px dashed #595959 !important;outline-offset: 2px !important;transition: none !important;}</style><script async="true" type="text/javascript" src="./Chapter8_files/roundtrip.js.download"></script><style type="text/css">.MathJax_Display {text-align: center; margin: 1em 0em; position: relative; display: block!important; text-indent: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; width: 100%}
.MathJax .merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MathJax .MJX-monospace {font-family: monospace}
.MathJax .MJX-sans-serif {font-family: sans-serif}
#MathJax_Tooltip {background-color: InfoBackground; color: InfoText; border: 1px solid black; box-shadow: 2px 2px 5px #AAAAAA; -webkit-box-shadow: 2px 2px 5px #AAAAAA; -moz-box-shadow: 2px 2px 5px #AAAAAA; -khtml-box-shadow: 2px 2px 5px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true'); padding: 3px 4px; z-index: 401; position: absolute; left: 0; top: 0; width: auto; height: auto; display: none}
.MathJax {display: inline; font-style: normal; font-weight: normal; line-height: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; padding: 0; margin: 0}
.MathJax:focus, body :focus .MathJax {display: inline-table}
.MathJax.MathJax_FullWidth {text-align: center; display: table-cell!important; width: 10000em!important}
.MathJax img, .MathJax nobr, .MathJax a {border: 0; padding: 0; margin: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; vertical-align: 0; line-height: normal; text-decoration: none}
img.MathJax_strut {border: 0!important; padding: 0!important; margin: 0!important; vertical-align: 0!important}
.MathJax span {display: inline; position: static; border: 0; padding: 0; margin: 0; vertical-align: 0; line-height: normal; text-decoration: none}
.MathJax nobr {white-space: nowrap!important}
.MathJax img {display: inline!important; float: none!important}
.MathJax * {transition: none; -webkit-transition: none; -moz-transition: none; -ms-transition: none; -o-transition: none}
.MathJax_Processing {visibility: hidden; position: fixed; width: 0; height: 0; overflow: hidden}
.MathJax_Processed {display: none!important}
.MathJax_ExBox {display: block!important; overflow: hidden; width: 1px; height: 60ex; min-height: 0; max-height: none}
.MathJax .MathJax_EmBox {display: block!important; overflow: hidden; width: 1px; height: 60em; min-height: 0; max-height: none}
.MathJax_LineBox {display: table!important}
.MathJax_LineBox span {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MathJax .MathJax_HitBox {cursor: text; background: white; opacity: 0; filter: alpha(opacity=0)}
.MathJax .MathJax_HitBox * {filter: none; opacity: 1; background: transparent}
#MathJax_Tooltip * {filter: none; opacity: 1; background: transparent}
@font-face {font-family: MathJax_Main; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf?V=2.7.1') format('opentype')}
@font-face {font-family: MathJax_Main-bold; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf?V=2.7.1') format('opentype')}
@font-face {font-family: MathJax_Main-italic; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf?V=2.7.1') format('opentype')}
@font-face {font-family: MathJax_Math-italic; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf?V=2.7.1') format('opentype')}
@font-face {font-family: MathJax_Caligraphic; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf?V=2.7.1') format('opentype')}
@font-face {font-family: MathJax_Size1; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf?V=2.7.1') format('opentype')}
@font-face {font-family: MathJax_Size2; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf?V=2.7.1') format('opentype')}
@font-face {font-family: MathJax_Size3; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf?V=2.7.1') format('opentype')}
@font-face {font-family: MathJax_Size4; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf?V=2.7.1') format('opentype')}
</style><style type="text/css">@font-face {font-family: MathJax_Math-bold-italic; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf?V=2.7.1') format('opentype')}
</style></head>


<body class="reading sidenav  scalefonts library nav-collapsed"><div style="visibility: hidden; overflow: hidden; position: absolute; top: 0px; height: 1px; width: auto; padding: 0px; border: 0px; margin: 0px; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal;"><div id="MathJax_Hidden"></div></div><div id="MathJax_Message" style="display: none;"></div>

    
  <noscript> 
    <iframe src="//www.googletagmanager.com/ns.html?id=GTM-5P4V6Z"
            height="0" width="0"
            style="display:none;visibility:hidden">
    </iframe>
  </noscript>



    
      <div class="hide working" role="status">
        <div class="working-image"></div>
      </div>
      <div class="sbo-site-nav">
        





<a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#container" class="skip">Skip to content</a><header class="topbar t-topbar"><nav role="navigation" class="js-site-nav"><ul class="topnav"><li class="t-logo"><a href="https://learning.oreilly.com/home/" class="l0 None safari-home nav-icn js-keyboard-nav-home"><svg width="16" height="16" viewBox="0 0 16 16" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M11.738 14H9.254v-3.676a.617.617 0 0 0-.621-.613H7.39a.617.617 0 0 0-.62.613V14H4.284a.617.617 0 0 1-.622-.613V10.22c0-.327.132-.64.367-.87l3.547-3.493a.627.627 0 0 1 .875 0l3.54 3.499c.234.229.366.54.367.864v3.167a.617.617 0 0 1-.62.613zM7.57 2.181a.625.625 0 0 1 .882 0l5.77 5.692-.93.92-5.28-5.209-5.28 5.208-.932-.919 5.77-5.692z"></path></svg><span>Safari Home</span></a></li><li><a href="https://learning.oreilly.com/resource-centers/" class="t-resource-centers-nav l0 nav-icn"><!--?xml version="1.0" encoding="UTF-8"?--><svg width="16px" height="16px" viewBox="0 0 16 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><g id="Topic-Page-Design" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g id="Heron-Button" transform="translate(-20.000000, -78.000000)" fill="#4A3A30"><g id="Group-9" transform="translate(20.000000, 78.000000)"><rect id="Rectangle" x="9.6" y="0" width="6.4" height="6.4" rx="0.503118"></rect><rect id="Rectangle" x="9.6" y="9.6" width="6.4" height="6.4" rx="0.503118"></rect><rect id="Rectangle" x="0" y="9.6" width="6.4" height="6.4" rx="0.503118"></rect></g></g></g></svg><span>Resource Centers</span></a></li><li><a href="https://learning.oreilly.com/playlists/" class="t-queue-nav l0 nav-icn None"><!--?xml version="1.0" encoding="UTF-8"?--><svg width="21px" height="17px" viewBox="0 0 21 17" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><!-- Generator: Sketch 46.2 (44496) - http://www.bohemiancoding.com/sketch --><title>icon_Playlist_sml</title><desc>Created with Sketch.</desc><defs></defs><g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g id="icon_Playlist_sml" fill-rule="nonzero" fill="#000000"><g id="playlist-icon"><g id="Group-6"><rect id="Rectangle-path" x="5" y="0" width="16" height="3" rx="0.5"></rect><circle id="Oval" cx="1.5" cy="1.5" r="1.5"></circle></g><g id="Group-5" transform="translate(0.000000, 7.000000)"><circle id="Oval" cx="1.5" cy="1.5" r="1.5"></circle><rect id="Rectangle-path" x="5" y="0" width="16" height="3" rx="0.5"></rect></g><g id="Group-5-Copy" transform="translate(0.000000, 14.000000)"><circle id="Oval" cx="1.5" cy="1.5" r="1.5"></circle><rect id="Rectangle-path" x="5" y="0" width="16" height="3" rx="0.5"></rect></g></g></g></g></svg><span>
               Playlists
            </span></a></li><li class="search"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#" class="t-search-nav trigger nav-icn l0" data-dropdown-selector=".searchbox"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>search icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M31.3 0C20.9 0 12.5 8.4 12.5 18.8 12.5 22.5 13.6 25.9 15.4 28.8L1.2 42.9C-0.4 44.5-0.4 47.2 1.2 48.8 2 49.6 3.1 50 4.2 50 5.2 50 6.3 49.6 7.1 48.8L21.2 34.6C24.1 36.5 27.5 37.5 31.3 37.5 41.6 37.5 50 29.1 50 18.8 50 8.4 41.6 0 31.3 0ZM31.3 31.3C24.4 31.3 18.8 25.6 18.8 18.8 18.8 11.9 24.4 6.3 31.3 6.3 38.1 6.3 43.8 11.9 43.8 18.8 43.8 25.6 38.1 31.3 31.3 31.3Z"></path></g></svg><span>Search</span></a></li><li class="usermenu dropdown"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#" class="trigger l0 nav-icn nav-dropdown"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="20" height="20" version="1.1" fill="#4A3C31"><desc>navigation arrow</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M0.1 12.5L9.7 3.1C9.8 3 9.9 3 10 3 10.1 3 10.2 3 10.3 3.1L19.9 12.5C20 12.5 20 12.6 20 12.8 20 12.9 20 13 19.9 13L17 15.9C16.9 16 16.8 16 16.7 16 16.5 16 16.4 16 16.4 15.9L10 9.7 3.6 15.9C3.6 16 3.5 16 3.3 16 3.2 16 3.1 16 3 15.9L0.1 13C0 12.9 0 12.8 0 12.7 0 12.7 0 12.6 0.1 12.5Z"></path></g></svg><span>Expand Nav</span></a><div class="drop-content"><ul><li><a href="https://learning.oreilly.com/history/" class="t-recent-nav l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>recent items icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 0C11.2 0 0 11.2 0 25 0 38.8 11.2 50 25 50 38.8 50 50 38.8 50 25 50 11.2 38.8 0 25 0ZM6.3 25C6.3 14.6 14.6 6.3 25 6.3 35.4 6.3 43.8 14.6 43.8 25 43.8 35.4 35.4 43.8 25 43.8 14.6 43.8 6.3 35.4 6.3 25ZM31.8 31.5C32.5 30.5 32.4 29.2 31.6 28.3L27.1 23.8 27.1 12.8C27.1 11.5 26.2 10.4 25 10.4 23.9 10.4 22.9 11.5 22.9 12.8L22.9 25.7 28.8 31.7C29.2 32.1 29.7 32.3 30.2 32.3 30.8 32.3 31.3 32 31.8 31.5Z"></path></g></svg><span>History</span></a></li><li><a href="https://learning.oreilly.com/topics" class="t-topics-link l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 55" width="20" height="20" version="1.1" fill="#4A3C31"><desc>topics icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 55L50 41.262 50 13.762 25 0 0 13.762 0 41.262 25 55ZM8.333 37.032L8.333 17.968 25 8.462 41.667 17.968 41.667 37.032 25 46.538 8.333 37.032Z"></path></g></svg><span>Topics</span></a></li><li><a href="https://learning.oreilly.com/learning-paths/" class="l1 nav-icn t-learningpaths-nav js-toggle-menu-item"><!--?xml version="1.0" encoding="UTF-8"?--><svg width="32px" height="32px" viewBox="0 0 32 32" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><!-- Generator: Sketch 52.5 (67469) - http://www.bohemiancoding.com/sketch --><title>Mask</title><desc>Created with Sketch.</desc><g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><path d="M0,16.0214227 C0,15.0387209 0.796453294,14.2411658 1.77779753,14.2411658 C2.75914177,14.2411658 3.55559506,15.0387209 3.55559506,16.0214227 C3.55559506,17.0041246 2.75914177,17.8016797 1.77779753,17.8016797 C0.796453294,17.8016797 0,17.0041246 0,16.0214227 Z M9.77788642,5.22914885 C8.9280992,5.72049977 7.84008711,5.42853763 7.34941499,4.57757479 C6.85874287,3.72661195 7.15030167,2.63709467 8.00008889,2.14574375 C8.84987611,1.65439282 9.9378882,1.94635496 10.4285603,2.7973178 C10.9192324,3.64828064 10.6276736,4.73779792 9.77788642,5.22914885 Z M4.57213969,7.35869225 C5.42192691,7.85004318 5.71348571,8.93956046 5.22281359,9.79052329 C4.73214147,10.6414861 3.64412938,10.9334483 2.79434216,10.4420974 C1.94455494,9.95074642 1.65299614,8.86122915 2.14366826,8.01026631 C2.63434038,7.15930347 3.72235247,6.86734132 4.57213969,7.35869225 Z M2.79434216,21.6007481 C3.64412938,21.1093972 4.73214147,21.4013594 5.22281359,22.2523222 C5.71348571,23.103285 5.42192691,24.1928023 4.57213969,24.6841532 C3.72235247,25.1755042 2.63434038,24.883542 2.14366826,24.0325792 C1.65299614,23.1816163 1.94455494,22.0920991 2.79434216,21.6007481 Z M7.34941499,27.4652707 C7.84008711,26.6143079 8.9280992,26.3223457 9.77788642,26.8136966 C10.6276736,27.3050476 10.9192324,28.3945649 10.4285603,29.2455277 C9.9378882,30.0964905 8.84987611,30.3884527 8.00008889,29.8971017 C7.15030167,29.4057508 6.85874287,28.3162335 7.34941499,27.4652707 Z M18.7118524,11.3165596 C21.3074367,12.8173162 22.1963355,16.1392758 20.6976522,18.738451 C19.1989689,21.3358459 15.8815987,22.2259744 13.2860143,20.726998 C10.6922077,19.2262414 9.80330893,15.9042818 11.3002144,13.3051066 C12.7988978,10.7059314 16.116268,9.81580294 18.7118524,11.3165596 Z M26.7821642,27.8093944 L30.1315348,31.1633985 C30.3982044,31.4304371 30.2097579,31.8844026 29.8346426,31.8844026 L21.5945511,31.8844026 C21.1287681,31.8844026 20.751875,31.5069881 20.751875,31.0405608 L20.751875,22.7890697 C20.751875,22.4134355 21.2052134,22.2247282 21.4701052,22.4899865 L24.2843587,25.3081333 C26.8337204,23.0240636 28.4444049,19.7092251 28.4444049,16.0223129 C28.4444049,9.15052091 22.8621207,3.56051397 15.9998222,3.56051397 L15.9998222,0 C24.8230314,0 32,7.18689745 32,16.0223129 C32,20.6919269 29.9750886,24.8790914 26.7821642,27.8093944 Z" id="Mask" fill="#8B889A"></path></g></svg><span>Learning Paths</span></a></li><li class="nav-highlights"><a href="https://learning.oreilly.com/u/d59baa21-c0cd-4fcf-9c68-a2b8d4f52a79/" class="t-highlights-nav l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 35" width="20" height="20" fill="#4A3C31"><path d="M13.325 18.071H8.036c0-6.736 4.324-10.925 14.464-12.477V0C6.37 1.113 0 10.632 0 22.113 0 29.406 3.477 35 10.403 35c5.142 0 9.175-3.515 9.175-8.816 0-4.628-2.367-7.293-6.253-8.113zm27.5 0h-5.26c0-6.736 4.295-10.925 14.435-12.477V0C33.899 1.113 27.5 10.632 27.5 22.113 27.5 29.406 30.977 35 37.932 35c5.113 0 9.146-3.515 9.146-8.816 0-4.628-2.338-7.293-6.253-8.113z" fill-rule="evenodd"></path></svg><span>Highlights</span></a></li><li><a href="https://learning.oreilly.com/u/preferences/" class="t-settings-nav l1 js-settings nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 53" width="20" height="20" version="1.1" fill="#4A3C31"><desc>settings icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M44.6 29.6C44.7 28.6 44.8 27.5 44.8 26.5 44.8 25.5 44.7 24.4 44.6 23.4L49.6 19C50 18.8 50.1 18.3 49.9 17.9 48.9 14.7 47.1 11.7 44.9 9.1 44.6 8.8 44.2 8.7 43.8 8.8L37.4 11.1C35.8 9.8 34 8.7 32.1 8L30.9 1.4C30.8 0.9 30.4 0.6 30 0.5 26.7-0.2 23.3-0.2 20 0.5 19.6 0.6 19.2 0.9 19.1 1.4L17.9 8C16 8.7 14.1 9.8 12.6 11.1L6.2 8.8C5.8 8.7 5.4 8.8 5.1 9.1 2.9 11.7 1.1 14.7 0.1 17.9 -0.1 18.3 0 18.8 0.4 19L5.4 23.4C5.3 24.4 5.2 25.5 5.2 26.5 5.2 27.5 5.3 28.6 5.4 29.6L0.4 34C0 34.2-0.1 34.7 0.1 35.1 1.1 38.3 2.9 41.4 5.1 43.9 5.4 44.2 5.8 44.4 6.2 44.2L12.6 42C14.1 43.2 16 44.3 17.9 45L19.1 51.7C19.2 52.1 19.6 52.5 20 52.5 21.6 52.8 23.3 53 25 53 26.7 53 28.4 52.8 30 52.5 30.4 52.5 30.8 52.1 30.9 51.7L32.1 45C34 44.3 35.8 43.2 37.4 42L43.8 44.2C44.2 44.4 44.6 44.2 44.9 43.9 47.1 41.4 48.9 38.3 49.9 35.1 50.1 34.7 50 34.2 49.6 34L44.6 29.6ZM25 36.4C19.6 36.4 15.2 32 15.2 26.5 15.2 21 19.6 16.6 25 16.6 30.4 16.6 34.8 21 34.8 26.5 34.8 32 30.4 36.4 25 36.4Z"></path></g></svg><span>Settings</span></a></li><li><a href="https://www.oreilly.com/online-learning/support/" class="l1 no-icon">Support</a></li><li><a href="https://learning.oreilly.com/accounts/logout/" class="l1 no-icon">Sign Out</a></li></ul><ul class="profile"><li><a href="https://learning.oreilly.com/u/preferences/" class="l2 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 53" width="20" height="20" version="1.1" fill="#4A3C31"><desc>settings icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M44.6 29.6C44.7 28.6 44.8 27.5 44.8 26.5 44.8 25.5 44.7 24.4 44.6 23.4L49.6 19C50 18.8 50.1 18.3 49.9 17.9 48.9 14.7 47.1 11.7 44.9 9.1 44.6 8.8 44.2 8.7 43.8 8.8L37.4 11.1C35.8 9.8 34 8.7 32.1 8L30.9 1.4C30.8 0.9 30.4 0.6 30 0.5 26.7-0.2 23.3-0.2 20 0.5 19.6 0.6 19.2 0.9 19.1 1.4L17.9 8C16 8.7 14.1 9.8 12.6 11.1L6.2 8.8C5.8 8.7 5.4 8.8 5.1 9.1 2.9 11.7 1.1 14.7 0.1 17.9 -0.1 18.3 0 18.8 0.4 19L5.4 23.4C5.3 24.4 5.2 25.5 5.2 26.5 5.2 27.5 5.3 28.6 5.4 29.6L0.4 34C0 34.2-0.1 34.7 0.1 35.1 1.1 38.3 2.9 41.4 5.1 43.9 5.4 44.2 5.8 44.4 6.2 44.2L12.6 42C14.1 43.2 16 44.3 17.9 45L19.1 51.7C19.2 52.1 19.6 52.5 20 52.5 21.6 52.8 23.3 53 25 53 26.7 53 28.4 52.8 30 52.5 30.4 52.5 30.8 52.1 30.9 51.7L32.1 45C34 44.3 35.8 43.2 37.4 42L43.8 44.2C44.2 44.4 44.6 44.2 44.9 43.9 47.1 41.4 48.9 38.3 49.9 35.1 50.1 34.7 50 34.2 49.6 34L44.6 29.6ZM25 36.4C19.6 36.4 15.2 32 15.2 26.5 15.2 21 19.6 16.6 25 16.6 30.4 16.6 34.8 21 34.8 26.5 34.8 32 30.4 36.4 25 36.4Z"></path></g></svg><span>Settings</span></a></li><li><a href="https://www.oreilly.com/online-learning/support/" class="l2">Support</a></li><li><a href="https://learning.oreilly.com/accounts/logout/" class="l2">Sign Out</a></li></ul></div></li></ul></nav></header>


      </div>
      <div id="container" class="application" style="height: auto;">
        
          <div class="nav-container clearfix">
            


            
            
          </div>

          

  <div class="js-toc">
    
      <div class="sbo-reading-menu sbo-menu-top"><section class="sbo-toc-container toc-menu"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#" class="sbo-toc-thumb"><span class="sbo-title ss-list"><h1><div class="visuallyhidden">Table of Contents for </div>
      
      Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition
      
    </h1></span></a><div class="toc-contents"></div></section></div>

    

    <div class="interface-controls interface-controls-top">
      <ul class="interface-control-btns js-bitlist js-reader">
        <li class="js-search-in-archive search-in-archive t-search-in-archive"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#" title="Search in archive" class="js-search-controls search-controls"><span class="icon">Search in book...</span></a><form class="search-archive-bar js-search-form"><input type="search" name="query" placeholder="Search inside this book..." autocomplete="off"></form><div class="search-archive-results"><div class="js-sitb-results-region"></div></div></li><li class="queue-control"><div class="js-content-uri" data-content-uri="/api/v1/book/9781492032632/chapter/part01.html"><div class="js-collections-dropdown collections-dropdown menu-bit-cards"><div data-reactroot="" class="menu-dropdown-wrapper js-menu-dropdown-wrapper align-right"><img class="hidden" src="./Chapter8_files/ajax-transp.gif" alt="loading spinner"><div class="menu-control"><div class="control "><div class="js-playlists-menu"><button class="js-playlist-icon"><svg class="icon-add-to-playlist-sml" viewBox="0 0 16 14" version="1.1" xmlns="http://www.w3.org/2000/svg"><g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g fill-rule="nonzero" fill="#000000"><g transform="translate(-1.000000, 0.000000)"><rect x="5" y="0" width="12" height="2"></rect><title>Playlists</title><path d="M4.5,14 C6.43299662,14 8,12.4329966 8,10.5 C8,8.56700338 6.43299662,7 4.5,7 C2.56700338,7 1,8.56700338 1,10.5 C1,12.4329966 2.56700338,14 4.5,14 Z M2.5,10 L4,10 L4,8.5 L5,8.5 L5,10 L6.5,10 L6.5,11 L5,11 L5,12.5 L4,12.5 L4,11 L2.5,11 L2.5,10 Z"></path><circle cx="2" cy="5" r="1"></circle><circle cx="1.94117647" cy="1" r="1"></circle><rect x="5" y="4" width="12" height="2"></rect><rect x="9" y="8" width="8" height="2"></rect><rect x="9" y="12" width="8" height="2"></rect></g></g></g></svg><div class="js-playlist-addto-label">Add&nbsp;To</div></button></div></div></div></div></div></div></li><li class="js-font-control-panel font-control-activator"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#" data-push-state="false" id="font-controls" title="Change font size" aria-label="Change font size"><span class="icon">Toggle Font Controls</span></a></li><li class="dropdown sharing-controls"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#" class="trigger" data-push-state="false" title="Share" aria-label="Share"><i class="fa fa-share"></i></a><ul class="social-sharing dropdown-menu"><li><a class="twitter share-button t-twitter" target="_blank" aria-label="Share this section on Twitter" title="Share this section on Twitter" href="https://twitter.com/share?url=https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/part01.html&amp;text=Hands-on%20Machine%20Learning%20with%20Scikit-Learn%2C%20Keras%2C%20and%20TensorFlow%2C%202nd%20Edition&amp;via=safari"><span>Twitter</span></a></li><li><a class="facebook share-button t-facebook" target="_blank" aria-label="Share this section on Facebook" title="Share this section on Facebook" href="https://www.facebook.com/sharer/sharer.php?u=https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/part01.html"><span>Facebook</span></a></li><li><a class="googleplus share-button t-googleplus" target="_blank" aria-label="Share this secton on Google Plus" title="Share this secton on Google Plus" href="https://plus.google.com/share?url=https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/part01.html"><span>Google Plus</span></a></li><li><a class="email share-button t-email" aria-label="Share this section via email" title="Share this section via email" href="mailto:?subject=Safari:%20I.%20The%20Fundamentals%20of%20Machine%20Learning&amp;body=https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/part01.html%0D%0Afrom%20Hands-on%20Machine%20Learning%20with%20Scikit-Learn%2C%20Keras%2C%20and%20TensorFlow%2C%202nd%20Edition%0D%0A"><span>Email</span></a></li></ul></li>
      </ul>
    </div>

    
    <section role="document">
	  <div class="t-sbo-prev sbo-prev sbo-nav-top">
  
    
      
        <a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch07.html" class="prev nav-link">
      
          <span aria-hidden="true" class="pagination-label t-prev-label">Prev</span>
          <span class="visuallyhidden">Previous Chapter</span>
          <div class="pagination-title t-prev-title">7. Ensemble Learning and Random Forests</div>
        </a>
    
  
  </div>

  <div class="t-sbo-next sbo-next sbo-nav-top">
  
    
      
        <a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch09.html" class="next nav-link">
      
          <span aria-hidden="true" class="pagination-label t-next-label">Next</span>
          <span class="visuallyhidden">Next Chapter</span>
          <div class="pagination-title t-next-title">9. Unsupervised Learning Techniques</div>
        </a>
    
  
  </div>



<div id="sbo-rt-content"><div class="annotator-wrapper"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 8. Dimensionality Reduction"><div class="chapter" id="dimensionality_chapter">
<h1><span class="label">Chapter 8. </span>Dimensionality Reduction</h1>


<p>Many Machine Learning problems involve thousands or even millions of features for each training instance. Not only do all these features make training extremely slow, they can also make it much harder to find a good solution, as we will see. This problem is often referred to as the <em>curse of dimensionality</em>.</p>

<p>Fortunately, in real-world problems, it is often possible to reduce the number of features considerably, turning an intractable problem into a tractable one. For example, consider the MNIST images (introduced in <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch03.html#classification_chapter">Chapter&nbsp;3</a>): the pixels on the image borders are almost always white, so you could completely drop these pixels from the training set without losing much information. <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch07.html#mnist_feature_importance_plot">Figure&nbsp;7-6</a> confirms that these pixels are utterly unimportant for the classification task. Moreover, two neighboring pixels are often highly correlated: if you merge them into a single pixel (e.g., by taking the mean of the two pixel intensities), you will not lose much information.</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>Reducing dimensionality does lose some information (just like compressing an image to JPEG can degrade its quality), so even though it will speed up training, it may also make your system perform slightly worse. It also makes your pipelines a bit more complex and thus harder to maintain. So, if training is too slow, you should first try to train your system with the original data before considering using dimensionality reduction. In some cases, however, reducing the dimensionality of the training data may filter out some noise and unnecessary details and thus result in higher performance (but in general it won’t; it will just speed up training).</p>
</div>

<p>Apart from speeding up training, dimensionality reduction is also extremely useful for data visualization (or <em>DataViz</em>). Reducing the number of dimensions down to two (or three) makes it possible to plot a condensed view of a high-dimensional training set on a graph and often gain some important insights by visually detecting patterns, such as clusters. Moreover, DataViz is essential to communicate your conclusions to people who are not data scientists, in particular decision makers who will use your results.</p>

<p>In this chapter we will discuss the curse of dimensionality and get a sense of what goes on in high-dimensional space. Then, we will present the two main approaches to dimensionality reduction (projection and Manifold Learning), and we will go through three of the most popular dimensionality reduction techniques: PCA, Kernel PCA, and LLE.</p>






<section data-type="sect1" data-pdf-bookmark="The Curse of Dimensionality"><div class="sect1" id="idm46263521550248">
<h1>The Curse of Dimensionality</h1>

<p>We are so used to living in three dimensions<sup><a data-type="noteref" id="idm46263521548712-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#idm46263521548712" class="totri-footnote">1</a></sup> that our intuition fails us when we try to imagine a high-dimensional space. Even a basic 4D hypercube is incredibly hard to picture in our mind (see <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#hypercube_wikipedia">Figure&nbsp;8-1</a>), let alone a 200-dimensional ellipsoid bent in a 1,000-dimensional space.</p>

<figure><div id="hypercube_wikipedia" class="figure">
<img src="./Chapter8_files/mls2_0801.png" alt="mls2 0801" width="1153" height="381" data-mfp-src="/library/view/hands-on-machine-learning/9781492032632/assets/mls2_0801.png">
<h6><span class="label">Figure 8-1. </span>Point, segment, square, cube, and tesseract (0D to 4D hypercubes)<sup><a data-type="noteref" id="idm46263521545256-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#idm46263521545256" class="totri-footnote">2</a></sup></h6>
</div></figure>

<p>It turns out that many things behave very differently in high-dimensional space. For example, if you pick a random point in a unit square (a 1 × 1 square), it will have only about a 0.4% chance of being located less than 0.001 from a border (in other words, it is very unlikely that a random point will be “extreme” along any dimension). But in a 10,000-dimensional unit hypercube, this probability is greater than 99.999999%. Most points in a high-dimensional hypercube are very close to the border.<sup><a data-type="noteref" id="idm46263521540504-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#idm46263521540504" class="totri-footnote">3</a></sup></p>

<p>Here is a more troublesome difference: if you pick two points randomly in a unit square, the distance between these two points will be, on average, roughly 0.52. If you pick two random points in a unit 3D cube, the average distance will be roughly 0.66. But what about two points picked randomly in a 1,000,000-dimensional hypercube? Well, the average distance, believe it or not, will be about 408.25 (roughly <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-94-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; alttext=&quot;StartRoot 1 comma 000 comma 000 slash 6 EndRoot&quot;&gt;&lt;msqrt&gt;&lt;mrow&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;000&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;000&lt;/mn&gt;&lt;mo&gt;/&lt;/mo&gt;&lt;mn&gt;6&lt;/mn&gt;&lt;/mrow&gt;&lt;/msqrt&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-3888" aria-label="StartRoot 1 comma 000 comma 000 slash 6 EndRoot" style="width: 6.584em; display: inline-block;"><span style="display: inline-block; position: relative; width: 6.378em; height: 0px; font-size: 103%;"><span style="position: absolute; clip: rect(1.082em, 1006.39em, 2.625em, -1000.01em); top: -2.105em; left: 0em;"><span class="mrow" id="MathJax-Span-3889"><span class="msqrt" id="MathJax-Span-3890"><span style="display: inline-block; position: relative; width: 6.378em; height: 0px;"><span style="position: absolute; clip: rect(3.087em, 1005.31em, 4.424em, -1000.01em); top: -4.008em; left: 0.979em;"><span class="mrow" id="MathJax-Span-3891"><span class="mrow" id="MathJax-Span-3892"><span class="mn" id="MathJax-Span-3893" style="font-family: MathJax_Main;">1</span><span class="mo" id="MathJax-Span-3894" style="font-family: MathJax_Main;">,</span><span class="mn" id="MathJax-Span-3895" style="font-family: MathJax_Main; padding-left: 0.157em;">000</span><span class="mo" id="MathJax-Span-3896" style="font-family: MathJax_Main;">,</span><span class="mn" id="MathJax-Span-3897" style="font-family: MathJax_Main; padding-left: 0.157em;">000</span><span class="mo" id="MathJax-Span-3898" style="font-family: MathJax_Main;">/</span><span class="mn" id="MathJax-Span-3899" style="font-family: MathJax_Main;">6</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.602em, 1005.41em, 3.961em, -1000.01em); top: -4.573em; left: 0.979em;"><span style="display: inline-block; position: relative; width: 5.401em; height: 0px;"><span style="position: absolute; font-family: MathJax_Main; top: -4.008em; left: -0.1em;">−<span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; font-family: MathJax_Main; top: -4.008em; left: 4.681em;">−<span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -4.008em; left: 0.414em;">−<span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -4.008em; left: 0.979em;">−<span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -4.008em; left: 1.494em;">−<span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -4.008em; left: 2.008em;">−<span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -4.008em; left: 2.573em;">−<span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -4.008em; left: 3.087em;">−<span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -4.008em; left: 3.653em;">−<span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -4.008em; left: 4.167em;">−<span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(2.985em, 1001.04em, 4.527em, -1000.01em); top: -4.008em; left: 0em;"><span style="font-family: MathJax_Size1;">√</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.111em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.421em; border-left: 0px solid; width: 0px; height: 1.327em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="StartRoot 1 comma 000 comma 000 slash 6 EndRoot"><msqrt><mrow><mn>1</mn><mo>,</mo><mn>000</mn><mo>,</mo><mn>000</mn><mo>/</mo><mn>6</mn></mrow></msqrt></math></span></span><script type="math/mml" id="MathJax-Element-94"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="StartRoot 1 comma 000 comma 000 slash 6 EndRoot">
  <msqrt>
    <mrow>
      <mn>1</mn>
      <mo>,</mo>
      <mn>000</mn>
      <mo>,</mo>
      <mn>000</mn>
      <mo>/</mo>
      <mn>6</mn>
    </mrow>
  </msqrt>
</math></script>)! This is counterintuitive: how can two points be so far apart when they both lie within the same unit hypercube? Well, there’s just plenty of space in high dimensions. As a result, high-dimensional datasets are at risk of being very sparse: most training instances are likely to be far away from each other. This also means that a new instance will likely be far away from any training instance, making predictions much less reliable than in lower dimensions, since they will be based on much larger extrapolations. In short, the more dimensions the training set has, the greater the risk of overfitting it.</p>

<p>In theory, one solution to the curse of dimensionality could be to increase the size of the training set to reach a sufficient density of training instances. Unfortunately, in practice, the number of training instances required to reach a given density grows exponentially with the number of dimensions. With just 100 features (significantly fewer than in the MNIST problem), you would need more training instances than atoms in the observable universe in order for training instances to be within 0.1 of each other on average, assuming they were spread out uniformly across all dimensions.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Main Approaches for Dimensionality Reduction"><div class="sect1" id="idm46263521532248">
<h1>Main Approaches for Dimensionality Reduction</h1>

<p>Before we dive into specific dimensionality reduction algorithms, let’s take a look at the two main approaches to reducing dimensionality: projection and Manifold Learning.</p>








<section data-type="sect2" data-pdf-bookmark="Projection"><div class="sect2" id="idm46263521530632">
<h2>Projection</h2>

<p>In most real-world problems, training instances are <em>not</em> spread out uniformly across all dimensions. Many features are almost constant, while others are highly correlated (as discussed earlier for MNIST). As a result, all training instances lie within (or close to) a much lower-dimensional <em>subspace</em> of the high-dimensional space. This sounds very abstract, so let’s look at an example. In <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#dataset_3d_plot">Figure&nbsp;8-2</a> you can see a 3D dataset represented by the circles.</p>

<figure class="smallerseventyfive"><div id="dataset_3d_plot" class="figure">
<img src="./Chapter8_files/mls2_0802.png" alt="mls2 0802" width="1440" height="937" data-mfp-src="/library/view/hands-on-machine-learning/9781492032632/assets/mls2_0802.png">
<h6><span class="label">Figure 8-2. </span>A 3D dataset lying close to a 2D subspace</h6>
</div></figure>

<p>Notice that all training instances lie close to a plane: this is a lower-dimensional (2D) subspace of the high-dimensional (3D) space. If we project every training instance perpendicularly onto this subspace (as represented by the short lines connecting the instances to the plane), we get the new 2D dataset shown in <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#dataset_2d_plot">Figure&nbsp;8-3</a>. Ta-da! We have just reduced the dataset’s dimensionality from 3D to 2D. Note that the axes correspond to new features <em>z</em><sub>1</sub> and <em>z</em><sub>2</sub> (the coordinates of the projections on the plane).</p>

<figure class="smallersixty"><div id="dataset_2d_plot" class="figure">
<img src="./Chapter8_files/mls2_0803.png" alt="mls2 0803" width="1278" height="1084" data-mfp-src="/library/view/hands-on-machine-learning/9781492032632/assets/mls2_0803.png">
<h6><span class="label">Figure 8-3. </span>The new 2D dataset after projection</h6>
</div></figure>

<p>However, projection is not always the best approach to dimensionality reduction. In many cases the subspace may twist and turn, such as in the famous <em>Swiss roll</em> toy dataset represented in <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#swiss_roll_plot">Figure&nbsp;8-4</a>.</p>

<figure class="smallerseventyfive"><div id="swiss_roll_plot" class="figure">
<img src="./Chapter8_files/mls2_0804.png" alt="mls2 0804" width="1423" height="1096" data-mfp-src="/library/view/hands-on-machine-learning/9781492032632/assets/mls2_0804.png">
<h6><span class="label">Figure 8-4. </span>Swiss roll dataset</h6>
</div></figure>

<p>Simply projecting onto a plane (e.g., by dropping <em>x</em><sub>3</sub>) would squash different layers of the Swiss roll together, as shown in the left side of <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#squished_swiss_roll_plot">Figure&nbsp;8-5</a>. What you really want is to unroll the Swiss roll to obtain the 2D dataset in the right side of <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#squished_swiss_roll_plot">Figure&nbsp;8-5</a>.</p>

<figure><div id="squished_swiss_roll_plot" class="figure">
<img src="./Chapter8_files/mls2_0805.png" alt="mls2 0805" width="1439" height="488" data-mfp-src="/library/view/hands-on-machine-learning/9781492032632/assets/mls2_0805.png">
<h6><span class="label">Figure 8-5. </span>Squashing by projecting onto a plane (left) versus unrolling the Swiss roll (right)</h6>
</div></figure>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Manifold Learning"><div class="sect2" id="idm46263521509880">
<h2>Manifold Learning</h2>

<p>The Swiss roll is an example of a 2D <em>manifold</em>. Put simply, a 2D manifold is a 2D shape that can be bent and twisted in a higher-dimensional space. More generally, a <em>d</em>-dimensional manifold is a part of an <em>n</em>-dimensional space (where <em>d</em> &lt; <em>n</em>) that locally resembles a <em>d</em>-dimensional hyperplane. In the case of the Swiss roll, <em>d</em> = 2 and <em>n</em> = 3: it locally resembles a 2D plane, but it is rolled in the third dimension.</p>

<p>Many dimensionality reduction algorithms work by modeling the <em>manifold</em> on which the training instances lie; this is called <em>Manifold Learning</em>. It relies on the <em>manifold assumption</em>, also called the <em>manifold hypothesis</em>, which holds that most real-world high-dimensional datasets lie close to a much lower-dimensional manifold. This assumption is very often empirically observed.</p>

<p>Once again, think about the MNIST dataset: all handwritten digit images have some similarities. They are made of connected lines, the borders are white, and they are more or less centered. If you randomly generated images, only a ridiculously tiny fraction of them would look like handwritten digits. In other words, the degrees of freedom available to you if you try to create a digit image are dramatically lower than the degrees of freedom you would have if you were allowed to generate any image you wanted. These constraints tend to squeeze the dataset into a lower-dimensional manifold.</p>

<p>The manifold assumption is often accompanied by another implicit assumption: that the task at hand (e.g., classification or regression) will be simpler if expressed in the lower-dimensional space of the manifold. For example, in the top row of <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#manifold_decision_boundary_plot">Figure&nbsp;8-6</a> the Swiss roll is split into two classes: in the 3D space (on the left), the decision boundary would be fairly complex; but in the 2D unrolled manifold space (on the right), the decision boundary is a straight line.</p>

<p>However, this implicit assumption does not always hold. For example, in the bottom row of <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#manifold_decision_boundary_plot">Figure&nbsp;8-6</a>, the decision boundary is located at <em>x</em><sub>1</sub> = 5. This decision boundary looks very simple in the original 3D space (a vertical plane), but it looks more complex in the unrolled manifold (a collection of four independent line segments).</p>

<p>In short, reducing the dimensionality of your training set before training a model will usually speed up training, but it may not always lead to a better or simpler solution; it all depends on the dataset.</p>

<p>Hopefully you now have a good sense of what the curse of dimensionality is and how dimensionality reduction algorithms can fight it, especially when the manifold assumption holds. The rest of this chapter will go through some of the most popular algorithms.</p>

<figure><div id="manifold_decision_boundary_plot" class="figure">
<img src="./Chapter8_files/mls2_0806.png" alt="mls2 0806" width="1441" height="1086" data-mfp-src="/library/view/hands-on-machine-learning/9781492032632/assets/mls2_0806.png">
<h6><span class="label">Figure 8-6. </span>The decision boundary may not always be simpler with lower dimensions</h6>
</div></figure>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="PCA"><div class="sect1" id="idm46263521493688">
<h1>PCA</h1>

<p><em>Principal Component Analysis</em> (PCA) is by far the most popular dimensionality reduction algorithm. First it identifies the hyperplane that lies closest to the data, and then it projects the data onto it, just like in <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#dataset_3d_plot">Figure&nbsp;8-2</a>.</p>








<section data-type="sect2" data-pdf-bookmark="Preserving the Variance"><div class="sect2" id="idm46263521490456">
<h2>Preserving the Variance</h2>

<p>Before you can project the training set onto a lower-dimensional hyperplane, you first need to choose the right hyperplane. For example, a simple 2D dataset is represented on the left of <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#pca_best_projection_plot">Figure&nbsp;8-7</a>, along with three different axes (i.e., 1D hyperplanes). On the right is the result of the projection of the dataset onto each of these axes. As you can see, the projection onto the solid line preserves the maximum variance, while the projection onto the dotted line preserves very little variance, and the projection onto the dashed line preserves an intermediate amount of variance.</p>

<figure><div id="pca_best_projection_plot" class="figure">
<img src="./Chapter8_files/mls2_0807.png" alt="mls2 0807" width="1440" height="678" data-mfp-src="/library/view/hands-on-machine-learning/9781492032632/assets/mls2_0807.png">
<h6><span class="label">Figure 8-7. </span>Selecting the subspace to project on</h6>
</div></figure>

<p>It seems reasonable to select the axis that preserves the maximum amount of variance, as it will most likely lose less information than the other projections. Another way to justify this choice is that it is the axis that minimizes the mean squared distance between the original dataset and its projection onto that axis. This is the rather simple idea behind <a class="orm:hideurl" href="https://www.tandfonline.com/doi/pdf/10.1080/14786440109462720">PCS</a>.<sup><a data-type="noteref" id="idm46263521483912-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#idm46263521483912" class="totri-footnote">4</a></sup></p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Principal Components"><div class="sect2" id="idm46263521481704">
<h2>Principal Components</h2>

<p>PCA identifies the axis that accounts for the largest amount of variance in the training set. In <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#pca_best_projection_plot">Figure&nbsp;8-7</a>, it is the solid line. It also finds a second axis, orthogonal to the first one, that accounts for the largest amount of remaining variance. In this 2D example there is no choice: it is the dotted line. If it were a higher-dimensional dataset, PCA would also find a third axis, orthogonal to both previous axes, and a fourth, a fifth, and so on—as many axes as the number of dimensions in the dataset.</p>

<p>The <em>i</em><sup>th</sup> axis is called the <em>i</em><sup>th</sup> <em>principal component</em> (PC) of the data. In <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#pca_best_projection_plot">Figure&nbsp;8-7</a>, the first PC is the axis on which vector <strong>c</strong><sub><strong>1</strong></sub> lies, and the second PC is the axis on which vector <strong>c</strong><sub><strong>2</strong></sub> lies. In <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#dataset_3d_plot">Figure&nbsp;8-2</a> the first two PCs are the orthogonal axes on which the two arrows lie, on the plane, and the third PC is the axis orthogonal to that plane.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>For each principal component, PCA finds a zero-centered unit vector pointing in the direction of the PC. Since two opposing unit vectors lie on the same axis, the direction of the unit vectors returned by PCA is not stable: if you perturb the training set slightly and run PCA again, the unit vectors may point in the opposite direction as the original vectors. However, they will generally still lie on the same axes. In some cases, a pair of unit vectors may even rotate or swap (if the variance along these two axes are close), but the plane they define will generally remain the same.</p>
</div>

<p>So how can you find the principal components of a training set? Luckily, there is a standard matrix factorization technique called <em>Singular Value Decomposition</em> (SVD) that can decompose the training set matrix <strong>X</strong> into the matrix multiplication of three matrices <strong>U</strong> <strong>Σ</strong> <strong>V</strong><sup><em>T</em></sup>, where <strong>V</strong> contains the unit vectors that define all the principal components that we are looking for, as shown in <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#principal_components_matrix">Equation 8-1</a>.</p>
<div class="fifty-percent" id="principal_components_matrix" data-type="equation"><h5><span class="label">Equation 8-1. </span>Principal components matrix</h5>
<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-95-Frame" tabindex="0" style="text-align: center; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;V&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mfenced open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;mtable&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mo&gt;&amp;#x2223;&lt;/mo&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mo&gt;&amp;#x2223;&lt;/mo&gt;&lt;/mtd&gt;&lt;mtd /&gt;&lt;mtd&gt;&lt;mo&gt;&amp;#x2223;&lt;/mo&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;msub&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;c&lt;/mi&gt;&lt;mn mathvariant=&quot;bold&quot;&gt;1&lt;/mn&gt;&lt;/msub&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;msub&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;c&lt;/mi&gt;&lt;mn mathvariant=&quot;bold&quot;&gt;2&lt;/mn&gt;&lt;/msub&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mo&gt;&amp;#x22EF;&lt;/mo&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;msub&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;c&lt;/mi&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;n&lt;/mi&gt;&lt;/msub&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd&gt;&lt;mo&gt;&amp;#x2223;&lt;/mo&gt;&lt;/mtd&gt;&lt;mtd&gt;&lt;mo&gt;&amp;#x2223;&lt;/mo&gt;&lt;/mtd&gt;&lt;mtd /&gt;&lt;mtd&gt;&lt;mo&gt;&amp;#x2223;&lt;/mo&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;/mtable&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-3900" style="width: 11.159em; display: inline-block;"><span style="display: inline-block; position: relative; width: 10.8em; height: 0px; font-size: 103%;"><span style="position: absolute; clip: rect(1.956em, 1010.5em, 6.224em, -1000.01em); top: -4.316em; left: 0em;"><span class="mrow" id="MathJax-Span-3901"><span class="mrow" id="MathJax-Span-3902"><span class="mi" id="MathJax-Span-3903" style="font-family: MathJax_Main-bold;">V</span><span class="mo" id="MathJax-Span-3904" style="font-family: MathJax_Main; padding-left: 0.26em;">=</span><span class="mfenced" id="MathJax-Span-3905" style="padding-left: 0.26em;"><span class="mo" id="MathJax-Span-3906" style="vertical-align: 2.213em;"><span style="display: inline-block; position: relative; width: 0.877em; height: 0px;"><span style="position: absolute; font-family: MathJax_Size4; top: -2.877em; left: 0em;">⎛<span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; font-family: MathJax_Size4; top: -0.717em; left: 0em;">⎝<span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="font-family: MathJax_Size4; position: absolute; top: -1.746em; left: 0em;">⎜<span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mtable" id="MathJax-Span-3907" style="padding-right: 0.157em; padding-left: 0.157em;"><span style="display: inline-block; position: relative; width: 6.584em; height: 0px;"><span style="position: absolute; clip: rect(2.573em, 1000.99em, 6.789em, -1000.01em); top: -4.882em; left: 0em;"><span style="display: inline-block; position: relative; width: 0.979em; height: 0px;"><span style="position: absolute; clip: rect(3.087em, 1000.16em, 4.424em, -1000.01em); top: -5.447em; left: 50%; margin-left: -0.152em;"><span class="mtd" id="MathJax-Span-3908"><span class="mrow" id="MathJax-Span-3909"><span class="mo" id="MathJax-Span-3910" style="font-family: MathJax_Main;">∣</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.396em, 1000.99em, 4.321em, -1000.01em); top: -3.956em; left: 50%; margin-left: -0.512em;"><span class="mtd" id="MathJax-Span-3919"><span class="mrow" id="MathJax-Span-3920"><span class="msub" id="MathJax-Span-3921"><span style="display: inline-block; position: relative; width: 0.979em; height: 0px;"><span style="position: absolute; clip: rect(3.396em, 1000.47em, 4.167em, -1000.01em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-3922" style="font-family: MathJax_Main-bold;">c</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.854em; left: 0.517em;"><span class="mn" id="MathJax-Span-3923" style="font-size: 70.7%; font-family: MathJax_Main-bold;">1</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.087em, 1000.16em, 4.424em, -1000.01em); top: -2.517em; left: 50%; margin-left: -0.152em;"><span class="mtd" id="MathJax-Span-3937"><span class="mrow" id="MathJax-Span-3938"><span class="mo" id="MathJax-Span-3939" style="font-family: MathJax_Main;">∣</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.887em;"></span></span><span style="position: absolute; clip: rect(2.573em, 1000.99em, 6.789em, -1000.01em); top: -4.882em; left: 1.802em;"><span style="display: inline-block; position: relative; width: 0.979em; height: 0px;"><span style="position: absolute; clip: rect(3.087em, 1000.16em, 4.424em, -1000.01em); top: -5.447em; left: 50%; margin-left: -0.152em;"><span class="mtd" id="MathJax-Span-3911"><span class="mrow" id="MathJax-Span-3912"><span class="mo" id="MathJax-Span-3913" style="font-family: MathJax_Main;">∣</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.396em, 1000.99em, 4.321em, -1000.01em); top: -3.956em; left: 50%; margin-left: -0.512em;"><span class="mtd" id="MathJax-Span-3924"><span class="mrow" id="MathJax-Span-3925"><span class="msub" id="MathJax-Span-3926"><span style="display: inline-block; position: relative; width: 0.979em; height: 0px;"><span style="position: absolute; clip: rect(3.396em, 1000.47em, 4.167em, -1000.01em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-3927" style="font-family: MathJax_Main-bold;">c</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.854em; left: 0.517em;"><span class="mn" id="MathJax-Span-3928" style="font-size: 70.7%; font-family: MathJax_Main-bold;">2</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.087em, 1000.16em, 4.424em, -1000.01em); top: -2.517em; left: 50%; margin-left: -0.152em;"><span class="mtd" id="MathJax-Span-3940"><span class="mrow" id="MathJax-Span-3941"><span class="mo" id="MathJax-Span-3942" style="font-family: MathJax_Main;">∣</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.887em;"></span></span><span style="position: absolute; clip: rect(2.419em, 1001.09em, 5.658em, -1000.01em); top: -4.008em; left: 3.602em;"><span style="display: inline-block; position: relative; width: 1.185em; height: 0px;"><span style="position: absolute; clip: rect(3.859em, 1000.01em, 4.167em, -1000.01em); top: -5.447em; left: 50%; margin-left: 0em;"><span class="mtd" id="MathJax-Span-3914"><span class="mrow" id="MathJax-Span-3915"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.55em, 1001.09em, 3.961em, -1000.01em); top: -3.956em; left: 50%; margin-left: -0.563em;"><span class="mtd" id="MathJax-Span-3929"><span class="mrow" id="MathJax-Span-3930"><span class="mo" id="MathJax-Span-3931" style="font-family: MathJax_Main;">⋯</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.859em, 1000.01em, 4.167em, -1000.01em); top: -2.517em; left: 50%; margin-left: 0em;"><span class="mtd" id="MathJax-Span-3943"><span class="mrow" id="MathJax-Span-3944"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(2.573em, 1001.04em, 6.789em, -1000.01em); top: -4.882em; left: 5.555em;"><span style="display: inline-block; position: relative; width: 1.031em; height: 0px;"><span style="position: absolute; clip: rect(3.087em, 1000.16em, 4.424em, -1000.01em); top: -5.447em; left: 50%; margin-left: -0.152em;"><span class="mtd" id="MathJax-Span-3916"><span class="mrow" id="MathJax-Span-3917"><span class="mo" id="MathJax-Span-3918" style="font-family: MathJax_Main;">∣</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.396em, 1001.04em, 4.321em, -1000.01em); top: -3.956em; left: 50%; margin-left: -0.512em;"><span class="mtd" id="MathJax-Span-3932"><span class="mrow" id="MathJax-Span-3933"><span class="msub" id="MathJax-Span-3934"><span style="display: inline-block; position: relative; width: 1.031em; height: 0px;"><span style="position: absolute; clip: rect(3.396em, 1000.47em, 4.167em, -1000.01em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-3935" style="font-family: MathJax_Main-bold;">c</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.854em; left: 0.517em;"><span class="mi" id="MathJax-Span-3936" style="font-size: 70.7%; font-family: MathJax_Main-bold;">n</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.087em, 1000.16em, 4.424em, -1000.01em); top: -2.517em; left: 50%; margin-left: -0.152em;"><span class="mtd" id="MathJax-Span-3945"><span class="mrow" id="MathJax-Span-3946"><span class="mo" id="MathJax-Span-3947" style="font-family: MathJax_Main;">∣</span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.887em;"></span></span></span></span><span class="mo" id="MathJax-Span-3948" style="vertical-align: 2.213em;"><span style="display: inline-block; position: relative; width: 0.877em; height: 0px;"><span style="position: absolute; font-family: MathJax_Size4; top: -2.877em; left: 0em;">⎞<span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; font-family: MathJax_Size4; top: -0.717em; left: 0em;">⎠<span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="font-family: MathJax_Size4; position: absolute; top: -1.746em; left: 0em;">⎟<span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.321em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.851em; border-left: 0px solid; width: 0px; height: 4.186em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mi mathvariant="bold">V</mi><mo>=</mo><mfenced open="(" close=")"><mtable><mtr><mtd><mo>∣</mo></mtd><mtd><mo>∣</mo></mtd><mtd></mtd><mtd><mo>∣</mo></mtd></mtr><mtr><mtd><msub><mi mathvariant="bold">c</mi><mn mathvariant="bold">1</mn></msub></mtd><mtd><msub><mi mathvariant="bold">c</mi><mn mathvariant="bold">2</mn></msub></mtd><mtd><mo>⋯</mo></mtd><mtd><msub><mi mathvariant="bold">c</mi><mi mathvariant="bold">n</mi></msub></mtd></mtr><mtr><mtd><mo>∣</mo></mtd><mtd><mo>∣</mo></mtd><mtd></mtd><mtd><mo>∣</mo></mtd></mtr></mtable></mfenced></mrow></math></span></span></div><script type="math/mml" id="MathJax-Element-95"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mrow>
    <mi mathvariant="bold">V</mi>
    <mo>=</mo>
    <mfenced open="(" close=")">
      <mtable>
        <mtr>
          <mtd>
            <mo>∣</mo>
          </mtd>
          <mtd>
            <mo>∣</mo>
          </mtd>
          <mtd></mtd>
          <mtd>
            <mo>∣</mo>
          </mtd>
        </mtr>
        <mtr>
          <mtd>
            <msub><mi mathvariant="bold">c</mi> <mn mathvariant="bold">1</mn> </msub>
          </mtd>
          <mtd>
            <msub><mi mathvariant="bold">c</mi> <mn mathvariant="bold">2</mn> </msub>
          </mtd>
          <mtd>
            <mo>⋯</mo>
          </mtd>
          <mtd>
            <msub><mi mathvariant="bold">c</mi> <mi mathvariant="bold">n</mi> </msub>
          </mtd>
        </mtr>
        <mtr>
          <mtd>
            <mo>∣</mo>
          </mtd>
          <mtd>
            <mo>∣</mo>
          </mtd>
          <mtd></mtd>
          <mtd>
            <mo>∣</mo>
          </mtd>
        </mtr>
      </mtable>
    </mfenced>
  </mrow>
</math></script>
</div>

<p>The following Python code uses NumPy’s <code>svd()</code> function to obtain all the principal components of the training set, then extracts the two unit vectors that define the first two PCs:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">X_centered</code> <code class="o">=</code> <code class="n">X</code> <code class="o">-</code> <code class="n">X</code><code class="o">.</code><code class="n">mean</code><code class="p">(</code><code class="n">axis</code><code class="o">=</code><code class="mi">0</code><code class="p">)</code>
<code class="n">U</code><code class="p">,</code> <code class="n">s</code><code class="p">,</code> <code class="n">Vt</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">linalg</code><code class="o">.</code><code class="n">svd</code><code class="p">(</code><code class="n">X_centered</code><code class="p">)</code>
<code class="n">c1</code> <code class="o">=</code> <code class="n">Vt</code><code class="o">.</code><code class="n">T</code><code class="p">[:,</code> <code class="mi">0</code><code class="p">]</code>
<code class="n">c2</code> <code class="o">=</code> <code class="n">Vt</code><code class="o">.</code><code class="n">T</code><code class="p">[:,</code> <code class="mi">1</code><code class="p">]</code></pre>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>PCA assumes that the dataset is centered around the origin. As we will see, Scikit-Learn’s PCA classes take care of centering the data for you. If you implement PCA yourself (as in the preceding example), or if you use other libraries, don’t forget to center the data first.</p>
</div>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Projecting Down to d Dimensions"><div class="sect2" id="idm46263521401528">
<h2>Projecting Down to d Dimensions</h2>

<p>Once you have identified all the principal components, you can reduce the dimensionality of the dataset down to <em>d</em> dimensions by projecting it onto the hyperplane defined by the first <em>d</em> principal components. Selecting this hyperplane ensures that the projection will preserve as much variance as possible. For example, in <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#dataset_3d_plot">Figure&nbsp;8-2</a> the 3D dataset is projected down to the 2D plane defined by the first two principal components, preserving a large part of the dataset’s variance. As a result, the 2D projection looks very much like the original 3D dataset.</p>

<p>To project the training set onto the hyperplane and obtain a reduced dataset <strong>X</strong><sub><em>d</em>-proj</sub> of dimensionality <em>d</em>, compute the matrix multiplication of the training set matrix <strong>X</strong> by the matrix <strong>W</strong><sub><em>d</em></sub>, defined as the matrix containing the first <em>d</em> columns of <strong>V</strong>, as shown in <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#pca_projection">Equation 8-2</a>.</p>
<div class="fifty-percent" id="pca_projection" data-type="equation"><h5><span class="label">Equation 8-2. </span>Projecting the training set down to <em>d</em> dimensions</h5>
<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-96-Frame" tabindex="0" style="text-align: center; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;X&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mtext&gt;-proj&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;X&lt;/mi&gt;&lt;msub&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;W&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-3949" style="width: 6.789em; display: inline-block;"><span style="display: inline-block; position: relative; width: 6.584em; height: 0px; font-size: 103%;"><span style="position: absolute; clip: rect(1.339em, 1006.59em, 2.625em, -1000.01em); top: -2.157em; left: 0em;"><span class="mrow" id="MathJax-Span-3950"><span class="mrow" id="MathJax-Span-3951"><span class="msub" id="MathJax-Span-3952"><span style="display: inline-block; position: relative; width: 2.779em; height: 0px;"><span style="position: absolute; clip: rect(3.19em, 1000.83em, 4.167em, -1000.01em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-3953" style="font-family: MathJax_Main-bold;">X</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.854em; left: 0.877em;"><span class="mrow" id="MathJax-Span-3954"><span class="mi" id="MathJax-Span-3955" style="font-size: 70.7%; font-family: MathJax_Math-italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mtext" id="MathJax-Span-3956" style="font-size: 70.7%; font-family: MathJax_Main;">-proj</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-3957" style="font-family: MathJax_Main; padding-left: 0.26em;">=</span><span class="mi" id="MathJax-Span-3958" style="font-family: MathJax_Main-bold; padding-left: 0.26em;">X</span><span class="msub" id="MathJax-Span-3959"><span style="display: inline-block; position: relative; width: 1.648em; height: 0px;"><span style="position: absolute; clip: rect(3.19em, 1001.14em, 4.167em, -1000.01em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-3960" style="font-family: MathJax_Main-bold;">W</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.854em; left: 1.185em;"><span class="mi" id="MathJax-Span-3961" style="font-size: 70.7%; font-family: MathJax_Math-italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.162em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.368em; border-left: 0px solid; width: 0px; height: 1.115em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><msub><mi mathvariant="bold">X</mi><mrow><mi>d</mi><mtext>-proj</mtext></mrow></msub><mo>=</mo><mi mathvariant="bold">X</mi><msub><mi mathvariant="bold">W</mi><mi>d</mi></msub></mrow></math></span></span></div><script type="math/mml" id="MathJax-Element-96"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mrow>
    <msub><mi mathvariant="bold">X</mi> <mrow><mi>d</mi><mtext>-proj</mtext></mrow> </msub>
    <mo>=</mo>
    <mi mathvariant="bold">X</mi>
    <msub><mi mathvariant="bold">W</mi> <mi>d</mi> </msub>
  </mrow>
</math></script></div>

<p>The following Python code projects the training set onto the plane defined by the first two principal components:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">W2</code> <code class="o">=</code> <code class="n">Vt</code><code class="o">.</code><code class="n">T</code><code class="p">[:,</code> <code class="p">:</code><code class="mi">2</code><code class="p">]</code>
<code class="n">X2D</code> <code class="o">=</code> <code class="n">X_centered</code><code class="o">.</code><code class="n">dot</code><code class="p">(</code><code class="n">W2</code><code class="p">)</code></pre>

<p>There you have it! You now know how to reduce the dimensionality of any dataset down to any number of dimensions, while preserving as much variance as possible.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Using Scikit-Learn"><div class="sect2" id="idm46263521376008">
<h2>Using Scikit-Learn</h2>

<p>Scikit-Learn’s <code>PCA</code> class uses SVD decomposition to implement PCA, just like we did earlier in this chapter. The following code applies PCA to reduce the dimensionality of the dataset down to two dimensions (note that it automatically takes care of centering the data):</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">sklearn.decomposition</code> <code class="kn">import</code> <code class="n">PCA</code>

<code class="n">pca</code> <code class="o">=</code> <code class="n">PCA</code><code class="p">(</code><code class="n">n_components</code> <code class="o">=</code> <code class="mi">2</code><code class="p">)</code>
<code class="n">X2D</code> <code class="o">=</code> <code class="n">pca</code><code class="o">.</code><code class="n">fit_transform</code><code class="p">(</code><code class="n">X</code><code class="p">)</code></pre>

<p>After fitting the <code>PCA</code> transformer to the dataset, its <code>components_</code> attribute holds the transpose of <strong>W</strong><sub><em>d</em></sub> (e.g., the unit vector that defines the first principal component is equal to <code>pca.components_.T[:, 0]</code>).</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Explained Variance Ratio"><div class="sect2" id="idm46263521314600">
<h2>Explained Variance Ratio</h2>

<p>Another useful piece of information is the <em>explained variance ratio</em> of each principal component, available via the <code>explained_variance_ratio_</code> variable. The ratio indicates the proportion of the dataset’s variance that lies along each principal component. For example, let’s look at the explained variance ratios of the first two components of the 3D dataset represented in <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#dataset_3d_plot">Figure&nbsp;8-2</a>:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">pca</code><code class="o">.</code><code class="n">explained_variance_ratio_</code>
<code class="go">array([0.84248607, 0.14631839])</code></pre>

<p>This output tells you that 84.2% of the dataset’s variance lies along the first PC, and 14.6% lies along the second PC. This leaves less than 1.2% for the third PC, so it is reasonable to assume that the third PC probably carries little information.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Choosing the Right Number of Dimensions"><div class="sect2" id="idm46263521268776">
<h2>Choosing the Right Number of Dimensions</h2>

<p>Instead of arbitrarily choosing the number of dimensions to reduce down to, it is simpler to choose the number of dimensions that add up to a sufficiently large portion of the variance (e.g., 95%). Unless, of course, you are reducing dimensionality for data visualization—in that case you will want to reduce the dimensionality down to 2 or 3.</p>

<p>The following code computes PCA without reducing dimensionality, then computes the minimum number of dimensions required to preserve 95% of the training set’s variance:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">pca</code> <code class="o">=</code> <code class="n">PCA</code><code class="p">()</code>
<code class="n">pca</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train</code><code class="p">)</code>
<code class="n">cumsum</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">cumsum</code><code class="p">(</code><code class="n">pca</code><code class="o">.</code><code class="n">explained_variance_ratio_</code><code class="p">)</code>
<code class="n">d</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">argmax</code><code class="p">(</code><code class="n">cumsum</code> <code class="o">&gt;=</code> <code class="mf">0.95</code><code class="p">)</code> <code class="o">+</code> <code class="mi">1</code></pre>

<p>You could then set <code>n_components=d</code> and run PCA again. But there is a much better option: instead of specifying the number of principal components you want to preserve, you can set <code>n_components</code> to be a float between <code>0.0</code> and <code>1.0</code>, indicating the ratio of variance you wish to preserve:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">pca</code> <code class="o">=</code> <code class="n">PCA</code><code class="p">(</code><code class="n">n_components</code><code class="o">=</code><code class="mf">0.95</code><code class="p">)</code>
<code class="n">X_reduced</code> <code class="o">=</code> <code class="n">pca</code><code class="o">.</code><code class="n">fit_transform</code><code class="p">(</code><code class="n">X_train</code><code class="p">)</code></pre>

<p>Yet another option is to plot the explained variance as a function of the number of dimensions (simply plot <code>cumsum</code>; see <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#explained_variance_plot">Figure&nbsp;8-8</a>). There will usually be an elbow in the curve, where the explained variance stops growing fast. In this case, you can see that reducing the dimensionality down to about 100 dimensions wouldn’t lose too much explained variance.</p>

<figure class="smallersixty"><div id="explained_variance_plot" class="figure">
<img src="./Chapter8_files/mls2_0808.png" alt="mls2 0808" width="1438" height="918" data-mfp-src="/library/view/hands-on-machine-learning/9781492032632/assets/mls2_0808.png">
<h6><span class="label">Figure 8-8. </span>Explained variance as a function of the number of dimensions</h6>
</div></figure>
</div></section>













<section data-type="sect2" data-pdf-bookmark="PCA for Compression"><div class="sect2" id="idm46263521131064">
<h2>PCA for Compression</h2>

<p>After dimensionality reduction, the training set takes up much less space. As an example, try applying PCA to the MNIST dataset while preserving 95% of its variance. You should find that each instance will have just over 150 features, instead of the original 784 features. So, while most of the variance is preserved, the dataset is now less than 20% of its original size! This is a reasonable compression ratio, and you can see how this size reduction can speed up a classification algorithm (such as an SVM classifier) tremendously.</p>

<p>It is also possible to decompress the reduced dataset back to 784 dimensions by applying the inverse transformation of the PCA projection. This won’t give you back the original data, since the projection lost a bit of information (within the 5% variance that was dropped), but it will likely be close to the original data. The mean squared distance between the original data and the reconstructed data (compressed and then decompressed) is called the <em>reconstruction error</em>. The following code compresses the MNIST dataset down to 154 dimensions, then uses the <code>inverse_transform()</code> method to decompress it back to 784 dimensions:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">pca</code> <code class="o">=</code> <code class="n">PCA</code><code class="p">(</code><code class="n">n_components</code> <code class="o">=</code> <code class="mi">154</code><code class="p">)</code>
<code class="n">X_reduced</code> <code class="o">=</code> <code class="n">pca</code><code class="o">.</code><code class="n">fit_transform</code><code class="p">(</code><code class="n">X_train</code><code class="p">)</code>
<code class="n">X_recovered</code> <code class="o">=</code> <code class="n">pca</code><code class="o">.</code><code class="n">inverse_transform</code><code class="p">(</code><code class="n">X_reduced</code><code class="p">)</code></pre>

<p><a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#mnist_compression_plot">Figure&nbsp;8-9</a> shows a few digits from the original training set (on the left), and the corresponding digits after compression and decompression. You can see that there is a slight image quality loss, but the digits are still mostly intact.</p>

<figure class="smallereighty"><div id="mnist_compression_plot" class="figure">
<img src="./Chapter8_files/mls2_0809.png" alt="mls2 0809" width="1439" height="723" data-mfp-src="/library/view/hands-on-machine-learning/9781492032632/assets/mls2_0809.png">
<h6><span class="label">Figure 8-9. </span>MNIST compression that preserves 95% of the variance</h6>
</div></figure>

<p>The equation of the inverse transformation is shown in <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#inverse_pca">Equation 8-3</a>.</p>
<div class="fifty-percent" id="inverse_pca" data-type="equation"><h5><span class="label">Equation 8-3. </span>PCA inverse transformation, back to the original number of dimensions</h5>
<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-97-Frame" tabindex="0" style="text-align: center; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;X&lt;/mi&gt;&lt;mtext&gt;recovered&lt;/mtext&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;msub&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;X&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;mtext&gt;-proj&lt;/mtext&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;msup&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;W&lt;/mi&gt;&lt;mi&gt;d&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-3962" style="width: 10.44em; display: inline-block;"><span style="display: inline-block; position: relative; width: 10.131em; height: 0px; font-size: 103%;"><span style="position: absolute; clip: rect(1.082em, 1010.14em, 2.573em, -1000.01em); top: -2.105em; left: 0em;"><span class="mrow" id="MathJax-Span-3963"><span class="mrow" id="MathJax-Span-3964"><span class="msub" id="MathJax-Span-3965"><span style="display: inline-block; position: relative; width: 3.859em; height: 0px;"><span style="position: absolute; clip: rect(3.19em, 1000.83em, 4.167em, -1000.01em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-3966" style="font-family: MathJax_Main-bold;">X</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.854em; left: 0.877em;"><span class="mtext" id="MathJax-Span-3967" style="font-size: 70.7%; font-family: MathJax_Main;">recovered</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-3968" style="font-family: MathJax_Main; padding-left: 0.26em;">=</span><span class="msub" id="MathJax-Span-3969" style="padding-left: 0.26em;"><span style="display: inline-block; position: relative; width: 2.779em; height: 0px;"><span style="position: absolute; clip: rect(3.19em, 1000.83em, 4.167em, -1000.01em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-3970" style="font-family: MathJax_Main-bold;">X</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.854em; left: 0.877em;"><span class="mrow" id="MathJax-Span-3971"><span class="mi" id="MathJax-Span-3972" style="font-size: 70.7%; font-family: MathJax_Math-italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mtext" id="MathJax-Span-3973" style="font-size: 70.7%; font-family: MathJax_Main;">-proj</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="msup" id="MathJax-Span-3974"><span style="display: inline-block; position: relative; width: 2.213em; height: 0px;"><span style="position: absolute; clip: rect(3.19em, 1001.66em, 4.321em, -1000.01em); top: -4.008em; left: 0em;"><span class="mrow" id="MathJax-Span-3975"><span class="msub" id="MathJax-Span-3976"><span style="display: inline-block; position: relative; width: 1.648em; height: 0px;"><span style="position: absolute; clip: rect(3.19em, 1001.14em, 4.167em, -1000.01em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-3977" style="font-family: MathJax_Main-bold;">W</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.854em; left: 1.185em;"><span class="mi" id="MathJax-Span-3978" style="font-size: 70.7%; font-family: MathJax_Math-italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -4.419em; left: 1.648em;"><span class="mi" id="MathJax-Span-3979" style="font-size: 70.7%; font-family: MathJax_Math-italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.105em;"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.111em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.368em; border-left: 0px solid; width: 0px; height: 1.327em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><msub><mi mathvariant="bold">X</mi><mtext>recovered</mtext></msub><mo>=</mo><msub><mi mathvariant="bold">X</mi><mrow><mi>d</mi><mtext>-proj</mtext></mrow></msub><msup><mrow><msub><mi mathvariant="bold">W</mi><mi>d</mi></msub></mrow><mi>T</mi></msup></mrow></math></span></span></div><script type="math/mml" id="MathJax-Element-97"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mrow>
    <msub><mi mathvariant="bold">X</mi> <mtext>recovered</mtext> </msub>
    <mo>=</mo>
    <msub><mi mathvariant="bold">X</mi> <mrow><mi>d</mi><mtext>-proj</mtext></mrow> </msub>
    <msup><mrow><msub><mi mathvariant="bold">W</mi> <mi>d</mi> </msub></mrow> <mi>T</mi> </msup>
  </mrow>
</math></script></div>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Randomized PCA"><div class="sect2" id="idm46263521130728">
<h2>Randomized PCA</h2>

<p>If you set the <code>svd_solver</code> hyperparameter to <code>"randomized"</code>, Scikit-Learn uses a stochastic algorithm called <em>Randomized PCA</em> that quickly finds an approximation of the first <em>d</em> principal components. Its computational complexity is <em>O</em>(<em>m</em> × <em>d</em><sup>2</sup>) + <em>O</em>(<em>d</em><sup>3</sup>), instead of <em>O</em>(<em>m</em> × <em>n</em><sup>2</sup>) + <em>O</em>(<em>n</em><sup>3</sup>) for the full SVD approach, so it is dramatically faster than full SVD when <em>d</em> is much smaller than <em>n</em>:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">rnd_pca</code> <code class="o">=</code> <code class="n">PCA</code><code class="p">(</code><code class="n">n_components</code><code class="o">=</code><code class="mi">154</code><code class="p">,</code> <code class="n">svd_solver</code><code class="o">=</code><code class="s2">"randomized"</code><code class="p">)</code>
<code class="n">X_reduced</code> <code class="o">=</code> <code class="n">rnd_pca</code><code class="o">.</code><code class="n">fit_transform</code><code class="p">(</code><code class="n">X_train</code><code class="p">)</code></pre>

<p>By default, <code>svd_solver</code> is actually set to <code>"auto"</code>: Scikit-Learn automatically uses the randomized PCA algorithm if <em>m</em> or <em>n</em> is greater than 500 and <em>d</em> is less than 80% of <em>m</em> or <em>n</em>, or else it uses the full SVD approach. If you want to force Scikit-Learn to use full SVD, you can set the <code>svd_solver</code> hyperparameter to <code>"full"</code>.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Incremental PCA"><div class="sect2" id="idm46263521031624">
<h2>Incremental PCA</h2>

<p>One problem with the preceding implementations of PCA is that they require the whole training set to fit in memory in order for the algorithm to run. Fortunately, <em>Incremental PCA</em> (IPCA) algorithms have been developed. They allow you to split the training set into mini-batches and feed an IPCA algorithm one mini-batch at a time. This is useful for large training sets and for applying PCA online (i.e., on the fly, as new instances arrive).</p>

<p>The following code splits the MNIST dataset into 100 mini-batches (using NumPy’s <code>array_split()</code> function) and feeds them to Scikit-Learn’s <a href="https://homl.info/32"><code>IncrementalPCA</code> class</a><sup><a data-type="noteref" id="idm46263521027480-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#idm46263521027480" class="totri-footnote">5</a></sup> to reduce the dimensionality of the MNIST dataset down to 154 dimensions (just like before). Note that you must call the <code>partial_fit()</code> method with each mini-batch, rather than the <code>fit()</code> method with the whole training set:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">sklearn.decomposition</code> <code class="kn">import</code> <code class="n">IncrementalPCA</code>

<code class="n">n_batches</code> <code class="o">=</code> <code class="mi">100</code>
<code class="n">inc_pca</code> <code class="o">=</code> <code class="n">IncrementalPCA</code><code class="p">(</code><code class="n">n_components</code><code class="o">=</code><code class="mi">154</code><code class="p">)</code>
<code class="k">for</code> <code class="n">X_batch</code> <code class="ow">in</code> <code class="n">np</code><code class="o">.</code><code class="n">array_split</code><code class="p">(</code><code class="n">X_train</code><code class="p">,</code> <code class="n">n_batches</code><code class="p">):</code>
    <code class="n">inc_pca</code><code class="o">.</code><code class="n">partial_fit</code><code class="p">(</code><code class="n">X_batch</code><code class="p">)</code>

<code class="n">X_reduced</code> <code class="o">=</code> <code class="n">inc_pca</code><code class="o">.</code><code class="n">transform</code><code class="p">(</code><code class="n">X_train</code><code class="p">)</code></pre>

<p>Alternatively, you can use NumPy’s <code>memmap</code> class, which allows you to manipulate a large array stored in a binary file on disk as if it were entirely in memory; the class loads only the data it needs in memory, when it needs it. Since the <code>IncrementalPCA</code> class uses only a small part of the array at any given time, the memory usage remains under control. This makes it possible to call the usual <code>fit()</code> method, as you can see in the following code:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">X_mm</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">memmap</code><code class="p">(</code><code class="n">filename</code><code class="p">,</code> <code class="n">dtype</code><code class="o">=</code><code class="s2">"float32"</code><code class="p">,</code> <code class="n">mode</code><code class="o">=</code><code class="s2">"readonly"</code><code class="p">,</code> <code class="n">shape</code><code class="o">=</code><code class="p">(</code><code class="n">m</code><code class="p">,</code> <code class="n">n</code><code class="p">))</code>

<code class="n">batch_size</code> <code class="o">=</code> <code class="n">m</code> <code class="o">//</code> <code class="n">n_batches</code>
<code class="n">inc_pca</code> <code class="o">=</code> <code class="n">IncrementalPCA</code><code class="p">(</code><code class="n">n_components</code><code class="o">=</code><code class="mi">154</code><code class="p">,</code> <code class="n">batch_size</code><code class="o">=</code><code class="n">batch_size</code><code class="p">)</code>
<code class="n">inc_pca</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_mm</code><code class="p">)</code></pre>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Kernel PCA"><div class="sect1" id="idm46263521493064">
<h1>Kernel PCA</h1>

<p>In <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch05.html#svm_chapter">Chapter&nbsp;5</a> we discussed the kernel trick, a mathematical technique that implicitly maps instances into a very high-dimensional space (called the <em>feature space</em>), enabling nonlinear classification and regression with Support Vector Machines. Recall that a linear decision boundary in the high-dimensional feature space corresponds to a complex nonlinear decision boundary in the <em>original space</em>.</p>

<p>It turns out that the same trick can be applied to PCA, making it possible to perform complex nonlinear projections for dimensionality reduction. This is called <a href="https://homl.info/33"><em>Kernel PCA</em> (kPCA)</a>.<sup><a data-type="noteref" id="idm46263520871048-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#idm46263520871048" class="totri-footnote">6</a></sup> It is often good at preserving clusters of instances after projection, or sometimes even unrolling datasets that lie close to a twisted manifold.</p>

<p>The following code uses Scikit-Learn’s <code>KernelPCA</code> class to perform kPCA with an RBF kernel (see <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch05.html#svm_chapter">Chapter&nbsp;5</a> for more details about the RBF kernel and the other kernels):</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">sklearn.decomposition</code> <code class="kn">import</code> <code class="n">KernelPCA</code>

<code class="n">rbf_pca</code> <code class="o">=</code> <code class="n">KernelPCA</code><code class="p">(</code><code class="n">n_components</code> <code class="o">=</code> <code class="mi">2</code><code class="p">,</code> <code class="n">kernel</code><code class="o">=</code><code class="s2">"rbf"</code><code class="p">,</code> <code class="n">gamma</code><code class="o">=</code><code class="mf">0.04</code><code class="p">)</code>
<code class="n">X_reduced</code> <code class="o">=</code> <code class="n">rbf_pca</code><code class="o">.</code><code class="n">fit_transform</code><code class="p">(</code><code class="n">X</code><code class="p">)</code></pre>

<p><a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#kernel_pca_plot">Figure&nbsp;8-10</a> shows the Swiss roll, reduced to two dimensions using a linear kernel (equivalent to simply using the <code>PCA</code> class), an RBF kernel, and a sigmoid kernel (Logistic).</p>

<figure><div id="kernel_pca_plot" class="figure">
<img src="./Chapter8_files/mls2_0810.png" alt="mls2 0810" width="1439" height="496" data-mfp-src="/library/view/hands-on-machine-learning/9781492032632/assets/mls2_0810.png">
<h6><span class="label">Figure 8-10. </span>Swiss roll reduced to 2D using kPCA with various kernels</h6>
</div></figure>








<section data-type="sect2" data-pdf-bookmark="Selecting a Kernel and Tuning Hyperparameters"><div class="sect2" id="idm46263520837320">
<h2>Selecting a Kernel and Tuning Hyperparameters</h2>

<p>As kPCA is an unsupervised learning algorithm, there is no obvious performance measure to help you select the best kernel and hyperparameter values. That said, dimensionality reduction is often a preparation step for a supervised learning task (e.g., classification), so you can use grid search to select the kernel and hyperparameters that lead to the best performance on that task. The following code creates a two-step pipeline, first reducing dimensionality to two dimensions using kPCA, then applying Logistic Regression for classification. Then it uses <code>GridSearchCV</code> to find the best kernel and gamma value for kPCA in order to get the best classification accuracy at the end of the pipeline:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">sklearn.model_selection</code> <code class="kn">import</code> <code class="n">GridSearchCV</code>
<code class="kn">from</code> <code class="nn">sklearn.linear_model</code> <code class="kn">import</code> <code class="n">LogisticRegression</code>
<code class="kn">from</code> <code class="nn">sklearn.pipeline</code> <code class="kn">import</code> <code class="n">Pipeline</code>

<code class="n">clf</code> <code class="o">=</code> <code class="n">Pipeline</code><code class="p">([</code>
        <code class="p">(</code><code class="s2">"kpca"</code><code class="p">,</code> <code class="n">KernelPCA</code><code class="p">(</code><code class="n">n_components</code><code class="o">=</code><code class="mi">2</code><code class="p">)),</code>
        <code class="p">(</code><code class="s2">"log_reg"</code><code class="p">,</code> <code class="n">LogisticRegression</code><code class="p">())</code>
    <code class="p">])</code>

<code class="n">param_grid</code> <code class="o">=</code> <code class="p">[{</code>
        <code class="s2">"kpca__gamma"</code><code class="p">:</code> <code class="n">np</code><code class="o">.</code><code class="n">linspace</code><code class="p">(</code><code class="mf">0.03</code><code class="p">,</code> <code class="mf">0.05</code><code class="p">,</code> <code class="mi">10</code><code class="p">),</code>
        <code class="s2">"kpca__kernel"</code><code class="p">:</code> <code class="p">[</code><code class="s2">"rbf"</code><code class="p">,</code> <code class="s2">"sigmoid"</code><code class="p">]</code>
    <code class="p">}]</code>

<code class="n">grid_search</code> <code class="o">=</code> <code class="n">GridSearchCV</code><code class="p">(</code><code class="n">clf</code><code class="p">,</code> <code class="n">param_grid</code><code class="p">,</code> <code class="n">cv</code><code class="o">=</code><code class="mi">3</code><code class="p">)</code>
<code class="n">grid_search</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">y</code><code class="p">)</code></pre>

<p>The best kernel and hyperparameters are then available through the <code>best_params_</code> variable:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="k">print</code><code class="p">(</code><code class="n">grid_search</code><code class="o">.</code><code class="n">best_params_</code><code class="p">)</code>
<code class="go">{'kpca__gamma': 0.043333333333333335, 'kpca__kernel': 'rbf'}</code></pre>

<p>Another approach, this time entirely unsupervised, is to select the kernel and hyperparameters that yield the lowest reconstruction error. Note that reconstruction is not as easy as with linear PCA. Here’s why. <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#kernel_pca_diagram">Figure&nbsp;8-11</a> shows the original Swiss roll 3D dataset (top left) and the resulting 2D dataset after kPCA is applied using an RBF kernel (top right). Thanks to the kernel trick, this transformation is mathematically equivalent to using the <em>feature map</em> φ to map the training set to an infinite-dimensional feature space (bottom right), then projecting the transformed training set down to 2D using linear PCA. Notice that if we could invert the linear PCA step for a given instance in the reduced space, the reconstructed point would lie in feature space, not in the original space (e.g., like the one represented by an x in the diagram). Since the feature space is infinite-dimensional, we cannot compute the reconstructed point, and therefore we cannot compute the true reconstruction error. Fortunately, it is possible to find a point in the original space that would map close to the reconstructed point. This point is called the reconstruction <em>pre-image</em>. Once you have this pre-image, you can measure its squared distance to the original instance. You can then select the kernel and hyperparameters that minimize this reconstruction pre-image error.</p>

<figure><div id="kernel_pca_diagram" class="figure">
<img src="./Chapter8_files/mls2_0811.png" alt="mls2 0811" width="1439" height="1157" data-mfp-src="/library/view/hands-on-machine-learning/9781492032632/assets/mls2_0811.png">
<h6><span class="label">Figure 8-11. </span>Kernel PCA and the reconstruction pre-image error</h6>
</div></figure>

<p>You may be wondering how to perform this reconstruction. One solution is to train a supervised regression model, with the projected instances as the training set and the original instances as the targets. Scikit-Learn will do this automatically if you set <code>fit_inverse_transform=True</code>, as shown in the following code:<sup><a data-type="noteref" id="idm46263520665112-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#idm46263520665112" class="totri-footnote">7</a></sup></p>

<pre data-type="programlisting" data-code-language="python"><code class="n">rbf_pca</code> <code class="o">=</code> <code class="n">KernelPCA</code><code class="p">(</code><code class="n">n_components</code> <code class="o">=</code> <code class="mi">2</code><code class="p">,</code> <code class="n">kernel</code><code class="o">=</code><code class="s2">"rbf"</code><code class="p">,</code> <code class="n">gamma</code><code class="o">=</code><code class="mf">0.0433</code><code class="p">,</code>
                    <code class="n">fit_inverse_transform</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>
<code class="n">X_reduced</code> <code class="o">=</code> <code class="n">rbf_pca</code><code class="o">.</code><code class="n">fit_transform</code><code class="p">(</code><code class="n">X</code><code class="p">)</code>
<code class="n">X_preimage</code> <code class="o">=</code> <code class="n">rbf_pca</code><code class="o">.</code><code class="n">inverse_transform</code><code class="p">(</code><code class="n">X_reduced</code><code class="p">)</code></pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>By default, <code>fit_inverse_transform=False</code> and <code>KernelPCA</code> has no <code>inverse_transform()</code> method. This method only gets created when you set <code>fit_inverse_transform=True</code>.</p>
</div>

<p>You can then compute the reconstruction pre-image error:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="kn">from</code> <code class="nn">sklearn.metrics</code> <code class="kn">import</code> <code class="n">mean_squared_error</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">mean_squared_error</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">X_preimage</code><code class="p">)</code>
<code class="go">32.786308795766132</code></pre>

<p>Now you can use grid search with cross-validation to find the kernel and hyperparameters that minimize this pre-image reconstruction error.</p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="LLE"><div class="sect1" id="idm46263520836696">
<h1>LLE</h1>

<p><a href="https://science.sciencemag.org/content/290/5500/2323.short"><em>Locally Linear Embedding</em></a> (LLE)<sup><a data-type="noteref" id="idm46263520557832-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#idm46263520557832" class="totri-footnote">8</a></sup> is another powerful <em>nonlinear dimensionality reduction</em> (NLDR) technique. It is a Manifold Learning technique that does not rely on projections like the previous algorithms do. In a nutshell, LLE works by first measuring how each training instance linearly relates to its closest neighbors (c.n.), and then looking for a low-dimensional representation of the training set where these local relationships are best preserved (more details shortly). This approach makes it particularly good at unrolling twisted manifolds, especially when there is not too much noise.</p>

<p>The following code uses Scikit-Learn’s <code>LocallyLinearEmbedding</code> class to unroll the Swiss roll:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">sklearn.manifold</code> <code class="kn">import</code> <code class="n">LocallyLinearEmbedding</code>

<code class="n">lle</code> <code class="o">=</code> <code class="n">LocallyLinearEmbedding</code><code class="p">(</code><code class="n">n_components</code><code class="o">=</code><code class="mi">2</code><code class="p">,</code> <code class="n">n_neighbors</code><code class="o">=</code><code class="mi">10</code><code class="p">)</code>
<code class="n">X_reduced</code> <code class="o">=</code> <code class="n">lle</code><code class="o">.</code><code class="n">fit_transform</code><code class="p">(</code><code class="n">X</code><code class="p">)</code></pre>

<p>The resulting 2D dataset is shown in <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#lle_unrolling_plot">Figure&nbsp;8-12</a>. As you can see, the Swiss roll is completely unrolled, and the distances between instances are locally well preserved. However, distances are not preserved on a larger scale: the left part of the unrolled Swiss roll is stretched, while the right part is squeezed. Nevertheless, LLE did a pretty good job at modeling the manifold.</p>

<figure class="smallerninety"><div id="lle_unrolling_plot" class="figure">
<img src="./Chapter8_files/mls2_0812.png" alt="mls2 0812" width="1441" height="956" data-mfp-src="/library/view/hands-on-machine-learning/9781492032632/assets/mls2_0812.png">
<h6><span class="label">Figure 8-12. </span>Unrolled Swiss roll using LLE</h6>
</div></figure>

<p>Here’s how LLE works: for each training instance <strong>x</strong><sup>(<em>i</em>)</sup>, the algorithm identifies its <em>k</em> closest neighbors (in the preceding code <em>k</em> = 10), then tries to reconstruct <strong>x</strong><sup>(<em>i</em>)</sup> as a linear function of these neighbors. More specifically, it finds the weights <em>w</em><sub><em>i,j</em></sub> such that the squared distance between <strong>x</strong><sup>(<em>i</em>)</sup> and <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-98-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;msubsup&gt;&lt;mo&gt;&amp;#x2211;&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/msubsup&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;msup&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;x&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-3980" style="width: 5.71em; display: inline-block;"><span style="display: inline-block; position: relative; width: 5.555em; height: 0px; font-size: 103%;"><span style="position: absolute; clip: rect(1.082em, 1005.56em, 2.676em, -1000.01em); top: -2.105em; left: 0em;"><span class="mrow" id="MathJax-Span-3981"><span class="mrow" id="MathJax-Span-3982"><span class="msubsup" id="MathJax-Span-3983"><span style="display: inline-block; position: relative; width: 2.316em; height: 0px;"><span style="position: absolute; clip: rect(3.087em, 1000.99em, 4.424em, -1000.01em); top: -4.008em; left: 0em;"><span class="mo" id="MathJax-Span-3984" style="font-family: MathJax_Size1; vertical-align: 0em;">∑</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.55em, 1000.68em, 4.167em, -1000.01em); top: -4.47em; left: 1.082em;"><span class="mi" id="MathJax-Span-3985" style="font-size: 70.7%; font-family: MathJax_Math-italic;">m</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.396em, 1001.3em, 4.321em, -1000.01em); top: -3.699em; left: 1.082em;"><span class="mrow" id="MathJax-Span-3986"><span class="mi" id="MathJax-Span-3987" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span><span class="mo" id="MathJax-Span-3988" style="font-size: 70.7%; font-family: MathJax_Main;">=</span><span class="mn" id="MathJax-Span-3989" style="font-size: 70.7%; font-family: MathJax_Main;">1</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mrow" id="MathJax-Span-3990" style="padding-left: 0.157em;"><span class="msub" id="MathJax-Span-3991"><span style="display: inline-block; position: relative; width: 1.545em; height: 0px;"><span style="position: absolute; clip: rect(3.396em, 1000.68em, 4.167em, -1000.01em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-3992" style="font-family: MathJax_Math-italic;">w</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.854em; left: 0.722em;"><span class="mrow" id="MathJax-Span-3993"><span class="mi" id="MathJax-Span-3994" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mo" id="MathJax-Span-3995" style="font-size: 70.7%; font-family: MathJax_Main;">,</span><span class="mi" id="MathJax-Span-3996" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="msup" id="MathJax-Span-3997"><span style="display: inline-block; position: relative; width: 1.545em; height: 0px;"><span style="position: absolute; clip: rect(3.396em, 1000.58em, 4.167em, -1000.01em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-3998" style="font-family: MathJax_Main-bold;">x</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -4.368em; left: 0.62em;"><span class="mrow" id="MathJax-Span-3999"><span class="mo" id="MathJax-Span-4000" style="font-size: 70.7%; font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-4001" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span><span class="mo" id="MathJax-Span-4002" style="font-size: 70.7%; font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.111em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.474em; border-left: 0px solid; width: 0px; height: 1.485em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></msubsup><mrow><msub><mi>w</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><msup><mi mathvariant="bold">x</mi><mrow><mo>(</mo><mi>j</mi><mo>)</mo></mrow></msup></mrow></mrow></math></span></span><script type="math/mml" id="MathJax-Element-98"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow>
    <msubsup><mo>∑</mo> <mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow> <mi>m</mi> </msubsup>
    <mrow>
      <msub><mi>w</mi> <mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow> </msub>
      <msup><mi mathvariant="bold">x</mi> <mrow><mo>(</mo><mi>j</mi><mo>)</mo></mrow> </msup>
    </mrow>
  </mrow>
</math></script> is as small as possible, assuming <em>w</em><sub><em>i,j</em></sub> = 0  if <strong>x</strong><sup>(<em>j</em>)</sup> is not one of the <em>k</em> closest neighbors of <strong>x</strong><sup>(<em>i</em>)</sup>. Thus the first step of LLE is the constrained optimization problem described in <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#lle_first_step">Equation 8-4</a>, where <strong>W</strong> is the weight matrix containing all the weights <em>w</em><sub><em>i,j</em></sub>. The second constraint simply normalizes the weights for each training instance <strong>x</strong><sup>(<em>i</em>)</sup>.</p>
<div class="pagebreak-before less_space" id="lle_first_step" data-type="equation"><h5><span class="label">Equation 8-4. </span>LLE step one: linearly modeling local relationships</h5>
<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-99-Frame" tabindex="0" style="text-align: center; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mtable displaystyle=&quot;true&quot;&gt;&lt;mtr&gt;&lt;mtd /&gt;&lt;mtd columnalign=&quot;left&quot;&gt;&lt;mrow&gt;&lt;mover accent=&quot;true&quot;&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;W&lt;/mi&gt;&lt;mo&gt;^&lt;/mo&gt;&lt;/mover&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;munder&gt;&lt;mo form=&quot;prefix&quot;&gt;argmin&lt;/mo&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;W&lt;/mi&gt;&lt;/munder&gt;&lt;mstyle scriptlevel=&quot;0&quot; displaystyle=&quot;true&quot;&gt;&lt;munderover&gt;&lt;mo&gt;&amp;#x2211;&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/munderover&gt;&lt;/mstyle&gt;&lt;msup&gt;&lt;mfenced separators=&quot;&quot; open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;msup&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;x&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mo&gt;-&lt;/mo&gt;&lt;munderover&gt;&lt;mo&gt;&amp;#x2211;&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/munderover&gt;&lt;msub&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;msup&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;x&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mfenced&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd /&gt;&lt;mtd columnalign=&quot;left&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;subject&lt;/mtext&gt;&lt;mspace width=&quot;4.pt&quot; /&gt;&lt;mtext&gt;to&lt;/mtext&gt;&lt;mspace width=&quot;4.pt&quot; /&gt;&lt;mfenced separators=&quot;&quot; open=&quot;{&quot; close=&quot;&quot;&gt;&lt;mtable&gt;&lt;mtr&gt;&lt;mtd columnalign=&quot;left&quot;&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;0&lt;/mn&gt;&lt;/mrow&gt;&lt;/mtd&gt;&lt;mtd columnalign=&quot;left&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;if&lt;/mtext&gt;&lt;mspace width=&quot;4.pt&quot; /&gt;&lt;msup&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;x&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mspace width=&quot;4.pt&quot; /&gt;&lt;mtext&gt;is&lt;/mtext&gt;&lt;mspace width=&quot;4.pt&quot; /&gt;&lt;mtext&gt;not&lt;/mtext&gt;&lt;mspace width=&quot;4.pt&quot; /&gt;&lt;mtext&gt;one&lt;/mtext&gt;&lt;mspace width=&quot;4.pt&quot; /&gt;&lt;mtext&gt;of&lt;/mtext&gt;&lt;mspace width=&quot;4.pt&quot; /&gt;&lt;mtext&gt;the&lt;/mtext&gt;&lt;mspace width=&quot;4.pt&quot; /&gt;&lt;mi&gt;k&lt;/mi&gt;&lt;mspace width=&quot;4.pt&quot; /&gt;&lt;mtext&gt;c.n.&lt;/mtext&gt;&lt;mspace width=&quot;4.pt&quot; /&gt;&lt;mtext&gt;of&lt;/mtext&gt;&lt;mspace width=&quot;4.pt&quot; /&gt;&lt;msup&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;x&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;mtr&gt;&lt;mtd columnalign=&quot;left&quot;&gt;&lt;mrow&gt;&lt;munderover&gt;&lt;mo&gt;&amp;#x2211;&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/munderover&gt;&lt;msub&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/mtd&gt;&lt;mtd columnalign=&quot;left&quot;&gt;&lt;mrow&gt;&lt;mtext&gt;for&lt;/mtext&gt;&lt;mspace width=&quot;4.pt&quot; /&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mo&gt;&amp;#x22EF;&lt;/mo&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/mrow&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;/mtable&gt;&lt;/mfenced&gt;&lt;/mrow&gt;&lt;/mtd&gt;&lt;/mtr&gt;&lt;/mtable&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-4003" style="width: 30.954em; display: inline-block;"><span style="display: inline-block; position: relative; width: 30.029em; height: 0px; font-size: 103%;"><span style="position: absolute; clip: rect(-1.643em, 1029.73em, 5.35em, -1000.01em); top: -2.105em; left: 0em;"><span class="mrow" id="MathJax-Span-4004"><span class="mtable" id="MathJax-Span-4005" style="padding-right: 0.157em; padding-left: 0.157em;"><span style="display: inline-block; position: relative; width: 29.72em; height: 0px;"><span style="position: absolute; clip: rect(2.728em, 1000.01em, 6.532em, -1000.01em); top: -4.522em; left: 0em;"><span style="display: inline-block; position: relative; width: 0em; height: 0px;"><span style="position: absolute; clip: rect(3.859em, 1000.01em, 4.167em, -1000.01em); top: -5.653em; left: 50%; margin-left: 0em;"><span class="mtd" id="MathJax-Span-4006"><span class="mrow" id="MathJax-Span-4007"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.859em, 1000.01em, 4.167em, -1000.01em); top: -2.157em; left: 50%; margin-left: 0em;"><span class="mtd" id="MathJax-Span-4058"><span class="mrow" id="MathJax-Span-4059"></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.527em;"></span></span><span style="position: absolute; clip: rect(3.961em, 1028.8em, 10.954em, -1000.01em); top: -7.71em; left: 0.825em;"><span style="display: inline-block; position: relative; width: 28.949em; height: 0px;"><span style="position: absolute; clip: rect(2.162em, 1016.82em, 5.761em, -1000.01em); top: -5.91em; left: 0em;"><span class="mtd" id="MathJax-Span-4008"><span class="mrow" id="MathJax-Span-4009"><span class="mrow" id="MathJax-Span-4010"><span class="mover" id="MathJax-Span-4011"><span style="display: inline-block; position: relative; width: 1.185em; height: 0px;"><span style="position: absolute; clip: rect(3.19em, 1001.14em, 4.167em, -1000.01em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-4012" style="font-family: MathJax_Main-bold;">W</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.087em, 1000.99em, 3.602em, -1000.01em); top: -4.265em; left: 0.105em;"><span class="mo" id="MathJax-Span-4013" style=""><span style="font-family: MathJax_Size2;">ˆ</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-4014" style="font-family: MathJax_Main; padding-left: 0.26em;">=</span><span class="munder" id="MathJax-Span-4015" style="padding-left: 0.311em; padding-right: 0.311em;"><span style="display: inline-block; position: relative; width: 3.036em; height: 0px;"><span style="position: absolute; clip: rect(3.19em, 1003.04em, 4.373em, -1000.01em); top: -4.008em; left: 0em;"><span class="mo" id="MathJax-Span-4016" style="font-family: MathJax_Main;">argmin</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.396em, 1000.83em, 4.27em, -1000.01em); top: -3.134em; left: 1.134em;"><span class="mi" id="MathJax-Span-4017" style="font-size: 70.7%; font-family: MathJax_Main-bold;">W</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mstyle" id="MathJax-Span-4018"><span class="mrow" id="MathJax-Span-4019"><span class="munderover" id="MathJax-Span-4020"><span style="display: inline-block; position: relative; width: 1.442em; height: 0px;"><span style="position: absolute; clip: rect(2.933em, 1001.4em, 4.63em, -1000.01em); top: -4.008em; left: 0em;"><span class="mo" id="MathJax-Span-4021" style="font-family: MathJax_Size2; vertical-align: 0em;">∑</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.396em, 1001.09em, 4.27em, -1000.01em); top: -2.928em; left: 0.157em;"><span class="mrow" id="MathJax-Span-4022"><span class="mi" id="MathJax-Span-4023" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mo" id="MathJax-Span-4024" style="font-size: 70.7%; font-family: MathJax_Main;">=</span><span class="mn" id="MathJax-Span-4025" style="font-size: 70.7%; font-family: MathJax_Main;">1</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.447em, 1000.63em, 4.167em, -1000.01em); top: -5.139em; left: 0.414em;"><span class="mi" id="MathJax-Span-4026" style="font-size: 70.7%; font-family: MathJax_Math-italic;">m</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span></span><span class="msup" id="MathJax-Span-4027" style="padding-left: 0.157em;"><span style="display: inline-block; position: relative; width: 9.309em; height: 0px;"><span style="position: absolute; clip: rect(2.162em, 1008.65em, 5.555em, -1000.01em); top: -4.059em; left: 0em;"><span class="mfenced" id="MathJax-Span-4028"><span class="mo" id="MathJax-Span-4029" style="vertical-align: 0em;"><span style="font-family: MathJax_Size4;">(</span></span><span class="msup" id="MathJax-Span-4030"><span style="display: inline-block; position: relative; width: 1.494em; height: 0px;"><span style="position: absolute; clip: rect(3.396em, 1000.58em, 4.167em, -1000.01em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-4031" style="font-family: MathJax_Main-bold;">x</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -4.419em; left: 0.62em;"><span class="mrow" id="MathJax-Span-4032"><span class="mo" id="MathJax-Span-4033" style="font-size: 70.7%; font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-4034" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mo" id="MathJax-Span-4035" style="font-size: 70.7%; font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-4036" style="font-family: MathJax_Main; padding-left: 0.208em;">−</span><span class="munderover" id="MathJax-Span-4037" style="padding-left: 0.208em;"><span style="display: inline-block; position: relative; width: 1.442em; height: 0px;"><span style="position: absolute; clip: rect(2.933em, 1001.4em, 4.63em, -1000.01em); top: -4.008em; left: 0em;"><span class="mo" id="MathJax-Span-4038" style="font-family: MathJax_Size2; vertical-align: 0em;">∑</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.396em, 1001.14em, 4.424em, -1000.01em); top: -2.928em; left: 0.105em;"><span class="mrow" id="MathJax-Span-4039"><span class="mi" id="MathJax-Span-4040" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span><span class="mo" id="MathJax-Span-4041" style="font-size: 70.7%; font-family: MathJax_Main;">=</span><span class="mn" id="MathJax-Span-4042" style="font-size: 70.7%; font-family: MathJax_Main;">1</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.447em, 1000.63em, 4.167em, -1000.01em); top: -5.139em; left: 0.414em;"><span class="mi" id="MathJax-Span-4043" style="font-size: 70.7%; font-family: MathJax_Math-italic;">m</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="msub" id="MathJax-Span-4044" style="padding-left: 0.157em;"><span style="display: inline-block; position: relative; width: 1.545em; height: 0px;"><span style="position: absolute; clip: rect(3.396em, 1000.68em, 4.167em, -1000.01em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-4045" style="font-family: MathJax_Math-italic;">w</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.854em; left: 0.722em;"><span class="mrow" id="MathJax-Span-4046"><span class="mi" id="MathJax-Span-4047" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mo" id="MathJax-Span-4048" style="font-size: 70.7%; font-family: MathJax_Main;">,</span><span class="mi" id="MathJax-Span-4049" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="msup" id="MathJax-Span-4050"><span style="display: inline-block; position: relative; width: 1.545em; height: 0px;"><span style="position: absolute; clip: rect(3.396em, 1000.58em, 4.167em, -1000.01em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-4051" style="font-family: MathJax_Main-bold;">x</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -4.419em; left: 0.62em;"><span class="mrow" id="MathJax-Span-4052"><span class="mo" id="MathJax-Span-4053" style="font-size: 70.7%; font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-4054" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span><span class="mo" id="MathJax-Span-4055" style="font-size: 70.7%; font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-4056" style="vertical-align: 0em;"><span style="font-family: MathJax_Size4;">)</span></span></span><span style="display: inline-block; width: 0px; height: 4.064em;"></span></span><span style="position: absolute; top: -5.499em; left: 8.897em;"><span class="mn" id="MathJax-Span-4057" style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.27em;"></span></span><span style="position: absolute; clip: rect(2.111em, 1028.8em, 5.401em, -1000.01em); top: -2.157em; left: 0em;"><span class="mtd" id="MathJax-Span-4060"><span class="mrow" id="MathJax-Span-4061"><span class="mrow" id="MathJax-Span-4062"><span class="mtext" id="MathJax-Span-4063" style="font-family: MathJax_Main;">subject</span><span class="mspace" id="MathJax-Span-4064" style="height: 0em; vertical-align: 0em; width: 0.414em; display: inline-block; overflow: hidden;"></span><span class="mtext" id="MathJax-Span-4065" style="font-family: MathJax_Main;">to</span><span class="mspace" id="MathJax-Span-4066" style="height: 0em; vertical-align: 0em; width: 0.414em; display: inline-block; overflow: hidden;"></span><span class="mfenced" id="MathJax-Span-4067" style="padding-left: 0.157em;"><span class="mo" id="MathJax-Span-4068" style="vertical-align: 0em;"><span style="font-family: MathJax_Size4;">{</span></span><span class="mtable" id="MathJax-Span-4069" style="padding-right: 0.157em; padding-left: 0.157em;"><span style="display: inline-block; position: relative; width: 22.882em; height: 0px;"><span style="position: absolute; clip: rect(2.419em, 1005.72em, 5.35em, -1000.01em); top: -4.008em; left: 0em;"><span style="display: inline-block; position: relative; width: 5.812em; height: 0px;"><span style="position: absolute; clip: rect(3.19em, 1003.3em, 4.476em, -1000.01em); top: -4.779em; left: 0em;"><span class="mtd" id="MathJax-Span-4070"><span class="mrow" id="MathJax-Span-4071"><span class="mrow" id="MathJax-Span-4072"><span class="msub" id="MathJax-Span-4073"><span style="display: inline-block; position: relative; width: 1.545em; height: 0px;"><span style="position: absolute; clip: rect(3.396em, 1000.68em, 4.167em, -1000.01em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-4074" style="font-family: MathJax_Math-italic;">w</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.854em; left: 0.722em;"><span class="mrow" id="MathJax-Span-4075"><span class="mi" id="MathJax-Span-4076" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mo" id="MathJax-Span-4077" style="font-size: 70.7%; font-family: MathJax_Main;">,</span><span class="mi" id="MathJax-Span-4078" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-4079" style="font-family: MathJax_Main; padding-left: 0.26em;">=</span><span class="mn" id="MathJax-Span-4080" style="font-family: MathJax_Main; padding-left: 0.26em;">0</span></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.087em, 1005.72em, 4.578em, -1000.01em); top: -3.288em; left: 0em;"><span class="mtd" id="MathJax-Span-4115"><span class="mrow" id="MathJax-Span-4116"><span class="mrow" id="MathJax-Span-4117"><span class="munderover" id="MathJax-Span-4118"><span style="display: inline-block; position: relative; width: 2.316em; height: 0px;"><span style="position: absolute; clip: rect(3.087em, 1000.99em, 4.424em, -1000.01em); top: -4.008em; left: 0em;"><span class="mo" id="MathJax-Span-4119" style="font-family: MathJax_Size1; vertical-align: 0em;">∑</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.55em, 1000.68em, 4.167em, -1000.01em); top: -4.47em; left: 1.082em;"><span class="mi" id="MathJax-Span-4120" style="font-size: 70.7%; font-family: MathJax_Math-italic;">m</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.396em, 1001.3em, 4.321em, -1000.01em); top: -3.699em; left: 1.082em;"><span class="mrow" id="MathJax-Span-4121"><span class="mi" id="MathJax-Span-4122" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span><span class="mo" id="MathJax-Span-4123" style="font-size: 70.7%; font-family: MathJax_Main;">=</span><span class="mn" id="MathJax-Span-4124" style="font-size: 70.7%; font-family: MathJax_Main;">1</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="msub" id="MathJax-Span-4125" style="padding-left: 0.157em;"><span style="display: inline-block; position: relative; width: 1.545em; height: 0px;"><span style="position: absolute; clip: rect(3.396em, 1000.68em, 4.167em, -1000.01em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-4126" style="font-family: MathJax_Math-italic;">w</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.854em; left: 0.722em;"><span class="mrow" id="MathJax-Span-4127"><span class="mi" id="MathJax-Span-4128" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mo" id="MathJax-Span-4129" style="font-size: 70.7%; font-family: MathJax_Main;">,</span><span class="mi" id="MathJax-Span-4130" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-4131" style="font-family: MathJax_Main; padding-left: 0.26em;">=</span><span class="mn" id="MathJax-Span-4132" style="font-family: MathJax_Main; padding-left: 0.26em;">1</span></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(2.162em, 1016.26em, 5.093em, -1000.01em); top: -4.008em; left: 6.584em;"><span style="display: inline-block; position: relative; width: 16.301em; height: 0px;"><span style="position: absolute; clip: rect(2.985em, 1016.26em, 4.167em, -1000.01em); top: -4.779em; left: 0em;"><span class="mtd" id="MathJax-Span-4081"><span class="mrow" id="MathJax-Span-4082"><span class="mrow" id="MathJax-Span-4083"><span class="mtext" id="MathJax-Span-4084" style="font-family: MathJax_Main;">if</span><span class="mspace" id="MathJax-Span-4085" style="height: 0em; vertical-align: 0em; width: 0.414em; display: inline-block; overflow: hidden;"></span><span class="msup" id="MathJax-Span-4086"><span style="display: inline-block; position: relative; width: 1.545em; height: 0px;"><span style="position: absolute; clip: rect(3.396em, 1000.58em, 4.167em, -1000.01em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-4087" style="font-family: MathJax_Main-bold;">x</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -4.368em; left: 0.62em;"><span class="mrow" id="MathJax-Span-4088"><span class="mo" id="MathJax-Span-4089" style="font-size: 70.7%; font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-4090" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span><span class="mo" id="MathJax-Span-4091" style="font-size: 70.7%; font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mspace" id="MathJax-Span-4092" style="height: 0em; vertical-align: 0em; width: 0.414em; display: inline-block; overflow: hidden;"></span><span class="mtext" id="MathJax-Span-4093" style="font-family: MathJax_Main;">is</span><span class="mspace" id="MathJax-Span-4094" style="height: 0em; vertical-align: 0em; width: 0.414em; display: inline-block; overflow: hidden;"></span><span class="mtext" id="MathJax-Span-4095" style="font-family: MathJax_Main;">not</span><span class="mspace" id="MathJax-Span-4096" style="height: 0em; vertical-align: 0em; width: 0.414em; display: inline-block; overflow: hidden;"></span><span class="mtext" id="MathJax-Span-4097" style="font-family: MathJax_Main;">one</span><span class="mspace" id="MathJax-Span-4098" style="height: 0em; vertical-align: 0em; width: 0.414em; display: inline-block; overflow: hidden;"></span><span class="mtext" id="MathJax-Span-4099" style="font-family: MathJax_Main;">of</span><span class="mspace" id="MathJax-Span-4100" style="height: 0em; vertical-align: 0em; width: 0.414em; display: inline-block; overflow: hidden;"></span><span class="mtext" id="MathJax-Span-4101" style="font-family: MathJax_Main;">the</span><span class="mspace" id="MathJax-Span-4102" style="height: 0em; vertical-align: 0em; width: 0.414em; display: inline-block; overflow: hidden;"></span><span class="mi" id="MathJax-Span-4103" style="font-family: MathJax_Math-italic;">k</span><span class="mspace" id="MathJax-Span-4104" style="height: 0em; vertical-align: 0em; width: 0.414em; display: inline-block; overflow: hidden;"></span><span class="mtext" id="MathJax-Span-4105" style="font-family: MathJax_Main;">c.n.</span><span class="mspace" id="MathJax-Span-4106" style="height: 0em; vertical-align: 0em; width: 0.414em; display: inline-block; overflow: hidden;"></span><span class="mtext" id="MathJax-Span-4107" style="font-family: MathJax_Main;">of</span><span class="mspace" id="MathJax-Span-4108" style="height: 0em; vertical-align: 0em; width: 0.414em; display: inline-block; overflow: hidden;"></span><span class="msup" id="MathJax-Span-4109"><span style="display: inline-block; position: relative; width: 1.494em; height: 0px;"><span style="position: absolute; clip: rect(3.396em, 1000.58em, 4.167em, -1000.01em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-4110" style="font-family: MathJax_Main-bold;">x</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -4.368em; left: 0.62em;"><span class="mrow" id="MathJax-Span-4111"><span class="mo" id="MathJax-Span-4112" style="font-size: 70.7%; font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-4113" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mo" id="MathJax-Span-4114" style="font-size: 70.7%; font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.139em, 1007.72em, 4.373em, -1000.01em); top: -3.288em; left: 0em;"><span class="mtd" id="MathJax-Span-4133"><span class="mrow" id="MathJax-Span-4134"><span class="mrow" id="MathJax-Span-4135"><span class="mtext" id="MathJax-Span-4136" style="font-family: MathJax_Main;">for</span><span class="mspace" id="MathJax-Span-4137" style="height: 0em; vertical-align: 0em; width: 0.414em; display: inline-block; overflow: hidden;"></span><span class="mi" id="MathJax-Span-4138" style="font-family: MathJax_Math-italic;">i</span><span class="mo" id="MathJax-Span-4139" style="font-family: MathJax_Main; padding-left: 0.26em;">=</span><span class="mn" id="MathJax-Span-4140" style="font-family: MathJax_Main; padding-left: 0.26em;">1</span><span class="mo" id="MathJax-Span-4141" style="font-family: MathJax_Main;">,</span><span class="mn" id="MathJax-Span-4142" style="font-family: MathJax_Main; padding-left: 0.157em;">2</span><span class="mo" id="MathJax-Span-4143" style="font-family: MathJax_Main;">,</span><span class="mo" id="MathJax-Span-4144" style="font-family: MathJax_Main; padding-left: 0.157em;">⋯</span><span class="mo" id="MathJax-Span-4145" style="font-family: MathJax_Main; padding-left: 0.157em;">,</span><span class="mi" id="MathJax-Span-4146" style="font-family: MathJax_Math-italic; padding-left: 0.157em;">m</span></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span><span style="display: inline-block; width: 0px; height: 7.715em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.111em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -3.228em; border-left: 0px solid; width: 0px; height: 6.993em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtable displaystyle="true"><mtr><mtd></mtd><mtd columnalign="left"><mrow><mover accent="true"><mi mathvariant="bold">W</mi><mo>^</mo></mover><mo>=</mo><munder><mo form="prefix">argmin</mo><mi mathvariant="bold">W</mi></munder><mstyle scriptlevel="0" displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover></mstyle><msup><mfenced separators="" open="(" close=")"><msup><mi mathvariant="bold">x</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup><mo>-</mo><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><msub><mi>w</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><msup><mi mathvariant="bold">x</mi><mrow><mo>(</mo><mi>j</mi><mo>)</mo></mrow></msup></mfenced><mn>2</mn></msup></mrow></mtd></mtr><mtr><mtd></mtd><mtd columnalign="left"><mrow><mtext>subject</mtext><mspace width="4.pt"></mspace><mtext>to</mtext><mspace width="4.pt"></mspace><mfenced separators="" open="{" close=""><mtable><mtr><mtd columnalign="left"><mrow><msub><mi>w</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>=</mo><mn>0</mn></mrow></mtd><mtd columnalign="left"><mrow><mtext>if</mtext><mspace width="4.pt"></mspace><msup><mi mathvariant="bold">x</mi><mrow><mo>(</mo><mi>j</mi><mo>)</mo></mrow></msup><mspace width="4.pt"></mspace><mtext>is</mtext><mspace width="4.pt"></mspace><mtext>not</mtext><mspace width="4.pt"></mspace><mtext>one</mtext><mspace width="4.pt"></mspace><mtext>of</mtext><mspace width="4.pt"></mspace><mtext>the</mtext><mspace width="4.pt"></mspace><mi>k</mi><mspace width="4.pt"></mspace><mtext>c.n.</mtext><mspace width="4.pt"></mspace><mtext>of</mtext><mspace width="4.pt"></mspace><msup><mi mathvariant="bold">x</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mrow></mtd></mtr><mtr><mtd columnalign="left"><mrow><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><msub><mi>w</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>=</mo><mn>1</mn></mrow></mtd><mtd columnalign="left"><mrow><mtext>for</mtext><mspace width="4.pt"></mspace><mi>i</mi><mo>=</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>m</mi></mrow></mtd></mtr></mtable></mfenced></mrow></mtd></mtr></mtable></math></span></span></div><script type="math/mml" id="MathJax-Element-99"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mtable displaystyle="true">
    <mtr>
      <mtd></mtd>
      <mtd columnalign="left">
        <mrow>
          <mover accent="true"><mi mathvariant="bold">W</mi> <mo>^</mo></mover>
          <mo>=</mo>
          <munder><mo form="prefix">argmin</mo> <mi mathvariant="bold">W</mi></munder>
          <mstyle scriptlevel="0" displaystyle="true">
            <munderover><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>m</mi> </munderover>
          </mstyle>
          <msup><mfenced separators="" open="(" close=")"><msup><mi mathvariant="bold">x</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow> </msup><mo>-</mo><munderover><mo>∑</mo> <mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow> <mi>m</mi> </munderover><msub><mi>w</mi> <mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow> </msub><msup><mi mathvariant="bold">x</mi> <mrow><mo>(</mo><mi>j</mi><mo>)</mo></mrow> </msup></mfenced> <mn>2</mn> </msup>
        </mrow>
      </mtd>
    </mtr>
    <mtr>
      <mtd></mtd>
      <mtd columnalign="left">
        <mrow>
          <mtext>subject</mtext>
          <mspace width="4.pt"></mspace>
          <mtext>to</mtext>
          <mspace width="4.pt"></mspace>
          <mfenced separators="" open="{" close="">
            <mtable>
              <mtr>
                <mtd columnalign="left">
                  <mrow>
                    <msub><mi>w</mi> <mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow> </msub>
                    <mo>=</mo>
                    <mn>0</mn>
                  </mrow>
                </mtd>
                <mtd columnalign="left">
                  <mrow>
                    <mtext>if</mtext>
                    <mspace width="4.pt"></mspace>
                    <msup><mi mathvariant="bold">x</mi> <mrow><mo>(</mo><mi>j</mi><mo>)</mo></mrow> </msup>
                    <mspace width="4.pt"></mspace>
                    <mtext>is</mtext>
                    <mspace width="4.pt"></mspace>
                    <mtext>not</mtext>
                    <mspace width="4.pt"></mspace>
                    <mtext>one</mtext>
                    <mspace width="4.pt"></mspace>
                    <mtext>of</mtext>
                    <mspace width="4.pt"></mspace>
                    <mtext>the</mtext>
                    <mspace width="4.pt"></mspace>
                    <mi>k</mi>
                    <mspace width="4.pt"></mspace>
                    <mtext>c.n.</mtext>
                    <mspace width="4.pt"></mspace>
                    <mtext>of</mtext>
                    <mspace width="4.pt"></mspace>
                    <msup><mi mathvariant="bold">x</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow> </msup>
                  </mrow>
                </mtd>
              </mtr>
              <mtr>
                <mtd columnalign="left">
                  <mrow>
                    <munderover><mo>∑</mo> <mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow> <mi>m</mi> </munderover>
                    <msub><mi>w</mi> <mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow> </msub>
                    <mo>=</mo>
                    <mn>1</mn>
                  </mrow>
                </mtd>
                <mtd columnalign="left">
                  <mrow>
                    <mtext>for</mtext>
                    <mspace width="4.pt"></mspace>
                    <mi>i</mi>
                    <mo>=</mo>
                    <mn>1</mn>
                    <mo>,</mo>
                    <mn>2</mn>
                    <mo>,</mo>
                    <mo>⋯</mo>
                    <mo>,</mo>
                    <mi>m</mi>
                  </mrow>
                </mtd>
              </mtr>
            </mtable>
          </mfenced>
        </mrow>
      </mtd>
    </mtr>
  </mtable>
</math></script>
</div>

<p>After this step, the weight matrix <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-100-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mover accent=&quot;true&quot;&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;W&lt;/mi&gt;&lt;mo&gt;^&lt;/mo&gt;&lt;/mover&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-4147" style="width: 1.237em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.185em; height: 0px; font-size: 103%;"><span style="position: absolute; clip: rect(0.928em, 1001.14em, 2.265em, -1000.01em); top: -2.105em; left: 0em;"><span class="mrow" id="MathJax-Span-4148"><span class="mover" id="MathJax-Span-4149"><span style="display: inline-block; position: relative; width: 1.185em; height: 0px;"><span style="position: absolute; clip: rect(3.19em, 1001.14em, 4.167em, -1000.01em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-4150" style="font-family: MathJax_Main-bold;">W</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.087em, 1000.99em, 3.602em, -1000.01em); top: -4.265em; left: 0.105em;"><span class="mo" id="MathJax-Span-4151" style=""><span style="font-family: MathJax_Size2;">ˆ</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.111em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.05em; border-left: 0px solid; width: 0px; height: 1.168em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mover accent="true"><mi mathvariant="bold">W</mi><mo>^</mo></mover></math></span></span><script type="math/mml" id="MathJax-Element-100"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <mover accent="true"><mi mathvariant="bold">W</mi> <mo>^</mo></mover>
</math></script> (containing the weights <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-101-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; alttext=&quot;ModifyingAbove w With caret Subscript i comma j&quot;&gt;&lt;msub&gt;&lt;mover accent=&quot;true&quot;&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mo&gt;^&lt;/mo&gt;&lt;/mover&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-4152" aria-label="ModifyingAbove w With caret Subscript i comma j" style="width: 1.596em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.545em; height: 0px; font-size: 103%;"><span style="position: absolute; clip: rect(1.185em, 1001.55em, 2.573em, -1000.01em); top: -2.105em; left: 0em;"><span class="mrow" id="MathJax-Span-4153"><span class="msub" id="MathJax-Span-4154"><span style="display: inline-block; position: relative; width: 1.545em; height: 0px;"><span style="position: absolute; clip: rect(3.087em, 1000.73em, 4.167em, -1000.01em); top: -4.008em; left: 0em;"><span class="mover" id="MathJax-Span-4155"><span style="display: inline-block; position: relative; width: 0.722em; height: 0px;"><span style="position: absolute; clip: rect(3.396em, 1000.68em, 4.167em, -1000.01em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-4156" style="font-family: MathJax_Math-italic;">w</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.139em, 1000.58em, 3.602em, -1000.01em); top: -4.008em; left: 0.157em;"><span class="mo" id="MathJax-Span-4157" style=""><span style="font-family: MathJax_Size1;">ˆ</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.854em; left: 0.722em;"><span class="mrow" id="MathJax-Span-4158"><span class="mi" id="MathJax-Span-4159" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mo" id="MathJax-Span-4160" style="font-size: 70.7%; font-family: MathJax_Main;">,</span><span class="mi" id="MathJax-Span-4161" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.111em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.368em; border-left: 0px solid; width: 0px; height: 1.221em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="ModifyingAbove w With caret Subscript i comma j"><msub><mover accent="true"><mi>w</mi><mo>^</mo></mover><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub></math></span></span><script type="math/mml" id="MathJax-Element-101"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="ModifyingAbove w With caret Subscript i comma j">
  <msub><mover accent="true"><mi>w</mi> <mo>^</mo></mover> <mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow> </msub>
</math></script>) encodes the local linear relationships between the training instances. The second step is to map the training instances into a <em>d</em>-dimensional space (where <em>d</em> &lt; <em>n</em>) while preserving these local relationships as much as possible. If <strong>z</strong><sup>(<em>i</em>)</sup> is the image of <strong>x</strong><sup>(<em>i</em>)</sup> in this <em>d</em>-dimensional space, then we want the squared distance between <strong>z</strong><sup>(<em>i</em>)</sup> and <span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax" id="MathJax-Element-102-Frame" tabindex="0" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mrow&gt;&lt;msubsup&gt;&lt;mo&gt;&amp;#x2211;&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/msubsup&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mover accent=&quot;true&quot;&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mo&gt;^&lt;/mo&gt;&lt;/mover&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;msup&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;z&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation" style="position: relative;"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-4162" style="width: 5.607em; display: inline-block;"><span style="display: inline-block; position: relative; width: 5.452em; height: 0px; font-size: 103%;"><span style="position: absolute; clip: rect(1.082em, 1005.46em, 2.676em, -1000.01em); top: -2.105em; left: 0em;"><span class="mrow" id="MathJax-Span-4163"><span class="mrow" id="MathJax-Span-4164"><span class="msubsup" id="MathJax-Span-4165"><span style="display: inline-block; position: relative; width: 2.316em; height: 0px;"><span style="position: absolute; clip: rect(3.087em, 1000.99em, 4.424em, -1000.01em); top: -4.008em; left: 0em;"><span class="mo" id="MathJax-Span-4166" style="font-family: MathJax_Size1; vertical-align: 0em;">∑</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.55em, 1000.68em, 4.167em, -1000.01em); top: -4.47em; left: 1.082em;"><span class="mi" id="MathJax-Span-4167" style="font-size: 70.7%; font-family: MathJax_Math-italic;">m</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.396em, 1001.3em, 4.321em, -1000.01em); top: -3.699em; left: 1.082em;"><span class="mrow" id="MathJax-Span-4168"><span class="mi" id="MathJax-Span-4169" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span><span class="mo" id="MathJax-Span-4170" style="font-size: 70.7%; font-family: MathJax_Main;">=</span><span class="mn" id="MathJax-Span-4171" style="font-size: 70.7%; font-family: MathJax_Main;">1</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mrow" id="MathJax-Span-4172" style="padding-left: 0.157em;"><span class="msub" id="MathJax-Span-4173"><span style="display: inline-block; position: relative; width: 1.545em; height: 0px;"><span style="position: absolute; clip: rect(3.087em, 1000.73em, 4.167em, -1000.01em); top: -4.008em; left: 0em;"><span class="mover" id="MathJax-Span-4174"><span style="display: inline-block; position: relative; width: 0.722em; height: 0px;"><span style="position: absolute; clip: rect(3.396em, 1000.68em, 4.167em, -1000.01em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-4175" style="font-family: MathJax_Math-italic;">w</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.139em, 1000.58em, 3.602em, -1000.01em); top: -4.008em; left: 0.157em;"><span class="mo" id="MathJax-Span-4176" style=""><span style="font-family: MathJax_Size1;">ˆ</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.854em; left: 0.722em;"><span class="mrow" id="MathJax-Span-4177"><span class="mi" id="MathJax-Span-4178" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mo" id="MathJax-Span-4179" style="font-size: 70.7%; font-family: MathJax_Main;">,</span><span class="mi" id="MathJax-Span-4180" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="msup" id="MathJax-Span-4181"><span style="display: inline-block; position: relative; width: 1.442em; height: 0px;"><span style="position: absolute; clip: rect(3.396em, 1000.47em, 4.167em, -1000.01em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-4182" style="font-family: MathJax_Main-bold;">z</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -4.368em; left: 0.517em;"><span class="mrow" id="MathJax-Span-4183"><span class="mo" id="MathJax-Span-4184" style="font-size: 70.7%; font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-4185" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span><span class="mo" id="MathJax-Span-4186" style="font-size: 70.7%; font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.111em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.474em; border-left: 0px solid; width: 0px; height: 1.485em;"></span></span></nobr><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></msubsup><mrow><msub><mover accent="true"><mi>w</mi><mo>^</mo></mover><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><msup><mi mathvariant="bold">z</mi><mrow><mo>(</mo><mi>j</mi><mo>)</mo></mrow></msup></mrow></mrow></math></span></span><script type="math/mml" id="MathJax-Element-102"><math xmlns="http://www.w3.org/1998/Math/MathML">
  <mrow>
    <msubsup><mo>∑</mo> <mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow> <mi>m</mi> </msubsup>
    <mrow>
      <msub><mover accent="true"><mi>w</mi> <mo>^</mo></mover> <mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow> </msub>
      <msup><mi mathvariant="bold">z</mi> <mrow><mo>(</mo><mi>j</mi><mo>)</mo></mrow> </msup>
    </mrow>
  </mrow>
</math></script> to be as small as possible. This idea leads to the unconstrained optimization problem described in <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#lle_second_step">Equation 8-5</a>. It looks very similar to the first step, but instead of keeping the instances fixed and finding the optimal weights, we are doing the reverse: keeping the weights fixed and finding the optimal position of the instances’ images in the low-dimensional space. Note that <strong>Z</strong> is the matrix containing all <strong>z</strong><sup>(<em>i</em>)</sup>.</p>
<div id="lle_second_step" data-type="equation"><h5><span class="label">Equation 8-5. </span>LLE step two: reducing dimensionality while preserving relationships</h5>
<span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-103-Frame" tabindex="0" style="text-align: center; position: relative;" data-mathml="&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;&gt;&lt;mrow&gt;&lt;mover accent=&quot;true&quot;&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;Z&lt;/mi&gt;&lt;mo&gt;^&lt;/mo&gt;&lt;/mover&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;munder&gt;&lt;mo form=&quot;prefix&quot;&gt;argmin&lt;/mo&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;Z&lt;/mi&gt;&lt;/munder&gt;&lt;mstyle scriptlevel=&quot;0&quot; displaystyle=&quot;true&quot;&gt;&lt;munderover&gt;&lt;mo&gt;&amp;#x2211;&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/munderover&gt;&lt;/mstyle&gt;&lt;msup&gt;&lt;mfenced separators=&quot;&quot; open=&quot;(&quot; close=&quot;)&quot;&gt;&lt;msup&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;z&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;mo&gt;-&lt;/mo&gt;&lt;munderover&gt;&lt;mo&gt;&amp;#x2211;&lt;/mo&gt;&lt;mrow&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;/munderover&gt;&lt;msub&gt;&lt;mover accent=&quot;true&quot;&gt;&lt;mi&gt;w&lt;/mi&gt;&lt;mo&gt;^&lt;/mo&gt;&lt;/mover&gt;&lt;mrow&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mo&gt;,&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;msup&gt;&lt;mi mathvariant=&quot;bold&quot;&gt;z&lt;/mi&gt;&lt;mrow&gt;&lt;mo&gt;(&lt;/mo&gt;&lt;mi&gt;j&lt;/mi&gt;&lt;mo&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;/msup&gt;&lt;/mfenced&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;/math&gt;" role="presentation"><nobr aria-hidden="true"><span class="math" id="MathJax-Span-4187" style="width: 16.661em; display: inline-block;"><span style="display: inline-block; position: relative; width: 16.147em; height: 0px; font-size: 103%;"><span style="position: absolute; clip: rect(0.003em, 1016.15em, 3.602em, -1000.01em); top: -2.105em; left: 0em;"><span class="mrow" id="MathJax-Span-4188"><span class="mrow" id="MathJax-Span-4189"><span class="mover" id="MathJax-Span-4190"><span style="display: inline-block; position: relative; width: 0.722em; height: 0px;"><span style="position: absolute; clip: rect(3.19em, 1000.63em, 4.167em, -1000.01em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-4191" style="font-family: MathJax_Main-bold;">Z</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.139em, 1000.58em, 3.602em, -1000.01em); top: -4.265em; left: 0.054em;"><span class="mo" id="MathJax-Span-4192" style=""><span style="font-family: MathJax_Size1;">ˆ</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-4193" style="font-family: MathJax_Main; padding-left: 0.26em;">=</span><span class="munder" id="MathJax-Span-4194" style="padding-left: 0.311em; padding-right: 0.311em;"><span style="display: inline-block; position: relative; width: 3.036em; height: 0px;"><span style="position: absolute; clip: rect(3.19em, 1003.04em, 4.373em, -1000.01em); top: -4.008em; left: 0em;"><span class="mo" id="MathJax-Span-4195" style="font-family: MathJax_Main;">argmin</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.396em, 1000.47em, 4.27em, -1000.01em); top: -3.134em; left: 1.288em;"><span class="mi" id="MathJax-Span-4196" style="font-size: 70.7%; font-family: MathJax_Main-bold;">Z</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mstyle" id="MathJax-Span-4197"><span class="mrow" id="MathJax-Span-4198"><span class="munderover" id="MathJax-Span-4199"><span style="display: inline-block; position: relative; width: 1.442em; height: 0px;"><span style="position: absolute; clip: rect(2.933em, 1001.4em, 4.63em, -1000.01em); top: -4.008em; left: 0em;"><span class="mo" id="MathJax-Span-4200" style="font-family: MathJax_Size2; vertical-align: 0em;">∑</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.396em, 1001.09em, 4.27em, -1000.01em); top: -2.928em; left: 0.157em;"><span class="mrow" id="MathJax-Span-4201"><span class="mi" id="MathJax-Span-4202" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mo" id="MathJax-Span-4203" style="font-size: 70.7%; font-family: MathJax_Main;">=</span><span class="mn" id="MathJax-Span-4204" style="font-size: 70.7%; font-family: MathJax_Main;">1</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.447em, 1000.63em, 4.167em, -1000.01em); top: -5.139em; left: 0.414em;"><span class="mi" id="MathJax-Span-4205" style="font-size: 70.7%; font-family: MathJax_Math-italic;">m</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span></span><span class="msup" id="MathJax-Span-4206" style="padding-left: 0.157em;"><span style="display: inline-block; position: relative; width: 9.154em; height: 0px;"><span style="position: absolute; clip: rect(2.162em, 1008.5em, 5.555em, -1000.01em); top: -4.059em; left: 0em;"><span class="mfenced" id="MathJax-Span-4207"><span class="mo" id="MathJax-Span-4208" style="vertical-align: 0em;"><span style="font-family: MathJax_Size4;">(</span></span><span class="msup" id="MathJax-Span-4209"><span style="display: inline-block; position: relative; width: 1.391em; height: 0px;"><span style="position: absolute; clip: rect(3.396em, 1000.47em, 4.167em, -1000.01em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-4210" style="font-family: MathJax_Main-bold;">z</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -4.419em; left: 0.517em;"><span class="mrow" id="MathJax-Span-4211"><span class="mo" id="MathJax-Span-4212" style="font-size: 70.7%; font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-4213" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mo" id="MathJax-Span-4214" style="font-size: 70.7%; font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-4215" style="font-family: MathJax_Main; padding-left: 0.208em;">−</span><span class="munderover" id="MathJax-Span-4216" style="padding-left: 0.208em;"><span style="display: inline-block; position: relative; width: 1.442em; height: 0px;"><span style="position: absolute; clip: rect(2.933em, 1001.4em, 4.63em, -1000.01em); top: -4.008em; left: 0em;"><span class="mo" id="MathJax-Span-4217" style="font-family: MathJax_Size2; vertical-align: 0em;">∑</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.396em, 1001.14em, 4.424em, -1000.01em); top: -2.928em; left: 0.105em;"><span class="mrow" id="MathJax-Span-4218"><span class="mi" id="MathJax-Span-4219" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span><span class="mo" id="MathJax-Span-4220" style="font-size: 70.7%; font-family: MathJax_Main;">=</span><span class="mn" id="MathJax-Span-4221" style="font-size: 70.7%; font-family: MathJax_Main;">1</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.447em, 1000.63em, 4.167em, -1000.01em); top: -5.139em; left: 0.414em;"><span class="mi" id="MathJax-Span-4222" style="font-size: 70.7%; font-family: MathJax_Math-italic;">m</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="msub" id="MathJax-Span-4223" style="padding-left: 0.157em;"><span style="display: inline-block; position: relative; width: 1.545em; height: 0px;"><span style="position: absolute; clip: rect(3.087em, 1000.73em, 4.167em, -1000.01em); top: -4.008em; left: 0em;"><span class="mover" id="MathJax-Span-4224"><span style="display: inline-block; position: relative; width: 0.722em; height: 0px;"><span style="position: absolute; clip: rect(3.396em, 1000.68em, 4.167em, -1000.01em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-4225" style="font-family: MathJax_Math-italic;">w</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; clip: rect(3.139em, 1000.58em, 3.602em, -1000.01em); top: -4.008em; left: 0.157em;"><span class="mo" id="MathJax-Span-4226" style=""><span style="font-family: MathJax_Size1;">ˆ</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -3.854em; left: 0.722em;"><span class="mrow" id="MathJax-Span-4227"><span class="mi" id="MathJax-Span-4228" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mo" id="MathJax-Span-4229" style="font-size: 70.7%; font-family: MathJax_Main;">,</span><span class="mi" id="MathJax-Span-4230" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="msup" id="MathJax-Span-4231"><span style="display: inline-block; position: relative; width: 1.442em; height: 0px;"><span style="position: absolute; clip: rect(3.396em, 1000.47em, 4.167em, -1000.01em); top: -4.008em; left: 0em;"><span class="mi" id="MathJax-Span-4232" style="font-family: MathJax_Main-bold;">z</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span><span style="position: absolute; top: -4.419em; left: 0.517em;"><span class="mrow" id="MathJax-Span-4233"><span class="mo" id="MathJax-Span-4234" style="font-size: 70.7%; font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-4235" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span><span class="mo" id="MathJax-Span-4236" style="font-size: 70.7%; font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span><span class="mo" id="MathJax-Span-4237" style="vertical-align: 0em;"><span style="font-family: MathJax_Size4;">)</span></span></span><span style="display: inline-block; width: 0px; height: 4.064em;"></span></span><span style="position: absolute; top: -5.499em; left: 8.692em;"><span class="mn" id="MathJax-Span-4238" style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span style="display: inline-block; width: 0px; height: 4.013em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.111em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.427em; border-left: 0px solid; width: 0px; height: 3.498em;"></span></span></nobr><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mover accent="true"><mi mathvariant="bold">Z</mi><mo>^</mo></mover><mo>=</mo><munder><mo form="prefix">argmin</mo><mi mathvariant="bold">Z</mi></munder><mstyle scriptlevel="0" displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover></mstyle><msup><mfenced separators="" open="(" close=")"><msup><mi mathvariant="bold">z</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup><mo>-</mo><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><msub><mover accent="true"><mi>w</mi><mo>^</mo></mover><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><msup><mi mathvariant="bold">z</mi><mrow><mo>(</mo><mi>j</mi><mo>)</mo></mrow></msup></mfenced><mn>2</mn></msup></mrow></math></span></span></div><script type="math/mml" id="MathJax-Element-103"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
  <mrow>
    <mover accent="true"><mi mathvariant="bold">Z</mi> <mo>^</mo></mover>
    <mo>=</mo>
    <munder><mo form="prefix">argmin</mo> <mi mathvariant="bold">Z</mi></munder>
    <mstyle scriptlevel="0" displaystyle="true">
      <munderover><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>m</mi> </munderover>
    </mstyle>
    <msup><mfenced separators="" open="(" close=")"><msup><mi mathvariant="bold">z</mi> <mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow> </msup><mo>-</mo><munderover><mo>∑</mo> <mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow> <mi>m</mi> </munderover><msub><mover accent="true"><mi>w</mi> <mo>^</mo></mover> <mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow> </msub><msup><mi mathvariant="bold">z</mi> <mrow><mo>(</mo><mi>j</mi><mo>)</mo></mrow> </msup></mfenced> <mn>2</mn> </msup>
  </mrow>
</math></script>
</div>

<p>Scikit-Learn’s LLE implementation has the following computational complexity: <span class="keep-together"><em>O</em>(<em>m</em> log(<em>m</em>)<em>n</em> log(<em>k</em>))</span> for finding the <em>k</em> nearest neighbors, <em>O</em>(<em>mnk</em><sup>3</sup>) for optimizing the weights, and <em>O</em>(<em>dm</em><sup>2</sup>) for constructing the low-dimensional representations. Unfortunately, the <em>m</em><sup>2</sup> in the last term makes this algorithm scale poorly to very large datasets.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Other Dimensionality Reduction Techniques"><div class="sect1" id="idm46263520559768">
<h1>Other Dimensionality Reduction Techniques</h1>

<p>There are many other dimensionality reduction techniques, several of which are available in Scikit-Learn. Here are some of the most popular ones:</p>
<dl>
<dt>Random Projections</dt>
<dd>
<p>As its name suggests, projects the data to a lower dimensional space using a random linear projection. This may sound crazy, but it turns out that such a random projection is actually very likely to preserve distances well, as was demonstrated mathematically by Johnson-Lindenstrauss in a famous lemma. The quality of the dimensionality reduction depends on the number of instances and the target dimensionality, but surprisingly not on the initial dimensionality. Check out the documentation for the <code>sklearn.random_projection</code> package for more details.</p>
</dd>
<dt>Multidimensional Scaling (MDS)</dt>
<dd>
<p>Reduces dimensionality while trying to preserve the distances between the instances (see <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#other_dim_reduction_plot">Figure&nbsp;8-13</a>).</p>
</dd>
<dt>Isomap</dt>
<dd>
<p>Creates a graph by connecting each instance to its nearest neighbors, then reduces dimensionality while trying to preserve the <em>geodesic distances</em><sup><a data-type="noteref" id="idm46263520323752-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#idm46263520323752" class="totri-footnote">9</a></sup> between the instances.</p>
</dd>
<dt>t-Distributed Stochastic Neighbor Embedding (t-SNE)</dt>
<dd>
<p>Reduces dimensionality while trying to keep similar instances close and dissimilar instances apart. It is mostly used for visualization, in particular to visualize clusters of instances in high-dimensional space (e.g., to visualize the MNIST images in 2D).</p>
</dd>
<dt>Linear Discriminant Analysis (LDA)</dt>
<dd>
<p>Is a classification algorithm, but during training it learns the most discriminative axes between the classes, and these axes can then be used to define a hyperplane onto which to project the data. The benefit of this approach is that the projection will keep classes as far apart as possible, so LDA is a good technique to reduce dimensionality before running another classification algorithm such as an SVM classifier.</p>
</dd>
</dl>

<figure><div id="other_dim_reduction_plot" class="figure">
<img src="./Chapter8_files/mls2_0813.png" alt="mls2 0813" width="1440" height="493" data-mfp-src="/library/view/hands-on-machine-learning/9781492032632/assets/mls2_0813.png">
<h6><span class="label">Figure 8-13. </span>Using various techniques to reduce the Swill roll to 2D</h6>
</div></figure>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Exercises"><div class="sect1" id="idm46263520317336">
<h1>Exercises</h1>
<ol>
<li>
<p>What are the main motivations for reducing a dataset’s dimensionality? What are the main drawbacks?</p>
</li>
<li>
<p>What is the curse of dimensionality?</p>
</li>
<li>
<p>Once a dataset’s dimensionality has been reduced, is it possible to reverse the operation? If so, how? If not, why?</p>
</li>
<li>
<p>Can PCA be used to reduce the dimensionality of a highly nonlinear dataset?</p>
</li>
<li>
<p>Suppose you perform PCA on a 1,000-dimensional dataset, setting the explained variance ratio to 95%. How many dimensions will the resulting dataset have?</p>
</li>
<li>
<p>In what cases would you use vanilla PCA, Incremental PCA, Randomized PCA, or Kernel PCA?</p>
</li>
<li>
<p>How can you evaluate the performance of a dimensionality reduction algorithm on your dataset?</p>
</li>
<li>
<p>Does it make any sense to chain two different dimensionality reduction algorithms?</p>
</li>
<li>
<p>Load the MNIST dataset (introduced in <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch03.html#classification_chapter">Chapter&nbsp;3</a>) and split it into a training set and a test set (take the first 60,000 instances for training, and the remaining 10,000 for testing). Train a Random Forest classifier on the dataset and time how long it takes, then evaluate the resulting model on the test set. Next, use PCA to reduce the dataset’s dimensionality, with an explained variance ratio of 95%. Train a new Random Forest classifier on the reduced dataset and see how long it takes. Was training much faster? Next, evaluate the classifier on the test set. How does it compare to the previous classifier?</p>
</li>
<li>
<p>Use t-SNE to reduce the MNIST dataset down to two dimensions and plot the result using Matplotlib. You can use a scatterplot using 10 different colors to represent each image’s target class. Alternatively, you can replace each dot in the scatterplot with the corresponding instance’s class (a digit from 0 to 9), or even plot scaled-down versions of the digit images themselves (if you plot all digits, the visualization will be too cluttered, so you should either draw a random sample or plot an instance only if no other instance has already been plotted at a close distance). You should get a nice visualization with well-separated clusters of digits. Try using other dimensionality reduction algorithms such as PCA, LLE, or MDS and compare the resulting visualizations.</p>
</li>

</ol>

<p>Solutions to these exercises are available in <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/app01.html#solutions_appendix">Appendix&nbsp;A</a>.</p>
</div></section>







<div data-type="footnotes"><p data-type="footnote" id="idm46263521548712"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#idm46263521548712-marker" class="totri-footnote">1</a></sup> Well, four dimensions if you count time, and a few more if you are a string theorist.</p><p data-type="footnote" id="idm46263521545256"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#idm46263521545256-marker" class="totri-footnote">2</a></sup> Watch a rotating tesseract projected into 3D space at <a href="https://homl.info/30"><em class="hyperlink">https://homl.info/30</em></a>. Image by Wikipedia user NerdBoy1392 (<a href="https://creativecommons.org/licenses/by-sa/3.0/">Creative Commons BY-SA 3.0</a>). Reproduced from <a href="https://en.wikipedia.org/wiki/Tesseract"><em class="hyperlink">https://en.wikipedia.org/wiki/Tesseract</em></a>.</p><p data-type="footnote" id="idm46263521540504"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#idm46263521540504-marker" class="totri-footnote">3</a></sup> Fun fact: anyone you know is probably an extremist in at least one dimension (e.g., how much sugar they put in their coffee), if you consider enough dimensions.</p><p data-type="footnote" id="idm46263521483912"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#idm46263521483912-marker" class="totri-footnote">4</a></sup> Karl Pearson, “On Lines and Planes of Closest Fit to Systems of Points in Space,” The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science 2, no. 11 (1901): 559-572, <a href="https://doi.org/10.1080/14786440109462720"><em class="hyperlink">https://doi.org/10.1080/14786440109462720</em></a>.</p><p data-type="footnote" id="idm46263521027480"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#idm46263521027480-marker" class="totri-footnote">5</a></sup> Scikit-Learn uses the algorithm described in David A. Ross et al., “Incremental Learning for Robust Visual Tracking,” International Journal of Computer Vision 77, no. 1–3 (May 2008): 125–141.</p><p data-type="footnote" id="idm46263520871048"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#idm46263520871048-marker" class="totri-footnote">6</a></sup> Bernhard Schölkopf et al., “Kernel Principal Component Analysis,” in <em>Lecture Notes in Computer Science</em> 1327 (Berlin: Springer, 1997): 583–588.</p><p data-type="footnote" id="idm46263520665112"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#idm46263520665112-marker" class="totri-footnote">7</a></sup> If you set fit_inverse_transform = True, Scikit-Learn will use the algorithm described in Gokhan H. Bakır et at., <a href="https://homl.info/34">Learning to Find Pre-Images</a> (Tubingen, Germany: Max Planck Institute for Biological Cybernetics, 2004), which is based on Kernel Ridge Regression.</p><p data-type="footnote" id="idm46263520557832"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#idm46263520557832-marker" class="totri-footnote">8</a></sup> Sam T. Roweis and Lawrence K. Saul, “Nonlinear Dimensionality Reduction by Locally Linear Embedding,” Science 290, no. 5500 (December 2000): 2323–2326.</p><p data-type="footnote" id="idm46263520323752"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#idm46263520323752-marker" class="totri-footnote">9</a></sup> The geodesic distance between two nodes in a graph is the number of nodes on the shortest path between these nodes.</p></div></div></section><div class="annotator-outer annotator-viewer viewer annotator-hide">
  <ul class="annotator-widget annotator-listing"></ul>
</div><div class="annotator-modal-wrapper annotator-editor-modal annotator-editor annotator-hide">
	<div class="annotator-outer editor">
		<h2 class="title">Highlight</h2>
		<form class="annotator-widget">
			<ul class="annotator-listing">
			<li class="annotator-item"><textarea id="annotator-field-8" placeholder="Add a note using markdown (optional)" class="js-editor" maxlength="750"></textarea></li></ul>
			<div class="annotator-controls">
				<a class="link-to-markdown" href="https://daringfireball.net/projects/markdown/basics" target="_blank">?</a>
				<ul>
					<li class="delete annotator-hide"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#delete" class="annotator-delete-note button positive">Delete Note</a></li>
					<li class="save"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#save" class="annotator-save annotator-focus button positive">Save Note</a></li>
					<li class="cancel"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#cancel" class="annotator-cancel button">Cancel</a></li>
				</ul>
			</div>
		</form>
	</div>
</div><div class="annotator-modal-wrapper annotator-delete-confirm-modal" style="display: none;">
  <div class="annotator-outer">
    <h2 class="title">Highlight</h2>
      <a class="js-close-delete-confirm annotator-cancel close" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#close">Close</a>
      <div class="annotator-widget">
         <div class="delete-confirm">
            Are you sure you want to permanently delete this note?
         </div>
         <div class="annotator-controls">
            <a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#cancel" class="annotator-cancel button js-cancel-delete-confirm">No, I changed my mind</a>
            <a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#delete" class="annotator-delete button positive js-delete-confirm">Yes, delete it</a>
         </div>
       </div>
   </div>
</div><div class="annotator-adder" style="display: none;">
	<ul class="adders">
		
		<li class="copy"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#">Copy</a></li>
		
		<li class="add-highlight"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#">Add Highlight</a></li>
		<li class="add-note"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#">
			Add Note
		</a></li>
		
	</ul>
</div></div></div>



  <div class="t-sbo-prev sbo-prev sbo-nav-bottom">
  
    
      
        <a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch07.html" class="prev nav-link">
      
          <span aria-hidden="true" class="pagination-label t-prev-label">Prev</span>
          <span class="visuallyhidden">Previous Chapter</span>
          <div class="pagination-title t-prev-title">7. Ensemble Learning and Random Forests</div>
        </a>
    
  
  </div>

  <div class="t-sbo-next sbo-next sbo-nav-bottom">
  
    
      
        <a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch09.html" class="next nav-link">
      
          <span aria-hidden="true" class="pagination-label t-next-label">Next</span>
          <span class="visuallyhidden">Next Chapter</span>
          <div class="pagination-title t-next-title">9. Unsupervised Learning Techniques</div>
        </a>
    
  
  </div>

</section>
  </div>
<section class="sbo-saved-archives"></section>



          
          
  




    
    



        
      </div>
      



  <footer class="pagefoot">
    <a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#" class="icon-up" style="display: none;"><div class="visuallyhidden">Back to top</div></a>
    <ul class="js-footer-nav">
      <li class="full-support"><a href="https://www.oreilly.com/online-learning/support/">Support</a></li>
      <li><a href="https://www.oreilly.com/online-learning/apps.html">Get the App</a></li>
      
        <li><a href="https://learning.oreilly.com/accounts/logout/">Sign Out</a></li>
      
    </ul>
    <span class="copyright">© 2019 <a href="https://learning.oreilly.com/" target="_blank">Safari</a>.</span>
    <a href="https://learning.oreilly.com/terms/">Terms of Service</a> /
    <a href="https://learning.oreilly.com/membership-agreement/">Membership Agreement</a> /
    <a href="https://www.oreilly.com/privacy.html">Privacy Policy</a>
  </footer>

<script type="text/javascript">window.NREUM||(NREUM={});NREUM.info={"applicationID":"172641827,79672898,93931619","errorBeacon":"bam.nr-data.net","agent":"","applicationTime":451,"licenseKey":"510f1a6865","transactionName":"YgdaZ0NSW0cEB0RdWltNfkZfUEFdCgofXFBHDVYdR1pQQxZeRl1QQj1aWkU=","beacon":"bam.nr-data.net","queueTime":4}</script>


    
    <script src="./Chapter8_files/saved_resource" charset="utf-8"></script><script type="text/javascript" id="">!function(b,e,f,g,a,c,d){b.fbq||(a=b.fbq=function(){a.callMethod?a.callMethod.apply(a,arguments):a.queue.push(arguments)},b._fbq||(b._fbq=a),a.push=a,a.loaded=!0,a.version="2.0",a.queue=[],c=e.createElement(f),c.async=!0,c.src=g,d=e.getElementsByTagName(f)[0],d.parentNode.insertBefore(c,d))}(window,document,"script","https://connect.facebook.net/en_US/fbevents.js");fbq("init","1732687426968531");fbq("track","PageView");</script>
<noscript><img height="1" width="1" style="display:none" src="https://www.facebook.com/tr?id=1732687426968531&amp;ev=PageView&amp;noscript=1"></noscript><script type="text/javascript" id="">(function(){window.medalliaUserIdentifier=document.documentElement.dataset.userUuid;window.medalliaUserName=document.documentElement.dataset.username})();</script>
<script type="text/javascript" id="" src="./Chapter8_files/embed.js.download"></script><script type="text/javascript" id="">adroll_adv_id="BOHFZPCX5ZAM5LXWJURNUB";adroll_pix_id="3QFV44ZHVZG53BOB75QP3D";
(function(){var a=function(){if(document.readyState&&!/loaded|complete/.test(document.readyState))setTimeout(a,10);else if(window.__adroll_loaded){var b=document.createElement("script"),c="https:"==document.location.protocol?"https://s.adroll.com":"http://a.adroll.com";b.setAttribute("async","true");b.type="text/javascript";b.src=c+"/j/roundtrip.js";((document.getElementsByTagName("head")||[null])[0]||document.getElementsByTagName("script")[0].parentNode).appendChild(b)}else __adroll_loaded=!0,setTimeout(a,
50)};window.addEventListener?window.addEventListener("load",a,!1):window.attachEvent("onload",a)})();</script><script type="text/javascript" id="">adroll_adv_id="BOHFZPCX5ZAM5LXWJURNUB";adroll_pix_id="3QFV44ZHVZG53BOB75QP3D";
(function(){var a=function(){if(document.readyState&&!/loaded|complete/.test(document.readyState))setTimeout(a,10);else if(window.__adroll_loaded){var b=document.createElement("script"),c="https:"==document.location.protocol?"https://s.adroll.com":"http://a.adroll.com";b.setAttribute("async","true");b.type="text/javascript";b.src=c+"/j/roundtrip.js";((document.getElementsByTagName("head")||[null])[0]||document.getElementsByTagName("script")[0].parentNode).appendChild(b)}else __adroll_loaded=!0,setTimeout(a,
50)};window.addEventListener?window.addEventListener("load",a,!1):window.attachEvent("onload",a)})();</script>
<script type="text/javascript" id="">!function(b,e,f,g,a,c,d){b.fbq||(a=b.fbq=function(){a.callMethod?a.callMethod.apply(a,arguments):a.queue.push(arguments)},b._fbq||(b._fbq=a),a.push=a,a.loaded=!0,a.version="2.0",a.queue=[],c=e.createElement(f),c.async=!0,c.src=g,d=e.getElementsByTagName(f)[0],d.parentNode.insertBefore(c,d))}(window,document,"script","https://connect.facebook.net/en_US/fbevents.js");fbq("init","443792972845831");fbq("set","agent","tmgoogletagmanager","443792972845831");fbq("track","PageView");</script>
<noscript><img height="1" width="1" style="display:none" src="https://www.facebook.com/tr?id=443792972845831&amp;ev=PageView&amp;noscript=1"></noscript>

<script type="text/javascript" id="">!function(b,e,f,g,a,c,d){b.fbq||(a=b.fbq=function(){a.callMethod?a.callMethod.apply(a,arguments):a.queue.push(arguments)},b._fbq||(b._fbq=a),a.push=a,a.loaded=!0,a.version="2.0",a.queue=[],c=e.createElement(f),c.async=!0,c.src=g,d=e.getElementsByTagName(f)[0],d.parentNode.insertBefore(c,d))}(window,document,"script","https://connect.facebook.net/en_US/fbevents.js");fbq("init","443792972845831");fbq("track","PageView");</script>
<noscript><img height="1" width="1" style="display:none" src="https://www.facebook.com/tr?id=443792972845831&amp;ev=PageView&amp;noscript=1"></noscript>
<div style="width:0px; height:0px; display:none; visibility:hidden;" id="batBeacon0.09556792590964802"><img style="width:0px; height:0px; display:none; visibility:hidden;" id="batBeacon0.5229133033930915" width="0" height="0" alt="" src="./Chapter8_files/0"></div>
    <script src="./Chapter8_files/saved_resource(1)" charset="utf-8"></script>
  

<script src="./Chapter8_files/saved_resource(2)" type="text/javascript"></script><script type="text/javascript" id="">window._pp=window._pp||[];if("\/library\/view\/hands-on-machine-learning\/9781492032632\/part01.html"=="/confirmation/nnv/"&&"https:\/\/learning.oreilly.com\/library\/view\/hands-on-machine-learning\/9781492032632\/"=="https://learning.oreilly.com/register/")_pp.targetUrl="/confirm/trial";else if("\/library\/view\/hands-on-machine-learning\/9781492032632\/part01.html"=="/confirmation/nv/"&&"https:\/\/learning.oreilly.com\/library\/view\/hands-on-machine-learning\/9781492032632\/"=="https://learning.oreilly.com/subscribe/")_pp.targetUrl="/confirm/paid";else if("\/library\/view\/hands-on-machine-learning\/9781492032632\/part01.html"=="/confirmation/nnv/"&&"https:\/\/learning.oreilly.com\/library\/view\/hands-on-machine-learning\/9781492032632\/"=="https://learning.oreilly.com/signup/")_pp.targetUrl="/confirm/paid";_pp.siteId="2508";
_pp.siteUId="d59baa21-c0cd-4fcf-9c68-a2b8d4f52a79";_pp.orderValue="undefined";_pp.orderId="undefined";(function(){var ppjs=document.createElement("script");ppjs.type="text/javascript";ppjs.async=true;ppjs.src=("https:"==document.location.protocol?"https:":"http:")+"//cdn.pbbl.co/r/"+_pp.siteId+".js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(ppjs,s)})();</script><div class="annotator-notice"></div><div class="font-flyout" style="top: 201px; left: 1194px;"><div class="font-controls-panel">
	<div class="nightmodes">
		<ul>
			<li class="day"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#" id="day-mode" title="Day Mode">
				<i class="fa fa-sun-o"></i>
				<span>Day Mode</span></a></li>
			<li class="cloudy"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#" id="cloudy-mode" title="Cloudy Mode">
				<i class="fa fa-cloud"></i>
				<span>Cloud Mode</span>
			</a></li>
			<li class="night"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#" id="night-mode" title="Night Mode">
				<i class="fa fa-moon-o"></i>
				<span>Night Mode</span>
			</a></li>
		</ul>
	</div>

	<div class="font-resizer resizer">
		<div class="draggable-containment-wrapper">
			<i class="fa fa-font left"></i>
			<span class="filler" style="width: 50%;"></span>
			<div id="js-font-size-draggable" class="draggable ui-widget-content ui-draggable ui-draggable-handle" style="position: relative; left: 80px;"></div>
			<i class="fa fa-font right"></i>
		</div>
	</div>

	<div class="column-resizer resizer">
		<div class="draggable-containment-wrapper">
			<i class="fa fa-compress left"></i>
			<span class="filler" style="width: 50%;"></span>
			<div id="js-column-size-draggable" class="draggable ui-widget-content ui-draggable ui-draggable-handle" style="position: relative; left: 80px;"></div>
			<i class="fa fa-expand right"></i>
		</div>
	</div>

	<a id="reset" class="button" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch08.html#">Reset</a>
</div>
</div><script type="text/javascript" async="" src="./Chapter8_files/generic1566415868241.js.download" charset="UTF-8"></script><div style="display: none; visibility: hidden;"><script>(function(){if(null!==document.querySelector('iframe[title\x3d"fb:share_button Facebook Social Plugin"]')&&void 0!==document.querySelector('iframe[title\x3d"fb:share_button Facebook Social Plugin"]')){var a=!1;window.addEventListener("blur",function(){a&&dataLayer.push({event:"eventTracker",eventCat:"social",eventAct:"share",eventLbl:"facebook",eventVal:0,nonInteraction:0})});document.querySelector('iframe[title\x3d"fb:share_button Facebook Social Plugin"]').addEventListener("mouseover",function(){window.focus();
a=!0});document.querySelector('iframe[title\x3d"fb:share_button Facebook Social Plugin"]').addEventListener("mouseout",function(){a=!1})}try{window.twttr=function(b,a,d){var c,e=b.getElementsByTagName(a)[0];if(!b.getElementById(d))return b=b.createElement(a),b.id=d,b.src="//platform.twitter.com/widgets.js",e.parentNode.insertBefore(b,e),window.twttr||(c={_e:[],ready:function(a){c._e.push(a)}})}(document,"script","twitter-wjs"),twttr.ready(function(a){a.events.bind("tweet",trackTwitter)})}catch(b){}})();
null!==document.querySelector(".IN-widget")&&void 0!==document.querySelector(".IN-widget")&&document.querySelector(".IN-widget").addEventListener("click",function(){dataLayer.push({event:"eventTracker",eventCat:"social",eventAct:"share",eventLbl:"linkedin",eventVal:0,nonInteraction:0})});
function trackTwitter(a){a&&(a.target&&"IFRAME"==a.target.nodeName&&(opt_target=extractParamFromUri(a.target.src,"url")),dataLayer.push({event:"eventTracker",eventCat:"social",eventAct:"share",eventLbl:"twitter",eventVal:0,nonInteraction:0}))}function extractParamFromUri(a,b){if(a){var c=new RegExp("[\\?\x26#]"+b+"\x3d([^\x26#]*)");c=c.exec(a);if(null!=c)return unescape(c[1])}};</script></div><span><div id="KampyleAnimationContainer" style="z-index: 2147483000; border: 0px; position: fixed; display: block; width: 0px; height: 0px;"></div></span><iframe scrolling="no" frameborder="0" allowtransparency="true" src="./Chapter8_files/widget_iframe.097c1f5038f9e8a0d62a39a892838d66.html" title="Twitter settings iframe" style="display: none;"></iframe><div style="position: absolute; width: 0px; height: 0px; overflow: hidden; padding: 0px; border: 0px; margin: 0px;"><div id="MathJax_Font_Test" style="position: absolute; visibility: hidden; top: 0px; left: 0px; width: auto; padding: 0px; border: 0px; margin: 0px; white-space: nowrap; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; font-size: 40px; font-weight: normal; font-style: normal; font-family: MathJax_Size3, sans-serif;"></div></div></body></html>