<!DOCTYPE html>
<!-- saved from url=(0091)https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html -->
<html class=" js flexbox flexboxlegacy no-touch websqldatabase indexeddb history csscolumns csstransforms localstorage sessionstorage applicationcache svg inlinesvg zoom" lang="en" prefix="og: http://ogp.me/ns/# og:book: http://ogp.me/ns/book# og:video: http://ogp.me/ns/video#" itemscope="" itemtype="http://schema.org/Book http://schema.org/ItemPage" data-login-url="/accounts/login/" data-offline-url="/" data-url="/library/view/hands-on-machine-learning/9781492032632/part01.html" data-csrf-cookie="csrfsafari" data-highlight-privacy="" data-user-id="4626953" data-user-uuid="d59baa21-c0cd-4fcf-9c68-a2b8d4f52a79" data-username="17481074" data-account-type="B2B" data-activated-trial-date="" data-archive="9781492032632" data-publishers="O&#39;Reilly Media, Inc." data-htmlfile-name="part01.html" data-epub-title="Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition" data-debug="0" data-testing="0" style=""><!--<![endif]--><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="author" content="Safari Books Online"><meta name="format-detection" content="telephone=no"><meta http-equiv="cleartype" content="on"><meta name="HandheldFriendly" content="True"><meta name="MobileOptimized" content="320"><meta name="apple-itunes-app" content="app-id=881697395, app-argument=safaridetail://9781492032632"><meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, maximum-scale=1.0"><meta property="twitter:account_id" content="4503599627559754"><script type="text/javascript" async="" src="./Chapter13_files/cool-2.1.15.min.js.download"></script><script type="text/javascript" src="./Chapter13_files/510f1a6865"></script><script id="twitter-wjs" src="./Chapter13_files/widgets.js.download"></script><script src="./Chapter13_files/nr-1130.min.js.download"></script><script type="text/javascript" async="" src="./Chapter13_files/2508.js.download"></script><script async="" src="./Chapter13_files/fbevents.js.download"></script><script type="text/javascript" async="" src="./Chapter13_files/f.txt"></script><script type="text/javascript" async="" src="./Chapter13_files/f.txt"></script><script type="text/javascript" async="" src="./Chapter13_files/f.txt"></script><script type="text/javascript" async="" src="./Chapter13_files/analytics.js.download"></script><script type="text/javascript" async="" src="./Chapter13_files/ec.js.download"></script><script type="text/javascript" async="" src="./Chapter13_files/bat.js.download"></script><script type="text/javascript" async="" src="./Chapter13_files/f.txt"></script><script type="text/javascript" async="" src="./Chapter13_files/insight.min.js.download"></script><script type="text/javascript" async="" src="./Chapter13_files/f.txt"></script><script type="text/javascript" async="" src="./Chapter13_files/linkid.js.download"></script><script async="" src="./Chapter13_files/gtm.js.download"></script><script async="" src="./Chapter13_files/analytics.js.download"></script><script type="text/javascript">window.NREUM||(NREUM={}),__nr_require=function(e,n,t){function r(t){if(!n[t]){var o=n[t]={exports:{}};e[t][0].call(o.exports,function(n){var o=e[t][1][n];return r(o||n)},o,o.exports)}return n[t].exports}if("function"==typeof __nr_require)return __nr_require;for(var o=0;o<t.length;o++)r(t[o]);return r}({1:[function(e,n,t){function r(){}function o(e,n,t){return function(){return i(e,[c.now()].concat(u(arguments)),n?null:this,t),n?void 0:this}}var i=e("handle"),a=e(3),u=e(4),f=e("ee").get("tracer"),c=e("loader"),s=NREUM;"undefined"==typeof window.newrelic&&(newrelic=s);var p=["setPageViewName","setCustomAttribute","setErrorHandler","finished","addToTrace","inlineHit","addRelease"],d="api-",l=d+"ixn-";a(p,function(e,n){s[n]=o(d+n,!0,"api")}),s.addPageAction=o(d+"addPageAction",!0),s.setCurrentRouteName=o(d+"routeName",!0),n.exports=newrelic,s.interaction=function(){return(new r).get()};var m=r.prototype={createTracer:function(e,n){var t={},r=this,o="function"==typeof n;return i(l+"tracer",[c.now(),e,t],r),function(){if(f.emit((o?"":"no-")+"fn-start",[c.now(),r,o],t),o)try{return n.apply(this,arguments)}catch(e){throw f.emit("fn-err",[arguments,this,e],t),e}finally{f.emit("fn-end",[c.now()],t)}}}};a("actionText,setName,setAttribute,save,ignore,onEnd,getContext,end,get".split(","),function(e,n){m[n]=o(l+n)}),newrelic.noticeError=function(e,n){"string"==typeof e&&(e=new Error(e)),i("err",[e,c.now(),!1,n])}},{}],2:[function(e,n,t){function r(e,n){if(!o)return!1;if(e!==o)return!1;if(!n)return!0;if(!i)return!1;for(var t=i.split("."),r=n.split("."),a=0;a<r.length;a++)if(r[a]!==t[a])return!1;return!0}var o=null,i=null,a=/Version\/(\S+)\s+Safari/;if(navigator.userAgent){var u=navigator.userAgent,f=u.match(a);f&&u.indexOf("Chrome")===-1&&u.indexOf("Chromium")===-1&&(o="Safari",i=f[1])}n.exports={agent:o,version:i,match:r}},{}],3:[function(e,n,t){function r(e,n){var t=[],r="",i=0;for(r in e)o.call(e,r)&&(t[i]=n(r,e[r]),i+=1);return t}var o=Object.prototype.hasOwnProperty;n.exports=r},{}],4:[function(e,n,t){function r(e,n,t){n||(n=0),"undefined"==typeof t&&(t=e?e.length:0);for(var r=-1,o=t-n||0,i=Array(o<0?0:o);++r<o;)i[r]=e[n+r];return i}n.exports=r},{}],5:[function(e,n,t){n.exports={exists:"undefined"!=typeof window.performance&&window.performance.timing&&"undefined"!=typeof window.performance.timing.navigationStart}},{}],ee:[function(e,n,t){function r(){}function o(e){function n(e){return e&&e instanceof r?e:e?f(e,u,i):i()}function t(t,r,o,i){if(!d.aborted||i){e&&e(t,r,o);for(var a=n(o),u=v(t),f=u.length,c=0;c<f;c++)u[c].apply(a,r);var p=s[y[t]];return p&&p.push([b,t,r,a]),a}}function l(e,n){h[e]=v(e).concat(n)}function m(e,n){var t=h[e];if(t)for(var r=0;r<t.length;r++)t[r]===n&&t.splice(r,1)}function v(e){return h[e]||[]}function g(e){return p[e]=p[e]||o(t)}function w(e,n){c(e,function(e,t){n=n||"feature",y[t]=n,n in s||(s[n]=[])})}var h={},y={},b={on:l,addEventListener:l,removeEventListener:m,emit:t,get:g,listeners:v,context:n,buffer:w,abort:a,aborted:!1};return b}function i(){return new r}function a(){(s.api||s.feature)&&(d.aborted=!0,s=d.backlog={})}var u="nr@context",f=e("gos"),c=e(3),s={},p={},d=n.exports=o();d.backlog=s},{}],gos:[function(e,n,t){function r(e,n,t){if(o.call(e,n))return e[n];var r=t();if(Object.defineProperty&&Object.keys)try{return Object.defineProperty(e,n,{value:r,writable:!0,enumerable:!1}),r}catch(i){}return e[n]=r,r}var o=Object.prototype.hasOwnProperty;n.exports=r},{}],handle:[function(e,n,t){function r(e,n,t,r){o.buffer([e],r),o.emit(e,n,t)}var o=e("ee").get("handle");n.exports=r,r.ee=o},{}],id:[function(e,n,t){function r(e){var n=typeof e;return!e||"object"!==n&&"function"!==n?-1:e===window?0:a(e,i,function(){return o++})}var o=1,i="nr@id",a=e("gos");n.exports=r},{}],loader:[function(e,n,t){function r(){if(!E++){var e=x.info=NREUM.info,n=l.getElementsByTagName("script")[0];if(setTimeout(s.abort,3e4),!(e&&e.licenseKey&&e.applicationID&&n))return s.abort();c(y,function(n,t){e[n]||(e[n]=t)}),f("mark",["onload",a()+x.offset],null,"api");var t=l.createElement("script");t.src="https://"+e.agent,n.parentNode.insertBefore(t,n)}}function o(){"complete"===l.readyState&&i()}function i(){f("mark",["domContent",a()+x.offset],null,"api")}function a(){return O.exists&&performance.now?Math.round(performance.now()):(u=Math.max((new Date).getTime(),u))-x.offset}var u=(new Date).getTime(),f=e("handle"),c=e(3),s=e("ee"),p=e(2),d=window,l=d.document,m="addEventListener",v="attachEvent",g=d.XMLHttpRequest,w=g&&g.prototype;NREUM.o={ST:setTimeout,SI:d.setImmediate,CT:clearTimeout,XHR:g,REQ:d.Request,EV:d.Event,PR:d.Promise,MO:d.MutationObserver};var h=""+location,y={beacon:"bam.nr-data.net",errorBeacon:"bam.nr-data.net",agent:"js-agent.newrelic.com/nr-1130.min.js"},b=g&&w&&w[m]&&!/CriOS/.test(navigator.userAgent),x=n.exports={offset:u,now:a,origin:h,features:{},xhrWrappable:b,userAgent:p};e(1),l[m]?(l[m]("DOMContentLoaded",i,!1),d[m]("load",r,!1)):(l[v]("onreadystatechange",o),d[v]("onload",r)),f("mark",["firstbyte",u],null,"api");var E=0,O=e(5)},{}]},{},["loader"]);</script><link rel="apple-touch-icon" href="https://learning.oreilly.com/static/images/apple-touch-icon.0c29511d2d72.png"><link rel="shortcut icon" href="https://learning.oreilly.com/favicon.ico" type="image/x-icon"><link href="./Chapter13_files/css" rel="stylesheet" type="text/css"><title>13. Loading and Preprocessing Data with TensorFlow - Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition</title><link rel="stylesheet" href="./Chapter13_files/output.68851547a55f.css" type="text/css"><link rel="stylesheet" type="text/css" href="./Chapter13_files/annotator.e3b0c44298fc.css"><link rel="stylesheet" href="./Chapter13_files/font-awesome.min.css"><style type="text/css" title="ibis-book">@charset "utf-8";#sbo-rt-content html,#sbo-rt-content div,#sbo-rt-content div,#sbo-rt-content span,#sbo-rt-content applet,#sbo-rt-content object,#sbo-rt-content iframe,#sbo-rt-content h1,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5,#sbo-rt-content h6,#sbo-rt-content p,#sbo-rt-content blockquote,#sbo-rt-content pre,#sbo-rt-content a,#sbo-rt-content abbr,#sbo-rt-content acronym,#sbo-rt-content address,#sbo-rt-content big,#sbo-rt-content cite,#sbo-rt-content code,#sbo-rt-content del,#sbo-rt-content dfn,#sbo-rt-content em,#sbo-rt-content img,#sbo-rt-content ins,#sbo-rt-content kbd,#sbo-rt-content q,#sbo-rt-content s,#sbo-rt-content samp,#sbo-rt-content small,#sbo-rt-content strike,#sbo-rt-content strong,#sbo-rt-content sub,#sbo-rt-content sup,#sbo-rt-content tt,#sbo-rt-content var,#sbo-rt-content b,#sbo-rt-content u,#sbo-rt-content i,#sbo-rt-content center,#sbo-rt-content dl,#sbo-rt-content dt,#sbo-rt-content dd,#sbo-rt-content ol,#sbo-rt-content ul,#sbo-rt-content li,#sbo-rt-content fieldset,#sbo-rt-content form,#sbo-rt-content label,#sbo-rt-content legend,#sbo-rt-content table,#sbo-rt-content caption,#sbo-rt-content tdiv,#sbo-rt-content tfoot,#sbo-rt-content thead,#sbo-rt-content tr,#sbo-rt-content th,#sbo-rt-content td,#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content canvas,#sbo-rt-content details,#sbo-rt-content embed,#sbo-rt-content figure,#sbo-rt-content figcaption,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content output,#sbo-rt-content ruby,#sbo-rt-content section,#sbo-rt-content summary,#sbo-rt-content time,#sbo-rt-content mark,#sbo-rt-content audio,#sbo-rt-content video{margin:0;padding:0;border:0;font-size:100%;font:inherit;vertical-align:baseline}#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content details,#sbo-rt-content figcaption,#sbo-rt-content figure,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content section{display:block}#sbo-rt-content div{line-height:1}#sbo-rt-content ol,#sbo-rt-content ul{list-style:none}#sbo-rt-content blockquote,#sbo-rt-content q{quotes:none}#sbo-rt-content blockquote:before,#sbo-rt-content blockquote:after,#sbo-rt-content q:before,#sbo-rt-content q:after{content:none}#sbo-rt-content table{border-collapse:collapse;border-spacing:0}@page{margin:5px !important}#sbo-rt-content p{margin:10px 0 0;line-height:125%;text-align:left}#sbo-rt-content p.byline{text-align:left;margin:-33px auto 35px;font-style:italic;font-weight:bold}#sbo-rt-content div.preface p+p.byline{margin:1em 0 0 !important}#sbo-rt-content div.preface p.byline+p.byline{margin:0 !important}#sbo-rt-content div.sect1>p.byline{margin:-.25em 0 1em}#sbo-rt-content div.sect1>p.byline+p.byline{margin-top:-1em}#sbo-rt-content em{font-style:italic;font-family:inherit}#sbo-rt-content em strong,#sbo-rt-content strong em{font-weight:bold;font-style:italic;font-family:inherit}#sbo-rt-content strong,#sbo-rt-content span.bold{font-weight:bold}#sbo-rt-content em.replaceable{font-style:italic}#sbo-rt-content strong.userinput{font-weight:bold;font-style:normal}#sbo-rt-content span.bolditalic{font-weight:bold;font-style:italic}#sbo-rt-content a.ulink,#sbo-rt-content a.xref,#sbo-rt-content a.email,#sbo-rt-content a.link,#sbo-rt-content a{text-decoration:none;color:#8e0012}#sbo-rt-content span.lineannotation{font-style:italic;color:#a62a2a;font-family:serif}#sbo-rt-content span.underline{text-decoration:underline}#sbo-rt-content span.strikethrough{text-decoration:line-through}#sbo-rt-content span.smallcaps{font-variant:small-caps}#sbo-rt-content span.cursor{background:#000;color:#fff}#sbo-rt-content span.smaller{font-size:75%}#sbo-rt-content .boxedtext,#sbo-rt-content .keycap{border-style:solid;border-width:1px;border-color:#000;padding:1px}#sbo-rt-content span.gray50{color:#7F7F7F;}#sbo-rt-content h1,#sbo-rt-content div.toc-title,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5{-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;font-weight:bold;text-align:left;page-break-after:avoid !important;font-family:sans-serif,"DejaVuSans"}#sbo-rt-content div.toc-title{font-size:1.5em;margin-top:20px !important;margin-bottom:30px !important}#sbo-rt-content section[data-type="sect1"] h1{font-size:1.3em;color:#8e0012;margin:40px 0 8px 0}#sbo-rt-content section[data-type="sect2"] h2{font-size:1.1em;margin:30px 0 8px 0 !important}#sbo-rt-content section[data-type="sect3"] h3{font-size:1em;color:#555;margin:20px 0 8px 0 !important}#sbo-rt-content section[data-type="sect4"] h4{font-size:1em;font-weight:normal;font-style:italic;margin:15px 0 6px 0 !important}#sbo-rt-content section[data-type="chapter"]>div>h1,#sbo-rt-content section[data-type="preface"]>div>h1,#sbo-rt-content section[data-type="appendix"]>div>h1,#sbo-rt-content section[data-type="glossary"]>div>h1,#sbo-rt-content section[data-type="bibliography"]>div>h1,#sbo-rt-content section[data-type="index"]>div>h1{font-size:2em;line-height:1;margin-bottom:50px;color:#000;padding-bottom:10px;border-bottom:1px solid #000}#sbo-rt-content span.label,#sbo-rt-content span.keep-together{font-size:inherit;font-weight:inherit}#sbo-rt-content div[data-type="part"] h1{font-size:2em;text-align:center;margin-top:0 !important;margin-bottom:50px;padding:50px 0 10px 0;border-bottom:1px solid #000}#sbo-rt-content img.width-ninety{width:90%}#sbo-rt-content img{max-width:95%;margin:0 auto;padding:0}#sbo-rt-content div.figure{background-color:transparent;text-align:center !important;margin:15px 0 15px 0 !important;page-break-inside:avoid}#sbo-rt-content figure{margin:15px 0 15px 0 !important;page-break-inside:avoid}#sbo-rt-content div.figure h6,#sbo-rt-content figure h6,#sbo-rt-content figure figcaption{font-size:.9rem !important;text-align:center;font-weight:normal !important;font-style:italic;font-family:serif !important;text-transform:none !important;letter-spacing:normal !important;color:#000 !important;padding-top:10px !important;page-break-before:avoid}#sbo-rt-content div.informalfigure{text-align:center !important;padding:5px 0 !important}#sbo-rt-content div.sidebar{margin:15px 0 10px 0 !important;border:1px solid #DCDCDC;background-color:#F7F7F7;padding:15px !important;page-break-inside:avoid}#sbo-rt-content aside[data-type="sidebar"]{margin:15px 0 10px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar-title,#sbo-rt-content aside[data-type="sidebar"] h5{font-weight:bold;font-size:1em;font-family:sans-serif;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar ol,#sbo-rt-content div.sidebar ul,#sbo-rt-content aside[data-type="sidebar"] ol,#sbo-rt-content aside[data-type="sidebar"] ul{margin-left:1.25em !important}#sbo-rt-content div.sidebar div.figure p.title,#sbo-rt-content aside[data-type="sidebar"] figcaption,#sbo-rt-content div.sidebar div.informalfigure div.caption{font-size:90%;text-align:center;font-weight:normal;font-style:italic;font-family:serif !important;color:#000;padding:5px !important;page-break-before:avoid;page-break-after:avoid}#sbo-rt-content div.sidebar div.tip,#sbo-rt-content div.sidebar div[data-type="tip"],#sbo-rt-content div.sidebar div.note,#sbo-rt-content div.sidebar div[data-type="note"],#sbo-rt-content div.sidebar div.warning,#sbo-rt-content div.sidebar div[data-type="warning"],#sbo-rt-content div.sidebar div[data-type="caution"],#sbo-rt-content div.sidebar div[data-type="important"]{margin:20px auto 20px auto !important;font-size:90%;width:85%}#sbo-rt-content aside[data-type="sidebar"] p.byline{font-size:90%;font-weight:bold;font-style:italic;text-align:center;text-indent:0;margin:5px auto 6px;page-break-after:avoid}#sbo-rt-content pre{white-space:pre-wrap;font-family:"Ubuntu Mono",monospace;margin:25px 0 25px 20px;font-size:85%;display:block;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content div.note pre.programlisting,#sbo-rt-content div.tip pre.programlisting,#sbo-rt-content div.warning pre.programlisting,#sbo-rt-content div.caution pre.programlisting,#sbo-rt-content div.important pre.programlisting{margin-bottom:0}#sbo-rt-content code{font-family:"Ubuntu Mono",monospace;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content code strong em,#sbo-rt-content code em strong,#sbo-rt-content pre em strong,#sbo-rt-content pre strong em,#sbo-rt-content strong code em code,#sbo-rt-content em code strong code,#sbo-rt-content span.bolditalic code{font-weight:bold;font-style:italic;font-family:"Ubuntu Mono BoldItal",monospace}#sbo-rt-content code em,#sbo-rt-content em code,#sbo-rt-content pre em,#sbo-rt-content em.replaceable{font-family:"Ubuntu Mono Ital",monospace;font-style:italic}#sbo-rt-content code strong,#sbo-rt-content strong code,#sbo-rt-content pre strong,#sbo-rt-content strong.userinput{font-family:"Ubuntu Mono Bold",monospace;font-weight:bold}#sbo-rt-content div[data-type="example"]{margin:10px 0 15px 0 !important}#sbo-rt-content div[data-type="example"] h1,#sbo-rt-content div[data-type="example"] h2,#sbo-rt-content div[data-type="example"] h3,#sbo-rt-content div[data-type="example"] h4,#sbo-rt-content div[data-type="example"] h5,#sbo-rt-content div[data-type="example"] h6{font-style:italic;font-weight:normal;text-align:left !important;text-transform:none !important;font-family:serif !important;margin:10px 0 5px 0 !important;border-bottom:1px solid #000}#sbo-rt-content li pre.example{padding:10px 0 !important}#sbo-rt-content div[data-type="example"] pre[data-type="programlisting"],#sbo-rt-content div[data-type="example"] pre[data-type="screen"]{margin:0}#sbo-rt-content section[data-type="titlepage"]>div>h1{font-size:2em;margin:50px 0 10px 0 !important;line-height:1;text-align:center}#sbo-rt-content section[data-type="titlepage"] h2,#sbo-rt-content section[data-type="titlepage"] p.subtitle,#sbo-rt-content section[data-type="titlepage"] p[data-type="subtitle"]{font-size:1.3em;font-weight:normal;text-align:center;margin-top:.5em;color:#555}#sbo-rt-content section[data-type="titlepage"]>div>h2[data-type="author"],#sbo-rt-content section[data-type="titlepage"] p.author{font-size:1.3em;font-family:serif !important;font-weight:bold;margin:50px 0 !important;text-align:center}#sbo-rt-content section[data-type="titlepage"] p.edition{text-align:center;text-transform:uppercase;margin-top:2em}#sbo-rt-content section[data-type="titlepage"]{text-align:center}#sbo-rt-content section[data-type="titlepage"]:after{content:url(css_assets/titlepage_footer_ebook.png);margin:0 auto;max-width:80%}#sbo-rt-content div.book div.titlepage div.publishername{margin-top:60%;margin-bottom:20px;text-align:center;font-size:1.25em}#sbo-rt-content div.book div.titlepage div.locations p{margin:0;text-align:center}#sbo-rt-content div.book div.titlepage div.locations p.cities{font-size:80%;text-align:center;margin-top:5px}#sbo-rt-content section.preface[title="Dedication"]>div.titlepage h2.title{text-align:center;text-transform:uppercase;font-size:1.5em;margin-top:50px;margin-bottom:50px}#sbo-rt-content ul.stafflist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.stafflist li{list-style-type:none;padding:5px 0}#sbo-rt-content ul.printings li{list-style-type:none}#sbo-rt-content section.preface[title="Dedication"] p{font-style:italic;text-align:center}#sbo-rt-content div.colophon h1.title{font-size:1.3em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon h2.subtitle{margin:0 !important;color:#000;font-family:serif !important;font-size:1em;font-weight:normal}#sbo-rt-content div.colophon div.author h3.author{font-size:1.1em;font-family:serif !important;margin:10px 0 0 !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h4,#sbo-rt-content div.colophon div.editor h3.editor{color:#000;font-size:.8em;margin:15px 0 0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h3.editor{font-size:.8em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.publisher{margin-top:10px}#sbo-rt-content div.colophon div.publisher p,#sbo-rt-content div.colophon div.publisher span.publishername{margin:0;font-size:.8em}#sbo-rt-content div.legalnotice p,#sbo-rt-content div.timestamp p{font-size:.8em}#sbo-rt-content div.timestamp p{margin-top:10px}#sbo-rt-content div.colophon[title="About the Author"] h1.title,#sbo-rt-content div.colophon[title="Colophon"] h1.title{font-size:1.5em;margin:0 !important;font-family:sans-serif !important}#sbo-rt-content section.chapter div.titlepage div.author{margin:10px 0 10px 0}#sbo-rt-content section.chapter div.titlepage div.author div.affiliation{font-style:italic}#sbo-rt-content div.attribution{margin:5px 0 0 50px !important}#sbo-rt-content h3.author span.orgname{display:none}#sbo-rt-content div.epigraph{margin:10px 0 10px 20px !important;page-break-inside:avoid;font-size:90%}#sbo-rt-content div.epigraph p{font-style:italic}#sbo-rt-content blockquote,#sbo-rt-content div.blockquote{margin:10px !important;page-break-inside:avoid;font-size:95%}#sbo-rt-content blockquote p,#sbo-rt-content div.blockquote p{font-style:italic;margin:.75em 0 0 !important}#sbo-rt-content blockquote div.attribution,#sbo-rt-content blockquote p[data-type="attribution"]{margin:5px 0 10px 30px !important;text-align:right;width:80%}#sbo-rt-content blockquote div.attribution p,#sbo-rt-content blockquote p[data-type="attribution"]{font-style:normal;margin-top:5px}#sbo-rt-content blockquote div.attribution p:before,#sbo-rt-content blockquote p[data-type="attribution"]:before{font-style:normal;content:"—";-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none}#sbo-rt-content p.right{text-align:right;margin:0}#sbo-rt-content div[data-type="footnotes"]{border-top:1px solid black;margin-top:2em}#sbo-rt-content sub,#sbo-rt-content sup{font-size:75%;line-height:0;position:relative}#sbo-rt-content sup{top:-.5em}#sbo-rt-content sub{bottom:-.25em}#sbo-rt-content p[data-type="footnote"]{font-size:90% !important;line-height:1.2em !important;margin-left:2.5em !important;text-indent:-2.3em !important}#sbo-rt-content p[data-type="footnote"] sup{display:inline-block !important;position:static !important;width:2em !important;text-align:right !important;font-size:100% !important;padding-right:.5em !important}#sbo-rt-content p[data-type="footnote"] a[href$="-marker"]{font-family:sans-serif !important;font-size:90% !important;color:#8e0012 !important}#sbo-rt-content p[data-type="footnote"] a[data-type="xref"]{margin:0 !important;padding:0 !important;text-indent:0 !important}#sbo-rt-content a[data-type="noteref"]{font-family:sans-serif !important;color:#8e0012;margin-left:0;padding-left:0}#sbo-rt-content div.refentry p.refname{font-size:1em;font-family:sans-serif,"DejaVuSans";font-weight:bold;margin-bottom:5px;overflow:auto;width:100%}#sbo-rt-content div.refentry{width:100%;display:block;margin-top:2em}#sbo-rt-content div.refsynopsisdiv{display:block;clear:both}#sbo-rt-content div.refentry header{page-break-inside:avoid !important;display:block;break-inside:avoid !important;padding-top:0;border-bottom:1px solid #000}#sbo-rt-content div.refsect1 h6{font-size:.9em;font-family:sans-serif,"DejaVuSans";font-weight:bold}#sbo-rt-content div.refsect1{margin-top:3em}#sbo-rt-content dt{padding-top:10px !important;padding-bottom:0 !important}#sbo-rt-content dd{margin-left:1.5em !important;margin-bottom:.25em}#sbo-rt-content dd ol,#sbo-rt-content dd ul{padding-left:1em}#sbo-rt-content dd li{margin-top:0;margin-bottom:0}#sbo-rt-content dd,#sbo-rt-content li{text-align:left}#sbo-rt-content ul,#sbo-rt-content ul>li,#sbo-rt-content ol ul,#sbo-rt-content ol ul>li,#sbo-rt-content ul ol ul,#sbo-rt-content ul ol ul>li{list-style-type:disc}#sbo-rt-content ul ul,#sbo-rt-content ul ul>li{list-style-type:square}#sbo-rt-content ul ul ul,#sbo-rt-content ul ul ul>li{list-style-type:circle}#sbo-rt-content ol,#sbo-rt-content ol>li,#sbo-rt-content ol ul ol,#sbo-rt-content ol ul ol>li,#sbo-rt-content ul ol,#sbo-rt-content ul ol>li{list-style-type:decimal}#sbo-rt-content ol ol,#sbo-rt-content ol ol>li{list-style-type:lower-alpha}#sbo-rt-content ol ol ol,#sbo-rt-content ol ol ol>li{list-style-type:lower-roman}#sbo-rt-content ol,#sbo-rt-content ul{list-style-position:outside;margin:15px 0 15px 1.25em;padding-left:2.25em}#sbo-rt-content ol li,#sbo-rt-content ul li{margin:.5em 0 .65em;line-height:125%}#sbo-rt-content div.orderedlistalpha{list-style-type:upper-alpha}#sbo-rt-content table.simplelist,#sbo-rt-content ul.simplelist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.simplelist li{list-style-type:none;padding:5px 0}#sbo-rt-content table.simplelist td{border:none}#sbo-rt-content table.simplelist tr{border-bottom:none}#sbo-rt-content table.simplelist tr:nth-of-type(even){background-color:transparent}#sbo-rt-content dl.calloutlist p:first-child{margin-top:-25px !important}#sbo-rt-content dl.calloutlist dd{padding-left:0;margin-top:-25px}#sbo-rt-content dl.calloutlist img,#sbo-rt-content a.co img{padding:0}#sbo-rt-content div.toc ol{margin-top:8px !important;margin-bottom:8px !important;margin-left:0 !important;padding-left:0 !important}#sbo-rt-content div.toc ol ol{margin-left:30px !important;padding-left:0 !important}#sbo-rt-content div.toc ol li{list-style-type:none}#sbo-rt-content div.toc a{color:#8e0012}#sbo-rt-content div.toc ol a{font-size:1em;font-weight:bold}#sbo-rt-content div.toc ol>li>ol a{font-weight:bold;font-size:1em}#sbo-rt-content div.toc ol>li>ol>li>ol a{text-decoration:none;font-weight:normal;font-size:1em}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"],#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{margin:30px !important;font-size:90%;padding:10px 8px 20px 8px !important;page-break-inside:avoid}#sbo-rt-content div.tip ol,#sbo-rt-content div.tip ul,#sbo-rt-content div[data-type="tip"] ol,#sbo-rt-content div[data-type="tip"] ul,#sbo-rt-content div.note ol,#sbo-rt-content div.note ul,#sbo-rt-content div[data-type="note"] ol,#sbo-rt-content div[data-type="note"] ul,#sbo-rt-content div.warning ol,#sbo-rt-content div.warning ul,#sbo-rt-content div[data-type="warning"] ol,#sbo-rt-content div[data-type="warning"] ul,#sbo-rt-content div[data-type="caution"] ol,#sbo-rt-content div[data-type="caution"] ul,#sbo-rt-content div[data-type="important"] ol,#sbo-rt-content div[data-type="important"] ul{margin-left:1.5em !important}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"]{border:1px solid #BEBEBE;background-color:transparent}#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{border:1px solid #BC8F8F}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="note"] h1,#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1,#sbo-rt-content div[data-type="important"] h6{font-weight:bold;font-size:110%;font-family:sans-serif !important;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px !important}#sbo-rt-content div[data-type="tip"] figure h6,#sbo-rt-content div[data-type="note"] figure h6,#sbo-rt-content div[data-type="warning"] figure h6,#sbo-rt-content div[data-type="caution"] figure h6,#sbo-rt-content div[data-type="important"] figure h6{font-family:serif !important}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div[data-type="note"] h1{color:#737373}#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="important"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1{color:#C67171}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note,#sbo-rt-content div.safarienabled{background-color:transparent;margin:8px 0 0 !important;border:0 solid #BEBEBE;font-size:100%;padding:0 !important;page-break-inside:avoid}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note h3,#sbo-rt-content div.safarienabled h6{display:none}#sbo-rt-content div.table,#sbo-rt-content table{margin:15px 0 30px 0 !important;max-width:95%;border:none !important;background:none;display:table !important}#sbo-rt-content div.table,#sbo-rt-content div.informaltable,#sbo-rt-content table{page-break-inside:avoid}#sbo-rt-content tr,#sbo-rt-content tr td{border-bottom:1px solid #c3c3c3}#sbo-rt-content thead td,#sbo-rt-content thead th{border-bottom:#9d9d9d 1px solid !important;border-top:#9d9d9d 1px solid !important}#sbo-rt-content tr:nth-of-type(even){background-color:#f1f6fc}#sbo-rt-content thead{font-family:sans-serif;font-weight:bold}#sbo-rt-content td,#sbo-rt-content th{display:table-cell;padding:.3em;text-align:left;vertical-align:middle;font-size:80%}#sbo-rt-content div.informaltable table{margin:10px auto !important}#sbo-rt-content div.informaltable table tr{border-bottom:none}#sbo-rt-content div.informaltable table tr:nth-of-type(even){background-color:transparent}#sbo-rt-content div.informaltable td,#sbo-rt-content div.informaltable th{border:#9d9d9d 1px solid}#sbo-rt-content div.table-title,#sbo-rt-content table caption{font-weight:normal;font-style:italic;font-family:serif;font-size:1em;margin:10px 0 10px 0 !important;padding:0;page-break-after:avoid;text-align:left !important}#sbo-rt-content table code{font-size:smaller}#sbo-rt-content table.border tbody>tr:last-child>td{border-bottom:transparent}#sbo-rt-content div.equation,#sbo-rt-content div[data-type="equation"]{margin:10px 0 15px 0 !important}#sbo-rt-content div.equation-title,#sbo-rt-content div[data-type="equation"] h5{font-style:italic;font-weight:normal;font-family:serif !important;font-size:90%;margin:20px 0 10px 0 !important;page-break-after:avoid}#sbo-rt-content div.equation-contents{margin-left:20px}#sbo-rt-content div[data-type="equation"] math{font-size:calc(.35em + 1vw)}#sbo-rt-content span.inlinemediaobject{height:.85em;display:inline-block;margin-bottom:.2em}#sbo-rt-content span.inlinemediaobject img{margin:0;height:.85em}#sbo-rt-content div.informalequation{margin:20px 0 20px 20px;width:75%}#sbo-rt-content div.informalequation img{width:75%}#sbo-rt-content div.index{text-indent:0}#sbo-rt-content div.index h3{padding:.25em;margin-top:1em !important;background-color:#F0F0F0}#sbo-rt-content div.index li{line-height:130%;list-style-type:none}#sbo-rt-content div.index a.indexterm{color:#8e0012 !important}#sbo-rt-content div.index ul{margin-left:0 !important;padding-left:0 !important}#sbo-rt-content div.index ul ul{margin-left:1em !important;margin-top:0 !important}#sbo-rt-content code.boolean,#sbo-rt-content .navy{color:rgb(0,0,128);}#sbo-rt-content code.character,#sbo-rt-content .olive{color:rgb(128,128,0);}#sbo-rt-content code.comment,#sbo-rt-content .blue{color:rgb(0,0,255);}#sbo-rt-content code.conditional,#sbo-rt-content .limegreen{color:rgb(50,205,50);}#sbo-rt-content code.constant,#sbo-rt-content .darkorange{color:rgb(255,140,0);}#sbo-rt-content code.debug,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.define,#sbo-rt-content .darkgoldenrod,#sbo-rt-content .gold{color:rgb(184,134,11);}#sbo-rt-content code.delimiter,#sbo-rt-content .dimgray{color:rgb(105,105,105);}#sbo-rt-content code.error,#sbo-rt-content .red{color:rgb(255,0,0);}#sbo-rt-content code.exception,#sbo-rt-content .salmon{color:rgb(250,128,11);}#sbo-rt-content code.float,#sbo-rt-content .steelblue{color:rgb(70,130,180);}#sbo-rt-content pre code.function,#sbo-rt-content .green{color:rgb(0,128,0);}#sbo-rt-content code.identifier,#sbo-rt-content .royalblue{color:rgb(65,105,225);}#sbo-rt-content code.ignore,#sbo-rt-content .gray{color:rgb(128,128,128);}#sbo-rt-content code.include,#sbo-rt-content .purple{color:rgb(128,0,128);}#sbo-rt-content code.keyword,#sbo-rt-content .sienna{color:rgb(160,82,45);}#sbo-rt-content code.label,#sbo-rt-content .deeppink{color:rgb(255,20,147);}#sbo-rt-content code.macro,#sbo-rt-content .orangered{color:rgb(255,69,0);}#sbo-rt-content code.number,#sbo-rt-content .brown{color:rgb(165,42,42);}#sbo-rt-content code.operator,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.preCondit,#sbo-rt-content .teal{color:rgb(0,128,128);}#sbo-rt-content code.preProc,#sbo-rt-content .fuschia{color:rgb(255,0,255);}#sbo-rt-content code.repeat,#sbo-rt-content .indigo{color:rgb(75,0,130);}#sbo-rt-content code.special,#sbo-rt-content .saddlebrown{color:rgb(139,69,19);}#sbo-rt-content code.specialchar,#sbo-rt-content .magenta{color:rgb(255,0,255);}#sbo-rt-content code.specialcomment,#sbo-rt-content .seagreen{color:rgb(46,139,87);}#sbo-rt-content code.statement,#sbo-rt-content .forestgreen{color:rgb(34,139,34);}#sbo-rt-content code.storageclass,#sbo-rt-content .plum{color:rgb(221,160,221);}#sbo-rt-content code.string,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.structure,#sbo-rt-content .chocolate{color:rgb(210,106,30);}#sbo-rt-content code.tag,#sbo-rt-content .darkcyan{color:rgb(0,139,139);}#sbo-rt-content code.todo,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.type,#sbo-rt-content .mediumslateblue{color:rgb(123,104,238);}#sbo-rt-content code.typedef,#sbo-rt-content .darkgreen{color:rgb(0,100,0);}#sbo-rt-content code.underlined{text-decoration:underline;}#sbo-rt-content pre code.hll{background-color:#ffc}#sbo-rt-content pre code.c{color:#09F;font-style:italic}#sbo-rt-content pre code.err{color:#A00}#sbo-rt-content pre code.k{color:#069;font-weight:bold}#sbo-rt-content pre code.o{color:#555}#sbo-rt-content pre code.cm{color:#35586C;font-style:italic}#sbo-rt-content pre code.cp{color:#099}#sbo-rt-content pre code.c1{color:#35586C;font-style:italic}#sbo-rt-content pre code.cs{color:#35586C;font-weight:bold;font-style:italic}#sbo-rt-content pre code.gd{background-color:#FCC}#sbo-rt-content pre code.ge{font-style:italic}#sbo-rt-content pre code.gr{color:#F00}#sbo-rt-content pre code.gh{color:#030;font-weight:bold}#sbo-rt-content pre code.gi{background-color:#CFC}#sbo-rt-content pre code.go{color:#000}#sbo-rt-content pre code.gp{color:#009;font-weight:bold}#sbo-rt-content pre code.gs{font-weight:bold}#sbo-rt-content pre code.gu{color:#030;font-weight:bold}#sbo-rt-content pre code.gt{color:#9C6}#sbo-rt-content pre code.kc{color:#069;font-weight:bold}#sbo-rt-content pre code.kd{color:#069;font-weight:bold}#sbo-rt-content pre code.kn{color:#069;font-weight:bold}#sbo-rt-content pre code.kp{color:#069}#sbo-rt-content pre code.kr{color:#069;font-weight:bold}#sbo-rt-content pre code.kt{color:#078;font-weight:bold}#sbo-rt-content pre code.m{color:#F60}#sbo-rt-content pre code.s{color:#C30}#sbo-rt-content pre code.na{color:#309}#sbo-rt-content pre code.nb{color:#366}#sbo-rt-content pre code.nc{color:#0A8;font-weight:bold}#sbo-rt-content pre code.no{color:#360}#sbo-rt-content pre code.nd{color:#99F}#sbo-rt-content pre code.ni{color:#999;font-weight:bold}#sbo-rt-content pre code.ne{color:#C00;font-weight:bold}#sbo-rt-content pre code.nf{color:#C0F}#sbo-rt-content pre code.nl{color:#99F}#sbo-rt-content pre code.nn{color:#0CF;font-weight:bold}#sbo-rt-content pre code.nt{color:#309;font-weight:bold}#sbo-rt-content pre code.nv{color:#033}#sbo-rt-content pre code.ow{color:#000;font-weight:bold}#sbo-rt-content pre code.w{color:#bbb}#sbo-rt-content pre code.mf{color:#F60}#sbo-rt-content pre code.mh{color:#F60}#sbo-rt-content pre code.mi{color:#F60}#sbo-rt-content pre code.mo{color:#F60}#sbo-rt-content pre code.sb{color:#C30}#sbo-rt-content pre code.sc{color:#C30}#sbo-rt-content pre code.sd{color:#C30;font-style:italic}#sbo-rt-content pre code.s2{color:#C30}#sbo-rt-content pre code.se{color:#C30;font-weight:bold}#sbo-rt-content pre code.sh{color:#C30}#sbo-rt-content pre code.si{color:#A00}#sbo-rt-content pre code.sx{color:#C30}#sbo-rt-content pre code.sr{color:#3AA}#sbo-rt-content pre code.s1{color:#C30}#sbo-rt-content pre code.ss{color:#A60}#sbo-rt-content pre code.bp{color:#366}#sbo-rt-content pre code.vc{color:#033}#sbo-rt-content pre code.vg{color:#033}#sbo-rt-content pre code.vi{color:#033}#sbo-rt-content pre code.il{color:#F60}#sbo-rt-content pre code.g{color:#050}#sbo-rt-content pre code.l{color:#C60}#sbo-rt-content pre code.l{color:#F90}#sbo-rt-content pre code.n{color:#008}#sbo-rt-content pre code.nx{color:#008}#sbo-rt-content pre code.py{color:#96F}#sbo-rt-content pre code.p{color:#000}#sbo-rt-content pre code.x{color:#F06}#sbo-rt-content div.blockquote_sampler_toc{width:95%;margin:5px 5px 5px 10px !important}#sbo-rt-content div{font-family:serif;text-align:left}#sbo-rt-content .gray-background,#sbo-rt-content .reverse-video{background:#2E2E2E;color:#FFF}#sbo-rt-content .light-gray-background{background:#A0A0A0}#sbo-rt-content .preserve-whitespace{white-space:pre-wrap}#sbo-rt-content span.gray{color:#4C4C4C}#sbo-rt-content .width-10{width:10vw !important}#sbo-rt-content .width-20{width:20vw !important}#sbo-rt-content .width-30{width:30vw !important}#sbo-rt-content .width-40{width:40vw !important}#sbo-rt-content .width-50{width:50vw !important}#sbo-rt-content .width-60{width:60vw !important}#sbo-rt-content .width-70{width:70vw !important}#sbo-rt-content .width-80{width:80vw !important}#sbo-rt-content .width-90{width:90vw !important}#sbo-rt-content .width-full,#sbo-rt-content .width-100{width:100vw !important}#sbo-rt-content div[data-type="equation"].fifty-percent img{width:50%}</style><script> // <![CDATA[
    var g = {
      position_cache: {
        
          "chapter": "/api/v1/book/9781492032632/chapter/part01.html",
          "book_id": "9781492032632",
          "chapter_uri": "part01.html",
          "position": 100.0,
          "user_uuid": "d59baa21-c0cd-4fcf-9c68-a2b8d4f52a79",
          "next_chapter_uri": "/library/view/hands-on-machine-learning/9781492032632/ch01.html"
        
      },
      title: "Hands\u002Don Machine Learning with Scikit\u002DLearn, Keras, and TensorFlow, 2nd Edition",
      author_list: "Aurélien Géron",
      format: "book",
      source: "application/epub+zip",
      is_system_book: true,
      is_public: false,
      loaded_from_server: true,
      allow_scripts: false,
      has_mathml: true
    };
    // ]]></script><script src="./Chapter13_files/modernizr.8e35451ddb64.js.download"></script><script>
    
      

      
        
          window.PUBLIC_ANNOTATIONS = true;
        
      

      window.MOBILE_PUBLIC_ANNOTATIONS = false;

    

    
      window.PRIVACY_CONTROL_OVERRIDE = false;
    

      window.PRIVACY_CONTROL_SWITCH = true;

      window.PUBLISHER_PAGES = true;

      window.SBO = {
        "constants": {
          "SITB_ENDPOINT": "/api/v2/sitb/",
          "SEARCH_SELECT_ENDPOINT": "https://learning.oreilly.com/api/v2/search/select/",
          "ENABLE_ONLINE_TRAINING": false
        }
      };
  </script><link rel="canonical" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/part01.html"><meta name="description" content=" Part I. The Fundamentals of Machine Learning "><meta property="og:title" content="I. The Fundamentals of Machine Learning"><meta itemprop="isPartOf" content="/library/view/hands-on-machine-learning/9781492032632/"><meta itemprop="name" content="I. The Fundamentals of Machine Learning"><meta property="og:url" itemprop="url" content="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/part01.html"><meta property="og:site_name" content="Safari"><meta property="og:image" itemprop="thumbnailUrl" content="https://learning.oreilly.com/library/cover/9781492032632/"><meta property="og:description" itemprop="description" content=" Part I. The Fundamentals of Machine Learning "><meta itemprop="inLanguage" content="en"><meta itemprop="publisher" content="O&#39;Reilly Media, Inc."><meta property="og:type" content="book"><meta property="og:book:isbn" itemprop="isbn" content="9781492032649"><meta property="og:book:author" itemprop="author" content="Aurélien Géron"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@safari"><style type="text/css" id="font-styles" data-template="#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-size: &lt;%= font_size %&gt; !important; }"></style><style type="text/css" id="font-family" data-template="#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-family: &lt;%= font_family %&gt; !important; }"></style><style type="text/css" id="column-width" data-template="#sbo-rt-content { max-width: &lt;%= column_width %&gt;% !important; margin: 0 auto !important; }"></style><noscript><meta http-equiv="refresh" content="0; url=/library/no-js/" /></noscript><script type="text/javascript">
    (function(i,s,o,g,r,a,m) {
      i['GoogleAnalyticsObject']=r;
      i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();
      a=s.createElement(o),m=s.getElementsByTagName(o)[0];
      a.async=1;
      a.src=g;
      m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    var matches = document.cookie.match(/BrowserCookie\s*=\s*([a-f0-9\-]{36})/),
      user_uuid = null;

    if (matches && matches.length === 2) {
      user_uuid = matches[1];
    }

  
    ga('create', 'UA-39299553-7', {'userId': 'd59baa21-c0cd-4fcf-9c68-a2b8d4f52a79' });
  

  
    
      ga('set', 'dimension1', 'B2B');
    
  

  ga('set', 'dimension6', user_uuid);

  
    ga('set', 'dimension2', 'd59baa21-c0cd-4fcf-9c68-a2b8d4f52a79');
    
      ga('set', 'dimension7', '0012M0000229keZQAQ');
    
  

  

  

  //enable enhanced link tracking
  ga('require', 'linkid', 'linkid.js');

  // reading interface will track pageviews itself
  if (document.location.pathname.indexOf("/library/view") !== 0) {
    ga('send', 'pageview');
  }
  </script><script>
    var dataLayer = window.dataLayer || [];

    
      window.medalliaVsgUserIdentifier = 'd59baa21-c0cd-4fcf-9c68-a2b8d4f52a79';
      dataLayer.push({userIdentifier: 'd59baa21-c0cd-4fcf-9c68-a2b8d4f52a79'});
      dataLayer.push({loggedIn: 'yes'});

      
        window.medalliaVsgAccountIdentifier = '21bed0a7-6b7b-470c-8fa0-40a52db0b491';
        
        dataLayer.push({orgID: '21bed0a7-6b7b-470c-8fa0-40a52db0b491'});
        

        window.medalliaVsgIsIndividual = false;
        
          
          dataLayer.push({learningAccountType: 'enterprise'});
          
        

        
          dataLayer.push({learningPaidAccount: 'yes'});
        
      
    

    (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    '//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-5P4V6Z');
    (function () {
      var VERSION = 'V1.1';
      var AUTHOR = 'Awwad';
      if (!window.GtmHelper)
        window.GtmHelper = function () {
          var instance = this;
          var loc = document.location;
          this.version = VERSION;
          this.author = AUTHOR;
          this.readCookie = function (name) {
            var nameEQ = name + "=";
            var ca = document.cookie.split(';');
            for (var i = 0; i < ca.length; i++) {
              var c = ca[i];
              while (c.charAt(0) == ' ') c = c.substring(1, c.length);
              if (c.indexOf(nameEQ) == 0) return c.substring(nameEQ.length, c.length);
            }
            return null;
          };
          this.createCookie = function (name, value, days, cookieDomain) {
            var domain = "";
            var expires = "";

            if (days) {
              var date = new Date();
              date.setTime(date.getTime() + Math.ceil(days * 24 * 60 * 60 * 1000));
              var expires = " expires=" + date.toGMTString() + ";";
            }

            if (typeof (cookieDomain) != 'undefined')
              domain = " domain=" + cookieDomain + "; ";

            document.cookie = name + "=" + value + ";" + expires + domain + "path=/";
          };

          this.isDuplicated = function (currentTransactionId) {
            // the previous transaction id:
            var previousTransIdValue = this.readCookie("previousTransId");

            if (currentTransactionId === previousTransIdValue) {
              return true; // Duplication
            } else {
              return false;
            }
          };
        }
    })()
  </script><script defer="" src="./Chapter13_files/vendor.a48a756c5182.js.download"></script><script defer="" src="./Chapter13_files/reader.f2a0c6bd2fee.js.download"></script><script src="./Chapter13_files/f(1).txt"></script><script src="./Chapter13_files/f(2).txt"></script><script src="./Chapter13_files/f(3).txt"></script><script src="./Chapter13_files/f(4).txt"></script><script async="" src="./Chapter13_files/MathJax.js.download"></script><style id="annotator-dynamic-style">.annotator-adder, .annotator-outer, .annotator-notice {
  z-index: 2147483020;
}
.annotator-filter {
  z-index: 2147483010;
}</style><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 2px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 2px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: 1em}
.MathJax_MenuRadioCheck.RTL {right: 1em; left: auto}
.MathJax_MenuLabel {padding: 2px 2em 4px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #CCCCCC; margin: 4px 1px 0px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: Highlight; color: HighlightText}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MathJax_Preview .MJXf-math {color: inherit!important}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
</style><script async="true" type="text/javascript" src="./Chapter13_files/roundtrip.js.download"></script><style type="text/css" id="kampyleStyle">.noOutline{outline: none !important;}.wcagOutline:focus{outline: 1px dashed #595959 !important;outline-offset: 2px !important;transition: none !important;}</style><script async="true" type="text/javascript" src="./Chapter13_files/roundtrip.js.download"></script><style type="text/css">.MathJax_Display {text-align: center; margin: 1em 0em; position: relative; display: block!important; text-indent: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; width: 100%}
.MathJax .merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MathJax .MJX-monospace {font-family: monospace}
.MathJax .MJX-sans-serif {font-family: sans-serif}
#MathJax_Tooltip {background-color: InfoBackground; color: InfoText; border: 1px solid black; box-shadow: 2px 2px 5px #AAAAAA; -webkit-box-shadow: 2px 2px 5px #AAAAAA; -moz-box-shadow: 2px 2px 5px #AAAAAA; -khtml-box-shadow: 2px 2px 5px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true'); padding: 3px 4px; z-index: 401; position: absolute; left: 0; top: 0; width: auto; height: auto; display: none}
.MathJax {display: inline; font-style: normal; font-weight: normal; line-height: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; padding: 0; margin: 0}
.MathJax:focus, body :focus .MathJax {display: inline-table}
.MathJax.MathJax_FullWidth {text-align: center; display: table-cell!important; width: 10000em!important}
.MathJax img, .MathJax nobr, .MathJax a {border: 0; padding: 0; margin: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; vertical-align: 0; line-height: normal; text-decoration: none}
img.MathJax_strut {border: 0!important; padding: 0!important; margin: 0!important; vertical-align: 0!important}
.MathJax span {display: inline; position: static; border: 0; padding: 0; margin: 0; vertical-align: 0; line-height: normal; text-decoration: none}
.MathJax nobr {white-space: nowrap!important}
.MathJax img {display: inline!important; float: none!important}
.MathJax * {transition: none; -webkit-transition: none; -moz-transition: none; -ms-transition: none; -o-transition: none}
.MathJax_Processing {visibility: hidden; position: fixed; width: 0; height: 0; overflow: hidden}
.MathJax_Processed {display: none!important}
.MathJax_ExBox {display: block!important; overflow: hidden; width: 1px; height: 60ex; min-height: 0; max-height: none}
.MathJax .MathJax_EmBox {display: block!important; overflow: hidden; width: 1px; height: 60em; min-height: 0; max-height: none}
.MathJax_LineBox {display: table!important}
.MathJax_LineBox span {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MathJax .MathJax_HitBox {cursor: text; background: white; opacity: 0; filter: alpha(opacity=0)}
.MathJax .MathJax_HitBox * {filter: none; opacity: 1; background: transparent}
#MathJax_Tooltip * {filter: none; opacity: 1; background: transparent}
@font-face {font-family: MathJax_Main; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf?V=2.7.1') format('opentype')}
@font-face {font-family: MathJax_Main-bold; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf?V=2.7.1') format('opentype')}
@font-face {font-family: MathJax_Main-italic; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf?V=2.7.1') format('opentype')}
@font-face {font-family: MathJax_Math-italic; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf?V=2.7.1') format('opentype')}
@font-face {font-family: MathJax_Caligraphic; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf?V=2.7.1') format('opentype')}
@font-face {font-family: MathJax_Size1; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf?V=2.7.1') format('opentype')}
@font-face {font-family: MathJax_Size2; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf?V=2.7.1') format('opentype')}
@font-face {font-family: MathJax_Size3; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf?V=2.7.1') format('opentype')}
@font-face {font-family: MathJax_Size4; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf?V=2.7.1') format('opentype')}
</style><style type="text/css">@font-face {font-family: MathJax_Math-bold-italic; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf?V=2.7.1') format('opentype')}
</style><style type="text/css">@font-face {font-family: MathJax_Script; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf?V=2.7.1') format('opentype')}
</style><style type="text/css">@font-face {font-family: MathJax_AMS; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf?V=2.7.1') format('opentype')}
</style></head>


<body class="reading sidenav  scalefonts library nav-collapsed"><div style="visibility: hidden; overflow: hidden; position: absolute; top: 0px; height: 1px; width: auto; padding: 0px; border: 0px; margin: 0px; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal;"><div id="MathJax_Hidden"></div></div><div id="MathJax_Message" style="display: none;"></div>

    
  <noscript> 
    <iframe src="//www.googletagmanager.com/ns.html?id=GTM-5P4V6Z"
            height="0" width="0"
            style="display:none;visibility:hidden">
    </iframe>
  </noscript>



    
      <div class="hide working" role="status">
        <div class="working-image"></div>
      </div>
      <div class="sbo-site-nav">
        





<a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#container" class="skip">Skip to content</a><header class="topbar t-topbar"><nav role="navigation" class="js-site-nav"><ul class="topnav"><li class="t-logo"><a href="https://learning.oreilly.com/home/" class="l0 None safari-home nav-icn js-keyboard-nav-home"><svg width="16" height="16" viewBox="0 0 16 16" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M11.738 14H9.254v-3.676a.617.617 0 0 0-.621-.613H7.39a.617.617 0 0 0-.62.613V14H4.284a.617.617 0 0 1-.622-.613V10.22c0-.327.132-.64.367-.87l3.547-3.493a.627.627 0 0 1 .875 0l3.54 3.499c.234.229.366.54.367.864v3.167a.617.617 0 0 1-.62.613zM7.57 2.181a.625.625 0 0 1 .882 0l5.77 5.692-.93.92-5.28-5.209-5.28 5.208-.932-.919 5.77-5.692z"></path></svg><span>Safari Home</span></a></li><li><a href="https://learning.oreilly.com/resource-centers/" class="t-resource-centers-nav l0 nav-icn"><!--?xml version="1.0" encoding="UTF-8"?--><svg width="16px" height="16px" viewBox="0 0 16 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><g id="Topic-Page-Design" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g id="Heron-Button" transform="translate(-20.000000, -78.000000)" fill="#4A3A30"><g id="Group-9" transform="translate(20.000000, 78.000000)"><rect id="Rectangle" x="9.6" y="0" width="6.4" height="6.4" rx="0.503118"></rect><rect id="Rectangle" x="9.6" y="9.6" width="6.4" height="6.4" rx="0.503118"></rect><rect id="Rectangle" x="0" y="9.6" width="6.4" height="6.4" rx="0.503118"></rect></g></g></g></svg><span>Resource Centers</span></a></li><li><a href="https://learning.oreilly.com/playlists/" class="t-queue-nav l0 nav-icn None"><!--?xml version="1.0" encoding="UTF-8"?--><svg width="21px" height="17px" viewBox="0 0 21 17" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><!-- Generator: Sketch 46.2 (44496) - http://www.bohemiancoding.com/sketch --><title>icon_Playlist_sml</title><desc>Created with Sketch.</desc><defs></defs><g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g id="icon_Playlist_sml" fill-rule="nonzero" fill="#000000"><g id="playlist-icon"><g id="Group-6"><rect id="Rectangle-path" x="5" y="0" width="16" height="3" rx="0.5"></rect><circle id="Oval" cx="1.5" cy="1.5" r="1.5"></circle></g><g id="Group-5" transform="translate(0.000000, 7.000000)"><circle id="Oval" cx="1.5" cy="1.5" r="1.5"></circle><rect id="Rectangle-path" x="5" y="0" width="16" height="3" rx="0.5"></rect></g><g id="Group-5-Copy" transform="translate(0.000000, 14.000000)"><circle id="Oval" cx="1.5" cy="1.5" r="1.5"></circle><rect id="Rectangle-path" x="5" y="0" width="16" height="3" rx="0.5"></rect></g></g></g></g></svg><span>
               Playlists
            </span></a></li><li class="search"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#" class="t-search-nav trigger nav-icn l0" data-dropdown-selector=".searchbox"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>search icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M31.3 0C20.9 0 12.5 8.4 12.5 18.8 12.5 22.5 13.6 25.9 15.4 28.8L1.2 42.9C-0.4 44.5-0.4 47.2 1.2 48.8 2 49.6 3.1 50 4.2 50 5.2 50 6.3 49.6 7.1 48.8L21.2 34.6C24.1 36.5 27.5 37.5 31.3 37.5 41.6 37.5 50 29.1 50 18.8 50 8.4 41.6 0 31.3 0ZM31.3 31.3C24.4 31.3 18.8 25.6 18.8 18.8 18.8 11.9 24.4 6.3 31.3 6.3 38.1 6.3 43.8 11.9 43.8 18.8 43.8 25.6 38.1 31.3 31.3 31.3Z"></path></g></svg><span>Search</span></a></li><li class="usermenu dropdown"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#" class="trigger l0 nav-icn nav-dropdown"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="20" height="20" version="1.1" fill="#4A3C31"><desc>navigation arrow</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M0.1 12.5L9.7 3.1C9.8 3 9.9 3 10 3 10.1 3 10.2 3 10.3 3.1L19.9 12.5C20 12.5 20 12.6 20 12.8 20 12.9 20 13 19.9 13L17 15.9C16.9 16 16.8 16 16.7 16 16.5 16 16.4 16 16.4 15.9L10 9.7 3.6 15.9C3.6 16 3.5 16 3.3 16 3.2 16 3.1 16 3 15.9L0.1 13C0 12.9 0 12.8 0 12.7 0 12.7 0 12.6 0.1 12.5Z"></path></g></svg><span>Expand Nav</span></a><div class="drop-content"><ul><li><a href="https://learning.oreilly.com/history/" class="t-recent-nav l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>recent items icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 0C11.2 0 0 11.2 0 25 0 38.8 11.2 50 25 50 38.8 50 50 38.8 50 25 50 11.2 38.8 0 25 0ZM6.3 25C6.3 14.6 14.6 6.3 25 6.3 35.4 6.3 43.8 14.6 43.8 25 43.8 35.4 35.4 43.8 25 43.8 14.6 43.8 6.3 35.4 6.3 25ZM31.8 31.5C32.5 30.5 32.4 29.2 31.6 28.3L27.1 23.8 27.1 12.8C27.1 11.5 26.2 10.4 25 10.4 23.9 10.4 22.9 11.5 22.9 12.8L22.9 25.7 28.8 31.7C29.2 32.1 29.7 32.3 30.2 32.3 30.8 32.3 31.3 32 31.8 31.5Z"></path></g></svg><span>History</span></a></li><li><a href="https://learning.oreilly.com/topics" class="t-topics-link l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 55" width="20" height="20" version="1.1" fill="#4A3C31"><desc>topics icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 55L50 41.262 50 13.762 25 0 0 13.762 0 41.262 25 55ZM8.333 37.032L8.333 17.968 25 8.462 41.667 17.968 41.667 37.032 25 46.538 8.333 37.032Z"></path></g></svg><span>Topics</span></a></li><li><a href="https://learning.oreilly.com/learning-paths/" class="l1 nav-icn t-learningpaths-nav js-toggle-menu-item"><!--?xml version="1.0" encoding="UTF-8"?--><svg width="32px" height="32px" viewBox="0 0 32 32" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><!-- Generator: Sketch 52.5 (67469) - http://www.bohemiancoding.com/sketch --><title>Mask</title><desc>Created with Sketch.</desc><g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><path d="M0,16.0214227 C0,15.0387209 0.796453294,14.2411658 1.77779753,14.2411658 C2.75914177,14.2411658 3.55559506,15.0387209 3.55559506,16.0214227 C3.55559506,17.0041246 2.75914177,17.8016797 1.77779753,17.8016797 C0.796453294,17.8016797 0,17.0041246 0,16.0214227 Z M9.77788642,5.22914885 C8.9280992,5.72049977 7.84008711,5.42853763 7.34941499,4.57757479 C6.85874287,3.72661195 7.15030167,2.63709467 8.00008889,2.14574375 C8.84987611,1.65439282 9.9378882,1.94635496 10.4285603,2.7973178 C10.9192324,3.64828064 10.6276736,4.73779792 9.77788642,5.22914885 Z M4.57213969,7.35869225 C5.42192691,7.85004318 5.71348571,8.93956046 5.22281359,9.79052329 C4.73214147,10.6414861 3.64412938,10.9334483 2.79434216,10.4420974 C1.94455494,9.95074642 1.65299614,8.86122915 2.14366826,8.01026631 C2.63434038,7.15930347 3.72235247,6.86734132 4.57213969,7.35869225 Z M2.79434216,21.6007481 C3.64412938,21.1093972 4.73214147,21.4013594 5.22281359,22.2523222 C5.71348571,23.103285 5.42192691,24.1928023 4.57213969,24.6841532 C3.72235247,25.1755042 2.63434038,24.883542 2.14366826,24.0325792 C1.65299614,23.1816163 1.94455494,22.0920991 2.79434216,21.6007481 Z M7.34941499,27.4652707 C7.84008711,26.6143079 8.9280992,26.3223457 9.77788642,26.8136966 C10.6276736,27.3050476 10.9192324,28.3945649 10.4285603,29.2455277 C9.9378882,30.0964905 8.84987611,30.3884527 8.00008889,29.8971017 C7.15030167,29.4057508 6.85874287,28.3162335 7.34941499,27.4652707 Z M18.7118524,11.3165596 C21.3074367,12.8173162 22.1963355,16.1392758 20.6976522,18.738451 C19.1989689,21.3358459 15.8815987,22.2259744 13.2860143,20.726998 C10.6922077,19.2262414 9.80330893,15.9042818 11.3002144,13.3051066 C12.7988978,10.7059314 16.116268,9.81580294 18.7118524,11.3165596 Z M26.7821642,27.8093944 L30.1315348,31.1633985 C30.3982044,31.4304371 30.2097579,31.8844026 29.8346426,31.8844026 L21.5945511,31.8844026 C21.1287681,31.8844026 20.751875,31.5069881 20.751875,31.0405608 L20.751875,22.7890697 C20.751875,22.4134355 21.2052134,22.2247282 21.4701052,22.4899865 L24.2843587,25.3081333 C26.8337204,23.0240636 28.4444049,19.7092251 28.4444049,16.0223129 C28.4444049,9.15052091 22.8621207,3.56051397 15.9998222,3.56051397 L15.9998222,0 C24.8230314,0 32,7.18689745 32,16.0223129 C32,20.6919269 29.9750886,24.8790914 26.7821642,27.8093944 Z" id="Mask" fill="#8B889A"></path></g></svg><span>Learning Paths</span></a></li><li class="nav-highlights"><a href="https://learning.oreilly.com/u/d59baa21-c0cd-4fcf-9c68-a2b8d4f52a79/" class="t-highlights-nav l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 35" width="20" height="20" fill="#4A3C31"><path d="M13.325 18.071H8.036c0-6.736 4.324-10.925 14.464-12.477V0C6.37 1.113 0 10.632 0 22.113 0 29.406 3.477 35 10.403 35c5.142 0 9.175-3.515 9.175-8.816 0-4.628-2.367-7.293-6.253-8.113zm27.5 0h-5.26c0-6.736 4.295-10.925 14.435-12.477V0C33.899 1.113 27.5 10.632 27.5 22.113 27.5 29.406 30.977 35 37.932 35c5.113 0 9.146-3.515 9.146-8.816 0-4.628-2.338-7.293-6.253-8.113z" fill-rule="evenodd"></path></svg><span>Highlights</span></a></li><li><a href="https://learning.oreilly.com/u/preferences/" class="t-settings-nav l1 js-settings nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 53" width="20" height="20" version="1.1" fill="#4A3C31"><desc>settings icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M44.6 29.6C44.7 28.6 44.8 27.5 44.8 26.5 44.8 25.5 44.7 24.4 44.6 23.4L49.6 19C50 18.8 50.1 18.3 49.9 17.9 48.9 14.7 47.1 11.7 44.9 9.1 44.6 8.8 44.2 8.7 43.8 8.8L37.4 11.1C35.8 9.8 34 8.7 32.1 8L30.9 1.4C30.8 0.9 30.4 0.6 30 0.5 26.7-0.2 23.3-0.2 20 0.5 19.6 0.6 19.2 0.9 19.1 1.4L17.9 8C16 8.7 14.1 9.8 12.6 11.1L6.2 8.8C5.8 8.7 5.4 8.8 5.1 9.1 2.9 11.7 1.1 14.7 0.1 17.9 -0.1 18.3 0 18.8 0.4 19L5.4 23.4C5.3 24.4 5.2 25.5 5.2 26.5 5.2 27.5 5.3 28.6 5.4 29.6L0.4 34C0 34.2-0.1 34.7 0.1 35.1 1.1 38.3 2.9 41.4 5.1 43.9 5.4 44.2 5.8 44.4 6.2 44.2L12.6 42C14.1 43.2 16 44.3 17.9 45L19.1 51.7C19.2 52.1 19.6 52.5 20 52.5 21.6 52.8 23.3 53 25 53 26.7 53 28.4 52.8 30 52.5 30.4 52.5 30.8 52.1 30.9 51.7L32.1 45C34 44.3 35.8 43.2 37.4 42L43.8 44.2C44.2 44.4 44.6 44.2 44.9 43.9 47.1 41.4 48.9 38.3 49.9 35.1 50.1 34.7 50 34.2 49.6 34L44.6 29.6ZM25 36.4C19.6 36.4 15.2 32 15.2 26.5 15.2 21 19.6 16.6 25 16.6 30.4 16.6 34.8 21 34.8 26.5 34.8 32 30.4 36.4 25 36.4Z"></path></g></svg><span>Settings</span></a></li><li><a href="https://www.oreilly.com/online-learning/support/" class="l1 no-icon">Support</a></li><li><a href="https://learning.oreilly.com/accounts/logout/" class="l1 no-icon">Sign Out</a></li></ul><ul class="profile"><li><a href="https://learning.oreilly.com/u/preferences/" class="l2 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 53" width="20" height="20" version="1.1" fill="#4A3C31"><desc>settings icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M44.6 29.6C44.7 28.6 44.8 27.5 44.8 26.5 44.8 25.5 44.7 24.4 44.6 23.4L49.6 19C50 18.8 50.1 18.3 49.9 17.9 48.9 14.7 47.1 11.7 44.9 9.1 44.6 8.8 44.2 8.7 43.8 8.8L37.4 11.1C35.8 9.8 34 8.7 32.1 8L30.9 1.4C30.8 0.9 30.4 0.6 30 0.5 26.7-0.2 23.3-0.2 20 0.5 19.6 0.6 19.2 0.9 19.1 1.4L17.9 8C16 8.7 14.1 9.8 12.6 11.1L6.2 8.8C5.8 8.7 5.4 8.8 5.1 9.1 2.9 11.7 1.1 14.7 0.1 17.9 -0.1 18.3 0 18.8 0.4 19L5.4 23.4C5.3 24.4 5.2 25.5 5.2 26.5 5.2 27.5 5.3 28.6 5.4 29.6L0.4 34C0 34.2-0.1 34.7 0.1 35.1 1.1 38.3 2.9 41.4 5.1 43.9 5.4 44.2 5.8 44.4 6.2 44.2L12.6 42C14.1 43.2 16 44.3 17.9 45L19.1 51.7C19.2 52.1 19.6 52.5 20 52.5 21.6 52.8 23.3 53 25 53 26.7 53 28.4 52.8 30 52.5 30.4 52.5 30.8 52.1 30.9 51.7L32.1 45C34 44.3 35.8 43.2 37.4 42L43.8 44.2C44.2 44.4 44.6 44.2 44.9 43.9 47.1 41.4 48.9 38.3 49.9 35.1 50.1 34.7 50 34.2 49.6 34L44.6 29.6ZM25 36.4C19.6 36.4 15.2 32 15.2 26.5 15.2 21 19.6 16.6 25 16.6 30.4 16.6 34.8 21 34.8 26.5 34.8 32 30.4 36.4 25 36.4Z"></path></g></svg><span>Settings</span></a></li><li><a href="https://www.oreilly.com/online-learning/support/" class="l2">Support</a></li><li><a href="https://learning.oreilly.com/accounts/logout/" class="l2">Sign Out</a></li></ul></div></li></ul></nav></header>


      </div>
      <div id="container" class="application" style="height: auto;">
        
          <div class="nav-container clearfix">
            


            
            
          </div>

          

  <div class="js-toc">
    
      <div class="sbo-reading-menu sbo-menu-top"><section class="sbo-toc-container toc-menu"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#" class="sbo-toc-thumb"><span class="sbo-title ss-list"><h1><div class="visuallyhidden">Table of Contents for </div>
      
      Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition
      
    </h1></span></a><div class="toc-contents"></div></section></div>

    

    <div class="interface-controls interface-controls-top">
      <ul class="interface-control-btns js-bitlist js-reader">
        <li class="js-search-in-archive search-in-archive t-search-in-archive"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#" title="Search in archive" class="js-search-controls search-controls"><span class="icon">Search in book...</span></a><form class="search-archive-bar js-search-form"><input type="search" name="query" placeholder="Search inside this book..." autocomplete="off"></form><div class="search-archive-results"><div class="js-sitb-results-region"></div></div></li><li class="queue-control"><div class="js-content-uri" data-content-uri="/api/v1/book/9781492032632/chapter/part01.html"><div class="js-collections-dropdown collections-dropdown menu-bit-cards"><div data-reactroot="" class="menu-dropdown-wrapper js-menu-dropdown-wrapper align-right"><img class="hidden" src="./Chapter13_files/ajax-transp.gif" alt="loading spinner"><div class="menu-control"><div class="control "><div class="js-playlists-menu"><button class="js-playlist-icon"><svg class="icon-add-to-playlist-sml" viewBox="0 0 16 14" version="1.1" xmlns="http://www.w3.org/2000/svg"><g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g fill-rule="nonzero" fill="#000000"><g transform="translate(-1.000000, 0.000000)"><rect x="5" y="0" width="12" height="2"></rect><title>Playlists</title><path d="M4.5,14 C6.43299662,14 8,12.4329966 8,10.5 C8,8.56700338 6.43299662,7 4.5,7 C2.56700338,7 1,8.56700338 1,10.5 C1,12.4329966 2.56700338,14 4.5,14 Z M2.5,10 L4,10 L4,8.5 L5,8.5 L5,10 L6.5,10 L6.5,11 L5,11 L5,12.5 L4,12.5 L4,11 L2.5,11 L2.5,10 Z"></path><circle cx="2" cy="5" r="1"></circle><circle cx="1.94117647" cy="1" r="1"></circle><rect x="5" y="4" width="12" height="2"></rect><rect x="9" y="8" width="8" height="2"></rect><rect x="9" y="12" width="8" height="2"></rect></g></g></g></svg><div class="js-playlist-addto-label">Add&nbsp;To</div></button></div></div></div></div></div></div></li><li class="js-font-control-panel font-control-activator"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#" data-push-state="false" id="font-controls" title="Change font size" aria-label="Change font size"><span class="icon">Toggle Font Controls</span></a></li><li class="dropdown sharing-controls"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#" class="trigger" data-push-state="false" title="Share" aria-label="Share"><i class="fa fa-share"></i></a><ul class="social-sharing dropdown-menu"><li><a class="twitter share-button t-twitter" target="_blank" aria-label="Share this section on Twitter" title="Share this section on Twitter" href="https://twitter.com/share?url=https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/part01.html&amp;text=Hands-on%20Machine%20Learning%20with%20Scikit-Learn%2C%20Keras%2C%20and%20TensorFlow%2C%202nd%20Edition&amp;via=safari"><span>Twitter</span></a></li><li><a class="facebook share-button t-facebook" target="_blank" aria-label="Share this section on Facebook" title="Share this section on Facebook" href="https://www.facebook.com/sharer/sharer.php?u=https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/part01.html"><span>Facebook</span></a></li><li><a class="googleplus share-button t-googleplus" target="_blank" aria-label="Share this secton on Google Plus" title="Share this secton on Google Plus" href="https://plus.google.com/share?url=https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/part01.html"><span>Google Plus</span></a></li><li><a class="email share-button t-email" aria-label="Share this section via email" title="Share this section via email" href="mailto:?subject=Safari:%20I.%20The%20Fundamentals%20of%20Machine%20Learning&amp;body=https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/part01.html%0D%0Afrom%20Hands-on%20Machine%20Learning%20with%20Scikit-Learn%2C%20Keras%2C%20and%20TensorFlow%2C%202nd%20Edition%0D%0A"><span>Email</span></a></li></ul></li>
      </ul>
    </div>

    
    <section role="document">
	  <div class="t-sbo-prev sbo-prev sbo-nav-top">
  
    
      
        <a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html" class="prev nav-link">
      
          <span aria-hidden="true" class="pagination-label t-prev-label">Prev</span>
          <span class="visuallyhidden">Previous Chapter</span>
          <div class="pagination-title t-prev-title">12. Custom Models and Training with TensorFlow</div>
        </a>
    
  
  </div>

  <div class="t-sbo-next sbo-next sbo-nav-top">
  
    
      
        <a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch14.html" class="next nav-link">
      
          <span aria-hidden="true" class="pagination-label t-next-label">Next</span>
          <span class="visuallyhidden">Next Chapter</span>
          <div class="pagination-title t-next-title">14. Deep Computer Vision Using Convolutional Neural Networks</div>
        </a>
    
  
  </div>



<div id="sbo-rt-content"><div class="annotator-wrapper"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 13. Loading and Preprocessing Data with TensorFlow"><div class="chapter" id="data_chapter">
<h1><span class="label">Chapter 13. </span>Loading and Preprocessing Data with TensorFlow</h1>


<p>So far we have used only datasets that fit in memory, but Deep Learning systems are often trained on very large datasets that will not fit in RAM. Ingesting a large dataset and preprocessing it efficiently can be tricky to implement with other Deep Learning libraries, but TensorFlow makes it easy thanks to the <em>Data API</em>: you just create a dataset object, tell it where to get the data and how to transform it. TensorFlow takes care of all the implementation details, such as multithreading, queuing, batching, and prefetching. Moreover, the Data API works seamlessly with tf.keras!</p>

<p>Off the shelf, the Data API can read from text files (such as CSV files), binary files with fixed-size records, and binary files that use TensorFlow’s TFRecord format, which supports records of varying sizes. TFRecord is a flexible and efficient binary format based on Protocol Buffers (an open source binary format). The Data API also has support for reading from SQL databases. Moreover, many Open Source extensions are available to read from all sorts of data sources, such as Google’s BigQuery service.</p>

<p>Reading huge datasets efficiently is not the only difficulty: the data also needs to be preprocessed, usually normalized. Moreover, it is not always composed strictly of convenient numerical fields: there may be text features, categorical features, and so on. These need to be encoded, for example using one-hot encoding, bag-of-words encoding, or <em>embeddings</em> (as we will see, an embedding is a trainable dense vector that represents a category or token). To handle all this preprocessing, one option is to write custom preprocessing layers. Moreover, TensorFlow will soon provide standard Keras preprocessing layers to help you (they may actually be available by the time you read this).<sup><a data-type="noteref" id="idm46263504438760-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#idm46263504438760" class="totri-footnote">1</a></sup></p>

<p>In this chapter, we will cover the Data API, the TFRecord format, and how to create custom preprocessing layers and use the standard ones. We will also take a quick look at a few related projects from TensorFlow’s ecosystem:</p>
<dl>
<dt>TF Transform (<em>tf.Transform</em>)</dt>
<dd>
<p>Makes it possible to write a single preprocessing function that can be run both in batch mode on your full training set, before training (to speed it up), and then exported to a TF Function and incorporated into your trained model, so that once it is deployed in production, it can take care of preprocessing new instances on the fly.</p>
</dd>
<dt>TF Datasets (TFDS)</dt>
<dd>
<p>Provides a convenient function to download many common datasets of all kinds, including large ones like ImageNet, and it provides convenient dataset objects to manipulate them using the Data API.</p>
</dd>
</dl>

<p>So let’s get started!</p>






<section data-type="sect1" data-pdf-bookmark="The Data API"><div class="sect1" id="idm46263504432744">
<h1>The Data API</h1>

<p>The whole Data API revolves around the concept of a <em>dataset</em>: as you might suspect, this represents a sequence of data items. Usually you will use datasets that gradually read data from disk, but for simplicity let’s create a dataset entirely in RAM using <code>tf.data.Dataset.from_tensor_slices()</code>:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">X</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">range</code><code class="p">(</code><code class="mi">10</code><code class="p">)</code>  <code class="c"># any data tensor</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">dataset</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">data</code><code class="o">.</code><code class="n">Dataset</code><code class="o">.</code><code class="n">from_tensor_slices</code><code class="p">(</code><code class="n">X</code><code class="p">)</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">dataset</code>
<code class="go">&lt;TensorSliceDataset shapes: (), types: tf.int32&gt;</code></pre>

<p>The <code>from_tensor_slices()</code> function takes a tensor and creates a <code>tf.data.Dataset</code> whose elements are all the slices of <code>X</code> (along the first dimension), so this dataset contains 10 items: tensors 0, 1, 2, …, 9. In this case we would have obtained the same dataset if we had used <code>tf.data.Dataset.range(10)</code>.</p>

<p>You can simply iterate over a dataset’s items like this:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="k">for</code> <code class="n">item</code> <code class="ow">in</code> <code class="n">dataset</code><code class="p">:</code>
<code class="gp">... </code>    <code class="k">print</code><code class="p">(</code><code class="n">item</code><code class="p">)</code>
<code class="gp">...</code>
<code class="go">tf.Tensor(0, shape=(), dtype=int32)</code>
<code class="go">tf.Tensor(1, shape=(), dtype=int32)</code>
<code class="go">tf.Tensor(2, shape=(), dtype=int32)</code>
<code class="go">[...]</code>
<code class="go">tf.Tensor(9, shape=(), dtype=int32)</code></pre>








<section data-type="sect2" data-pdf-bookmark="Chaining Transformations"><div class="sect2" id="idm46263504385288">
<h2>Chaining Transformations</h2>

<p>Once you have a dataset, you can apply all sorts of transformations to it by calling its transformation methods. Each method returns a new dataset, so you can chain transformations like this (this chain is illustrated in <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#chaining_transformations_diagram">Figure&nbsp;13-1</a>):</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">dataset</code> <code class="o">=</code> <code class="n">dataset</code><code class="o">.</code><code class="n">repeat</code><code class="p">(</code><code class="mi">3</code><code class="p">)</code><code class="o">.</code><code class="n">batch</code><code class="p">(</code><code class="mi">7</code><code class="p">)</code>
<code class="gp">&gt;&gt;&gt; </code><code class="k">for</code> <code class="n">item</code> <code class="ow">in</code> <code class="n">dataset</code><code class="p">:</code>
<code class="gp">... </code>    <code class="k">print</code><code class="p">(</code><code class="n">item</code><code class="p">)</code>
<code class="gp">...</code>
<code class="go">tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)</code>
<code class="go">tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)</code>
<code class="go">tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)</code>
<code class="go">tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)</code>
<code class="go">tf.Tensor([8 9], shape=(2,), dtype=int32)</code></pre>

<figure><div id="chaining_transformations_diagram" class="figure">
<img src="./Chapter13_files/mls2_1301.png" alt="mls2 1301" width="1442" height="546" data-mfp-src="/library/view/hands-on-machine-learning/9781492032632/assets/mls2_1301.png">
<h6><span class="label">Figure 13-1. </span>Chaining dataset transformations</h6>
</div></figure>

<p>In this example, we first call the <code>repeat()</code> method on the original dataset, and it returns a new dataset that will repeat the items of the original dataset three times. Of course, this will not copy the whole data in memory three times! In fact, if you call this method with no arguments, the new dataset will repeat the source dataset forever (so the code that iterates over the dataset will have to decide when to stop). Then we call the <code>batch()</code> method on this new dataset, and again this creates a new dataset. This one will group the items of the previous dataset in batches of seven items. Finally, we iterate over the items of this final dataset. As you can see, the <code>batch()</code> method had to output a final batch of size two instead of seven, but you can call it with <code>drop_remainder=True</code> if you want it to drop this final batch so that all batches have the exact same size.</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>The dataset methods do <em>not</em> modify datasets, they create new ones, so make sure to keep a reference to these new datasets (e.g., <code>dataset = ...</code>), or else nothing will happen.</p>
</div>

<p>You can also transform the items by calling the <code>map()</code> method. For example, this creates a new dataset with all items doubled:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">dataset</code> <code class="o">=</code> <code class="n">dataset</code><code class="o">.</code><code class="n">map</code><code class="p">(</code><code class="k">lambda</code> <code class="n">x</code><code class="p">:</code> <code class="n">x</code> <code class="o">*</code> <code class="mi">2</code><code class="p">)</code> <code class="c"># Items: [0,2,4,6,8,10,12]</code></pre>

<p>This function is the one you will call to apply any preprocessing you want to your data. Sometimes this will include computations that can be quite intensive, such as reshaping or rotating an image, so you will usually want to spawn multiple threads to speed things up: it’s as simple as setting the <code>num_parallel_calls</code> argument. Note that the function you pass to the <code>map()</code> method must be convertible to a TF Function (see <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#data_chapter">Chapter&nbsp;13</a>).</p>

<p>While the <code>map()</code> method applies a transformation to each item, the <code>apply()</code> method applies a transformation to the dataset as a whole. For example, the following code applies the <code>unbatch()</code> function to the dataset (this function is currently experimental, but it will most likely move to the core API in a future release). Each item in the new dataset will be a single integer tensor instead of a batch of seven integers:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">dataset</code> <code class="o">=</code> <code class="n">dataset</code><code class="o">.</code><code class="n">apply</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">data</code><code class="o">.</code><code class="n">experimental</code><code class="o">.</code><code class="n">unbatch</code><code class="p">())</code> <code class="c"># Items: 0,2,4,...</code></pre>

<p>It is also possible to simply filter the dataset using the <code>filter()</code> method:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">dataset</code> <code class="o">=</code> <code class="n">dataset</code><code class="o">.</code><code class="n">filter</code><code class="p">(</code><code class="k">lambda</code> <code class="n">x</code><code class="p">:</code> <code class="n">x</code> <code class="o">&lt;</code> <code class="mi">10</code><code class="p">)</code> <code class="c"># Items: 0 2 4 6 8 0 2 4 6...</code></pre>

<p>You will often want to look at just a few items from a dataset. You can use the <code>take()</code> method for that:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="k">for</code> <code class="n">item</code> <code class="ow">in</code> <code class="n">dataset</code><code class="o">.</code><code class="n">take</code><code class="p">(</code><code class="mi">3</code><code class="p">):</code>
<code class="gp">... </code>    <code class="k">print</code><code class="p">(</code><code class="n">item</code><code class="p">)</code>
<code class="gp">...</code>
<code class="go">tf.Tensor(0, shape=(), dtype=int64)</code>
<code class="go">tf.Tensor(2, shape=(), dtype=int64)</code>
<code class="go">tf.Tensor(4, shape=(), dtype=int64)</code></pre>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Shuffling the Data"><div class="sect2" id="idm46263504141384">
<h2>Shuffling the Data</h2>

<p>As you know, Gradient Descent works best when the instances in the training set are independent and identically distributed (see <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch04.html#linear_models_chapter">Chapter&nbsp;4</a>). A simple way to ensure this is to shuffle the instances, using the <code>shuffle()</code> method. It will create a new dataset that will start by filling up a buffer with the first items of the source dataset. Then whenever it is asked for an item, it will pull one out randomly from the buffer and replace it with a fresh one from the source dataset, until it has iterated entirely through the source dataset. At this point it continues to pull out items randomly from the buffer until it is empty. You must specify the buffer size, and it is important to make it large enough or else shuffling will not be very effective.<sup><a data-type="noteref" id="idm46263504143880-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#idm46263504143880" class="totri-footnote">2</a></sup> Just don’t exceed the amount of RAM you have, and even if you have plenty of it, there’s no need to go beyond the dataset’s size. You can provide a random seed if you want the same random order every time you run your program. For example, the following code creates and displays a dataset containing the integers 0 to 9, repeated three times, shuffled using a buffer of size 5 and a random seed of 42, and  batched with a batch size of 7:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">dataset</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">data</code><code class="o">.</code><code class="n">Dataset</code><code class="o">.</code><code class="n">range</code><code class="p">(</code><code class="mi">10</code><code class="p">)</code><code class="o">.</code><code class="n">repeat</code><code class="p">(</code><code class="mi">3</code><code class="p">)</code> <code class="c"># 0 to 9, three times</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">dataset</code> <code class="o">=</code> <code class="n">dataset</code><code class="o">.</code><code class="n">shuffle</code><code class="p">(</code><code class="n">buffer_size</code><code class="o">=</code><code class="mi">5</code><code class="p">,</code> <code class="n">seed</code><code class="o">=</code><code class="mi">42</code><code class="p">)</code><code class="o">.</code><code class="n">batch</code><code class="p">(</code><code class="mi">7</code><code class="p">)</code>
<code class="gp">&gt;&gt;&gt; </code><code class="k">for</code> <code class="n">item</code> <code class="ow">in</code> <code class="n">dataset</code><code class="p">:</code>
<code class="gp">... </code>    <code class="k">print</code><code class="p">(</code><code class="n">item</code><code class="p">)</code>
<code class="gp">...</code>
<code class="go">tf.Tensor([0 2 3 6 7 9 4], shape=(7,), dtype=int64)</code>
<code class="go">tf.Tensor([5 0 1 1 8 6 5], shape=(7,), dtype=int64)</code>
<code class="go">tf.Tensor([4 8 7 1 2 3 0], shape=(7,), dtype=int64)</code>
<code class="go">tf.Tensor([5 4 2 7 8 9 9], shape=(7,), dtype=int64)</code>
<code class="go">tf.Tensor([3 6], shape=(2,), dtype=int64)</code></pre>
<div data-type="tip"><h6>Tip</h6>
<p>If you call <code>repeat()</code> on a shuffled dataset, by default it will generate a new order at every iteration. This is generally a good idea, but if you prefer to reuse the same order at each iteration (e.g., for tests or debugging), you can set <code>reshuffle_each_iteration=False</code>.</p>
</div>

<p>For a large dataset that does not fit in memory, this simple shuffling-buffer approach may not be sufficient, since the buffer will be small compared to the dataset. One solution is to shuffle the source data itself (for example, on Linux you can shuffle text files using the <code>shuf</code> command). This will definitely improve shuffling a lot! Even if the source data is shuffled, you will usually want to shuffle it some more, or else the same order will be repeated at each epoch, and the model may end up being biased (e.g., due to some spurious patterns present by chance in the source data’s order). To shuffle the instances some more, a common approach is to split the source data into multiple files, then read them in a random order during training. However, instances located in the same file will still end up close to each other. To avoid this you can pick multiple files randomly and read them simultaneously, interleaving their records. Then on top of that you can add a shuffling buffer using the <code>shuffle()</code> method. If all this sounds like a lot of work, don’t worry: the Data API makes all this possible in just a few lines of code. Let’s see how to do this.</p>










<section data-type="sect3" data-pdf-bookmark="Interleaving lines from multiple files"><div class="sect3" id="idm46263504035256">
<h3>Interleaving lines from multiple files</h3>

<p>First, let’s suppose that you loaded the California housing dataset, you shuffled it (unless it was already shuffled), you split it into a training set, a validation set, and a test set, then you split each set into many CSV files that each look like this (each row contains eight input features plus the target median house value):</p>

<pre data-type="programlisting">MedInc,HouseAge,AveRooms,AveBedrms,Popul,AveOccup,Lat,Long,MedianHouseValue
3.5214,15.0,3.0499,1.1065,1447.0,1.6059,37.63,-122.43,1.442
5.3275,5.0,6.4900,0.9910,3464.0,3.4433,33.69,-117.39,1.687
3.1,29.0,7.5423,1.5915,1328.0,2.2508,38.44,-122.98,1.621
[...]</pre>

<p>Let’s also suppose <code>train_filepaths</code> contains the list of training file paths (and you also have <code>valid_filepaths</code> and <code>test_filepaths</code>):</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">train_filepaths</code>
<code class="go">['datasets/housing/my_train_00.csv', 'datasets/housing/my_train_01.csv',...]</code></pre>

<p>Alternatively, you could use file patterns, for example <code>train_filepaths = "datasets/housing/my_train_*.csv"</code>. Now let’s create a dataset containing only these file paths:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">filepath_dataset</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">data</code><code class="o">.</code><code class="n">Dataset</code><code class="o">.</code><code class="n">list_files</code><code class="p">(</code><code class="n">train_filepaths</code><code class="p">,</code> <code class="n">seed</code><code class="o">=</code><code class="mi">42</code><code class="p">)</code></pre>

<p>By default, the <code>list_files()</code> function returns a dataset that shuffles the file paths. In general this is a good thing, but you can set <code>shuffle=False</code> if you do not want that, for some reason.</p>

<p>Next, we can call the <code>interleave()</code> method to read from five files at a time and interleave their lines (skipping the first line of each file, which is the header row, using the <code>skip()</code> method):</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">n_readers</code> <code class="o">=</code> <code class="mi">5</code>
<code class="n">dataset</code> <code class="o">=</code> <code class="n">filepath_dataset</code><code class="o">.</code><code class="n">interleave</code><code class="p">(</code>
    <code class="k">lambda</code> <code class="n">filepath</code><code class="p">:</code> <code class="n">tf</code><code class="o">.</code><code class="n">data</code><code class="o">.</code><code class="n">TextLineDataset</code><code class="p">(</code><code class="n">filepath</code><code class="p">)</code><code class="o">.</code><code class="n">skip</code><code class="p">(</code><code class="mi">1</code><code class="p">),</code>
    <code class="n">cycle_length</code><code class="o">=</code><code class="n">n_readers</code><code class="p">)</code></pre>

<p>The <code>interleave()</code> method will create a dataset that will pull five file paths from the <code>filepath_dataset</code>, and for each one it will call the function we gave it (a lambda in this example) to create a new dataset, in this case a <code>TextLineDataset</code>. It will then cycle through these 5 datasets, reading one line at a time from each until all datasets are out of items. Then it will get the next five file paths from the <code>filepath_dataset</code> and interleave them the same way, and so on until it runs out of file paths.</p>
<div data-type="tip"><h6>Tip</h6>
<p>For interleaving to work best, it is preferable to have files of identical length, or else the end of the longest files will not be interleaved.</p>
</div>

<p>By default, <code>interleave()</code> does not use parallelism; it just reads one line at a time from each file, sequentially. If you want it to actually read files in parallel, you can set the <code>num_parallel_calls</code> argument to the number of threads you want (note that the <code>map()</code> method also has this argument). You can even set it to <code>tf.data.experimental.AUTOTUNE</code> to make TensorFlow choose the right number of threads dynamically based on the available CPU (however, this is an experimental feature for now). Let’s look at what the dataset contains now:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="k">for</code> <code class="n">line</code> <code class="ow">in</code> <code class="n">dataset</code><code class="o">.</code><code class="n">take</code><code class="p">(</code><code class="mi">5</code><code class="p">):</code>
<code class="gp">... </code>    <code class="k">print</code><code class="p">(</code><code class="n">line</code><code class="o">.</code><code class="n">numpy</code><code class="p">())</code>
<code class="gp">...</code>
<code class="go">b'4.2083,44.0,5.3232,0.9171,846.0,2.3370,37.47,-122.2,2.782'</code>
<code class="go">b'4.1812,52.0,5.7013,0.9965,692.0,2.4027,33.73,-118.31,3.215'</code>
<code class="go">b'3.6875,44.0,4.5244,0.9930,457.0,3.1958,34.04,-118.15,1.625'</code>
<code class="go">b'3.3456,37.0,4.5140,0.9084,458.0,3.2253,36.67,-121.7,2.526'</code>
<code class="go">b'3.5214,15.0,3.0499,1.1065,1447.0,1.6059,37.63,-122.43,1.442'</code></pre>

<p>These are the first rows (ignoring the header row) of five CSV files, chosen randomly. Looks good! But as you can see, these are just byte strings; we need to parse them and scale the data.</p>
</div></section>



</div></section>













<section data-type="sect2" data-pdf-bookmark="Preprocessing the Data"><div class="sect2" id="idm46263504034632">
<h2>Preprocessing the Data</h2>

<p>Let’s implement a small function that will perform this preprocessing:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">X_mean</code><code class="p">,</code> <code class="n">X_std</code> <code class="o">=</code> <code class="p">[</code><code class="o">...</code><code class="p">]</code> <code class="c1"># mean and scale of each feature in the training set</code>
<code class="n">n_inputs</code> <code class="o">=</code> <code class="mi">8</code>

<code class="k">def</code> <code class="nf">preprocess</code><code class="p">(</code><code class="n">line</code><code class="p">):</code>
  <code class="n">defs</code> <code class="o">=</code> <code class="p">[</code><code class="mf">0.</code><code class="p">]</code> <code class="o">*</code> <code class="n">n_inputs</code> <code class="o">+</code> <code class="p">[</code><code class="n">tf</code><code class="o">.</code><code class="n">constant</code><code class="p">([],</code> <code class="n">dtype</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">)]</code>
  <code class="n">fields</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">io</code><code class="o">.</code><code class="n">decode_csv</code><code class="p">(</code><code class="n">line</code><code class="p">,</code> <code class="n">record_defaults</code><code class="o">=</code><code class="n">defs</code><code class="p">)</code>
  <code class="n">x</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">stack</code><code class="p">(</code><code class="n">fields</code><code class="p">[:</code><code class="o">-</code><code class="mi">1</code><code class="p">])</code>
  <code class="n">y</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">stack</code><code class="p">(</code><code class="n">fields</code><code class="p">[</code><code class="o">-</code><code class="mi">1</code><code class="p">:])</code>
  <code class="k">return</code> <code class="p">(</code><code class="n">x</code> <code class="o">-</code> <code class="n">X_mean</code><code class="p">)</code> <code class="o">/</code> <code class="n">X_std</code><code class="p">,</code> <code class="n">y</code></pre>

<p>Let’s walk through this code:</p>

<ul>
<li>
<p>First, we assume that you have precomputed the mean and standard deviation of each feature in the training set. <code>X_mean</code> and <code>X_std</code> are just 1D tensors (or NumPy arrays) containing eight floats, one per input feature.</p>
</li>
<li>
<p>The <code>preprocess()</code> function takes one CSV line and starts by parsing it. For this, it uses the <code>tf.io.decode_csv()</code> function, which takes two arguments: the first is the line to parse, and the second is an array containing the default value for each column in the CSV file. This array tells TensorFlow not only the default value for each column, but also the number of columns and their types. In this example, we tell it that all feature columns are floats and missing values should default to 0, but we provide an empty array of type <code>tf.float32</code> as the default value for the last column (the target): the array tells TensorFlow that this column contains floats, but that there is no default value, so it will raise an exception if it encounters a missing value.</p>
</li>
<li>
<p>The <code>decode_csv()</code> function returns a list of scalar tensors (one per column), but we need to return 1D tensor arrays. So we call <code>tf.stack()</code> on all tensors except for the last one (the target): this will stack these tensors into a 1D array. We then do the same for the target value (this makes it a 1D tensor array with a single value, rather than a scalar tensor).</p>
</li>
<li>
<p>Finally, we scale the input features by subtracting the feature means and then dividing by the feature standard deviations, and we return a tuple containing the scaled features and the target.</p>
</li>
</ul>

<p>Let’s test this preprocessing function:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">preprocess</code><code class="p">(</code><code class="n">b</code><code class="s">'4.2083,44.0,5.3232,0.9171,846.0,2.3370,37.47,-122.2,2.782'</code><code class="p">)</code>
<code class="go">(&lt;tf.Tensor: id=6227, shape=(8,), dtype=float32, numpy=</code>
<code class="go"> array([ 0.16579159,  1.216324  , -0.05204564, -0.39215982, -0.5277444 ,</code>
<code class="go">        -0.2633488 ,  0.8543046 , -1.3072058 ], dtype=float32)&gt;,</code>
<code class="go"> &lt;tf.Tensor: [...], numpy=array([2.782], dtype=float32)&gt;)</code></pre>

<p>Looks good! We can now apply this preprocessing function to the dataset.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Putting Everything Together"><div class="sect2" id="idm46263503642376">
<h2>Putting Everything Together</h2>

<p>To make the code reusable, let’s put together everything we have discussed so far into a small helper function: it will create and return a dataset that will efficiently load California housing data from multiple CSV files, preprocess it, shuffle it, optionally repeat it, and batch it (see <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#input_pipeline_diagram">Figure&nbsp;13-2</a>):</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">csv_reader_dataset</code><code class="p">(</code><code class="n">filepaths</code><code class="p">,</code> <code class="n">repeat</code><code class="o">=</code><code class="mi">1</code><code class="p">,</code> <code class="n">n_readers</code><code class="o">=</code><code class="mi">5</code><code class="p">,</code>
                       <code class="n">n_read_threads</code><code class="o">=</code><code class="bp">None</code><code class="p">,</code> <code class="n">shuffle_buffer_size</code><code class="o">=</code><code class="mi">10000</code><code class="p">,</code>
                       <code class="n">n_parse_threads</code><code class="o">=</code><code class="mi">5</code><code class="p">,</code> <code class="n">batch_size</code><code class="o">=</code><code class="mi">32</code><code class="p">):</code>
    <code class="n">dataset</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">data</code><code class="o">.</code><code class="n">Dataset</code><code class="o">.</code><code class="n">list_files</code><code class="p">(</code><code class="n">filepaths</code><code class="p">)</code>
    <code class="n">dataset</code> <code class="o">=</code> <code class="n">dataset</code><code class="o">.</code><code class="n">interleave</code><code class="p">(</code>
        <code class="k">lambda</code> <code class="n">filepath</code><code class="p">:</code> <code class="n">tf</code><code class="o">.</code><code class="n">data</code><code class="o">.</code><code class="n">TextLineDataset</code><code class="p">(</code><code class="n">filepath</code><code class="p">)</code><code class="o">.</code><code class="n">skip</code><code class="p">(</code><code class="mi">1</code><code class="p">),</code>
        <code class="n">cycle_length</code><code class="o">=</code><code class="n">n_readers</code><code class="p">,</code> <code class="n">num_parallel_calls</code><code class="o">=</code><code class="n">n_read_threads</code><code class="p">)</code>
    <code class="n">dataset</code> <code class="o">=</code> <code class="n">dataset</code><code class="o">.</code><code class="n">map</code><code class="p">(</code><code class="n">preprocess</code><code class="p">,</code> <code class="n">num_parallel_calls</code><code class="o">=</code><code class="n">n_parse_threads</code><code class="p">)</code>
    <code class="n">dataset</code> <code class="o">=</code> <code class="n">dataset</code><code class="o">.</code><code class="n">shuffle</code><code class="p">(</code><code class="n">shuffle_buffer_size</code><code class="p">)</code><code class="o">.</code><code class="n">repeat</code><code class="p">(</code><code class="n">repeat</code><code class="p">)</code>
    <code class="k">return</code> <code class="n">dataset</code><code class="o">.</code><code class="n">batch</code><code class="p">(</code><code class="n">batch_size</code><code class="p">)</code><code class="o">.</code><code class="n">prefetch</code><code class="p">(</code><code class="mi">1</code><code class="p">)</code></pre>

<figure><div id="input_pipeline_diagram" class="figure">
<img src="./Chapter13_files/mls2_1302.png" alt="mls2 1302" width="1439" height="916" data-mfp-src="/library/view/hands-on-machine-learning/9781492032632/assets/mls2_1302.png">
<h6><span class="label">Figure 13-2. </span>Loading and preprocessing data from multiple CSV files</h6>
</div></figure>

<p>Everything should make sense in this code, except the very last line (<code>prefetch(1)</code>), which is important for performance.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Prefetching"><div class="sect2" id="idm46263503513640">
<h2>Prefetching</h2>

<p>By calling <code>prefetch(1)</code> at the end, we are creating a dataset that will do its best to always be one batch ahead.<sup><a data-type="noteref" id="idm46263503511288-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#idm46263503511288" class="totri-footnote">3</a></sup> In other words, while our training algorithm is working on one batch, the dataset will already be working in parallel on getting the next batch ready (e.g., reading the data from disk and preprocessing it). This can improve performance dramatically, as is illustrated in <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#prefetching_diagram">Figure&nbsp;13-3</a>. If we also ensure that loading and preprocessing are multithreaded (by setting <code>num_parallel_calls</code> when calling <code>interleave()</code> and <code>map()</code>), we can exploit multiple cores on the CPU and hopefully make preparing one batch of data shorter than running a training step on the GPU: this way the GPU will be almost 100% utilized (except for the data transfer time from the CPU to the GPU<sup><a data-type="noteref" id="idm46263503507400-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#idm46263503507400" class="totri-footnote">4</a></sup>), and training will run much faster.</p>

<figure><div id="prefetching_diagram" class="figure">
<img src="./Chapter13_files/mls2_1303.png" alt="mls2 1303" width="1440" height="1101" data-mfp-src="/library/view/hands-on-machine-learning/9781492032632/assets/mls2_1303.png">
<h6><span class="label">Figure 13-3. </span>With prefetching, the CPU and the GPU work in parallel: as the GPU works on one batch, the CPU works on the next</h6>
</div></figure>
<div data-type="tip"><h6>Tip</h6>
<p>If you plan to purchase a GPU card, its processing power and its memory size are of course very important (in particular, a large RAM is crucial for computer vision). Just as important to get good performance is its <em>memory bandwidth</em>; this is the number of gigabytes of data it can get in or out of its RAM per second.</p>
</div>

<p>If the dataset is small enough to fit in memory, you significantly speed up training by using the dataset’s <code>cache()</code> method to cache its content to RAM. You should generally do this after loading and preprocessing the data, but before shuffling, repeating, batching and prefetching. This way, each instance will only be read and preprocessed once (instead of once per epoch), but the data will still be shuffled differently at each epoch, and the next batch will still be prepared in advance.</p>

<p>With that, you can now build efficient input pipelines to load and preprocess data from multiple text files. We have discussed the most common dataset methods, but there are a few more you may want to look at: <code>concatenate()</code>, <code>zip()</code>, <code>window()</code>, <code>reduce()</code>, <code>shard()</code>, <code>flat_map()</code>, and <code>padded_batch()</code>. There are also a couple more class methods: <code>from_generator()</code> and <code>from_tensors()</code>, which create a new dataset from a Python generator or a list of tensors, respectively. Please check the API documentation for more details. Also note that there are experimental features available in <code>tf.data.experimental</code>, many of which will most likely make it to the core API in future releases (e.g., check out the <code>CsvDataset</code> class, as well as the <code>make_csv_dataset()</code> method, which takes care of inferring the type of each column).</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Using the Dataset with tf.keras"><div class="sect2" id="idm46263503500328">
<h2>Using the Dataset with tf.keras</h2>

<p>Now we can use the <code>csv_reader_dataset()</code> function to create a dataset for the training set. Note that we do not need to repeat it, as this will be taken care of by tf.keras. We also create a dataset for the validation set and the test set:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">train_set</code> <code class="o">=</code> <code class="n">csv_reader_dataset</code><code class="p">(</code><code class="n">train_filepaths</code><code class="p">)</code>
<code class="n">valid_set</code> <code class="o">=</code> <code class="n">csv_reader_dataset</code><code class="p">(</code><code class="n">valid_filepaths</code><code class="p">)</code>
<code class="n">test_set</code> <code class="o">=</code> <code class="n">csv_reader_dataset</code><code class="p">(</code><code class="n">test_filepaths</code><code class="p">)</code></pre>

<p>And now we can simply build and train a Keras model using these datasets.<sup><a data-type="noteref" id="idm46263503484808-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#idm46263503484808" class="totri-footnote">5</a></sup> All we need to do is to pass the training and validation datasets to the <code>fit()</code> method, instead of <code>X_train, y_train</code>, <code>X_valid</code>, and <code>y_valid</code>:<sup><a data-type="noteref" id="idm46263503482392-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#idm46263503482392" class="totri-footnote">6</a></sup></p>

<pre data-type="programlisting" data-code-language="python"><code class="n">model</code> <code class="o">=</code> <code class="n">keras</code><code class="o">.</code><code class="n">models</code><code class="o">.</code><code class="n">Sequential</code><code class="p">([</code><code class="o">...</code><code class="p">])</code>
<code class="n">model</code><code class="o">.</code><code class="n">compile</code><code class="p">([</code><code class="o">...</code><code class="p">])</code>
<code class="n">model</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">train_set</code><code class="p">,</code> <code class="n">epochs</code><code class="o">=</code><code class="mi">10</code><code class="p">,</code> <code class="n">validation_data</code><code class="o">=</code><code class="n">valid_set</code><code class="p">)</code></pre>

<p>Similarly, we can pass a dataset to the <code>evaluate()</code> and <code>predict()</code> methods:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">model</code><code class="o">.</code><code class="n">evaluate</code><code class="p">(</code><code class="n">test_set</code><code class="p">)</code>
<code class="n">new_set</code> <code class="o">=</code> <code class="n">test_set</code><code class="o">.</code><code class="n">take</code><code class="p">(</code><code class="mi">3</code><code class="p">)</code><code class="o">.</code><code class="n">map</code><code class="p">(</code><code class="k">lambda</code> <code class="n">X</code><code class="p">,</code> <code class="n">y</code><code class="p">:</code> <code class="n">X</code><code class="p">)</code> <code class="c1"># pretend we have 3 new instances</code>
<code class="n">model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">new_set</code><code class="p">)</code> <code class="c1"># a dataset containing new instances</code></pre>

<p>Unlike the other sets, the <code>new_set</code> will usually not contain labels (if it does, Keras will ignore them). Note that in all these cases, you can still use NumPy arrays instead of datasets if you want (but of course they need to have been loaded and preprocessed first).</p>

<p>If you want to build your own custom training loop (as in <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#tensorflow_chapter">Chapter&nbsp;12</a>), you can just iterate over the training set, very naturally:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">for</code> <code class="n">X_batch</code><code class="p">,</code> <code class="n">y_batch</code> <code class="ow">in</code> <code class="n">train_set</code><code class="p">:</code>
    <code class="p">[</code><code class="o">...</code><code class="p">]</code> <code class="c1"># perform one gradient descent step</code></pre>

<p>In fact, it is even possible to create a TF Function (see <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#tensorflow_chapter">Chapter&nbsp;12</a>) that performs the whole training loop!</p>

<pre data-type="programlisting" data-code-language="python"><code class="nd">@tf.function</code>
<code class="k">def</code> <code class="nf">train</code><code class="p">(</code><code class="n">model</code><code class="p">,</code> <code class="n">optimizer</code><code class="p">,</code> <code class="n">loss_fn</code><code class="p">,</code> <code class="n">n_epochs</code><code class="p">,</code> <code class="p">[</code><code class="o">...</code><code class="p">]):</code>
    <code class="n">train_set</code> <code class="o">=</code> <code class="n">csv_reader_dataset</code><code class="p">(</code><code class="n">train_filepaths</code><code class="p">,</code> <code class="n">repeat</code><code class="o">=</code><code class="n">n_epochs</code><code class="p">,</code> <code class="p">[</code><code class="o">...</code><code class="p">])</code>
    <code class="k">for</code> <code class="n">X_batch</code><code class="p">,</code> <code class="n">y_batch</code> <code class="ow">in</code> <code class="n">train_set</code><code class="p">:</code>
        <code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">GradientTape</code><code class="p">()</code> <code class="k">as</code> <code class="n">tape</code><code class="p">:</code>
            <code class="n">y_pred</code> <code class="o">=</code> <code class="n">model</code><code class="p">(</code><code class="n">X_batch</code><code class="p">)</code>
            <code class="n">main_loss</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">reduce_mean</code><code class="p">(</code><code class="n">loss_fn</code><code class="p">(</code><code class="n">y_batch</code><code class="p">,</code> <code class="n">y_pred</code><code class="p">))</code>
            <code class="n">loss</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">add_n</code><code class="p">([</code><code class="n">main_loss</code><code class="p">]</code> <code class="o">+</code> <code class="n">model</code><code class="o">.</code><code class="n">losses</code><code class="p">)</code>
        <code class="n">grads</code> <code class="o">=</code> <code class="n">tape</code><code class="o">.</code><code class="n">gradient</code><code class="p">(</code><code class="n">loss</code><code class="p">,</code> <code class="n">model</code><code class="o">.</code><code class="n">trainable_variables</code><code class="p">)</code>
        <code class="n">optimizer</code><code class="o">.</code><code class="n">apply_gradients</code><code class="p">(</code><code class="nb">zip</code><code class="p">(</code><code class="n">grads</code><code class="p">,</code> <code class="n">model</code><code class="o">.</code><code class="n">trainable_variables</code><code class="p">))</code></pre>

<p>Congratulations, you now know how to build powerful input pipelines using the Data API! However, so far we have used CSV files, which are common, simple and convenient, but they are not really efficient, and they do not support large or complex data structures very well, such as images or audio. So let’s use TFRecords instead.</p>
<div data-type="tip"><h6>Tip</h6>
<p>If you are happy with CSV files (or whatever other format you are using), you do not <em>have</em> to use TFRecords. As the saying goes, if it ain’t broke, don’t fix it! TFRecords are useful when the bottleneck during training is loading and parsing the data.</p>
</div>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="The TFRecord Format"><div class="sect1" id="idm46263504432216">
<h1>The TFRecord Format</h1>

<p>The TFRecord format is TensorFlow’s preferred format for storing large amounts of data and reading it efficiently. It is a very simple binary format that just contains a sequence of binary records of varying sizes (each record just has a length, a CRC checksum to check that the length was not corrupted, then the actual data, and finally a CRC checksum for the data). You can easily create a TFRecord file using the <code>tf.io.TFRecordWriter</code> class:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">io</code><code class="o">.</code><code class="n">TFRecordWriter</code><code class="p">(</code><code class="s2">"my_data.tfrecord"</code><code class="p">)</code> <code class="k">as</code> <code class="n">f</code><code class="p">:</code>
    <code class="n">f</code><code class="o">.</code><code class="n">write</code><code class="p">(</code><code class="s-Affix">b</code><code class="s2">"This is the first record"</code><code class="p">)</code>
    <code class="n">f</code><code class="o">.</code><code class="n">write</code><code class="p">(</code><code class="s-Affix">b</code><code class="s2">"And this is the second record"</code><code class="p">)</code></pre>

<p>And you can then use a <code>tf.data.TFRecordDataset</code> to read one or more TFRecord files:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">filepaths</code> <code class="o">=</code> <code class="p">[</code><code class="s2">"my_data.tfrecord"</code><code class="p">]</code>
<code class="n">dataset</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">data</code><code class="o">.</code><code class="n">TFRecordDataset</code><code class="p">(</code><code class="n">filepaths</code><code class="p">)</code>
<code class="k">for</code> <code class="n">item</code> <code class="ow">in</code> <code class="n">dataset</code><code class="p">:</code>
    <code class="k">print</code><code class="p">(</code><code class="n">item</code><code class="p">)</code></pre>

<p>This will output:</p>

<pre data-type="programlisting">tf.Tensor(b'This is the first record', shape=(), dtype=string)
tf.Tensor(b'And this is the second record', shape=(), dtype=string)</pre>
<div data-type="tip"><h6>Tip</h6>
<p>By default, a <code>TFRecordDataset</code> will read files one by one, but you can make it read multiple files in parallel and interleave their records by setting <code>num_parallel_reads</code>. Alternatively, you could obtain the same result by using <code>list_files()</code> and <code>interleave()</code> as we did earlier to read multiple CSV files.</p>
</div>








<section data-type="sect2" data-pdf-bookmark="Compressed TFRecord Files"><div class="sect2" id="idm46263503045736">
<h2>Compressed TFRecord Files</h2>

<p>It can sometimes be useful to compress your TFRecord files, especially if they need to be loaded via a network connection. You can create a compressed TFRecord file by setting the <code>options</code> argument:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">options</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">io</code><code class="o">.</code><code class="n">TFRecordOptions</code><code class="p">(</code><code class="n">compression_type</code><code class="o">=</code><code class="s2">"GZIP"</code><code class="p">)</code>
<code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">io</code><code class="o">.</code><code class="n">TFRecordWriter</code><code class="p">(</code><code class="s2">"my_compressed.tfrecord"</code><code class="p">,</code> <code class="n">options</code><code class="p">)</code> <code class="k">as</code> <code class="n">f</code><code class="p">:</code>
  <code class="p">[</code><code class="o">...</code><code class="p">]</code></pre>

<p>When reading a compressed TFRecord file, you need to specify the compression type:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">dataset</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">data</code><code class="o">.</code><code class="n">TFRecordDataset</code><code class="p">([</code><code class="s2">"my_compressed.tfrecord"</code><code class="p">],</code>
                                  <code class="n">compression_type</code><code class="o">=</code><code class="s2">"GZIP"</code><code class="p">)</code></pre>
</div></section>













<section data-type="sect2" data-pdf-bookmark="A Brief Introduction to Protocol Buffers"><div class="sect2" id="idm46263503045400">
<h2>A Brief Introduction to Protocol Buffers</h2>

<p>Even though each record can use any binary format you want, TFRecord files usually contain serialized Protocol Buffers (also called <em>protobufs</em>). This is a portable, extensible, and efficient binary format developed at Google back in 2001 and made open source in 2008, and they are now widely used, in particular in <a href="https://grpc.io/">gRPC</a>, Google’s remote procedure call system. Protocol Buffers are defined using a simple language that looks like this:</p>

<pre data-type="programlisting" data-code-language="java"><code class="n">syntax</code> <code class="o">=</code> <code class="s">"proto3"</code><code class="o">;</code>
<code class="n">message</code> <code class="n">Person</code> <code class="o">{</code>
  <code class="n">string</code> <code class="n">name</code> <code class="o">=</code> <code class="mi">1</code><code class="o">;</code>
  <code class="n">int32</code> <code class="n">id</code> <code class="o">=</code> <code class="mi">2</code><code class="o">;</code>
  <code class="n">repeated</code> <code class="n">string</code> <code class="n">email</code> <code class="o">=</code> <code class="mi">3</code><code class="o">;</code>
<code class="o">}</code></pre>

<p>This definition says we are using the protobuf format version 3, and it specifies that each <code>Person</code> object<sup><a data-type="noteref" id="idm46263502886504-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#idm46263502886504" class="totri-footnote">7</a></sup> may (optionally) have a <code>name</code> of type <code>string</code>, an <code>id</code> of type <code>int32</code>, and zero or more <code>email</code> fields, each of type <code>string</code>. The numbers 1, 2, and 3 are the field identifiers: they will be used in each record’s binary representation. Once you have a definition in a <code>.proto</code> file, you can compile it. This requires <code>protoc</code>, the protobuf compiler, to generate access classes in Python (or some other language). Note that the protobuf definitions we will use have already been compiled for you, and their Python classes are part of TensorFlow, so you will not need to use <code>protoc</code>. All you need to know is how to use protobuf access classes in Python. To illustrate the basics, let’s look at a simple example that uses the access classes generated for the <code>Person</code> protobuf (the code is explained in the comments):</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="kn">from</code> <code class="nn">person_pb2</code> <code class="kn">import</code> <code class="n">Person</code>  <code class="c"># import the generated access class</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">person</code> <code class="o">=</code> <code class="n">Person</code><code class="p">(</code><code class="n">name</code><code class="o">=</code><code class="s">"Al"</code><code class="p">,</code> <code class="nb">id</code><code class="o">=</code><code class="mi">123</code><code class="p">,</code> <code class="n">email</code><code class="o">=</code><code class="p">[</code><code class="s">"a@b.com"</code><code class="p">])</code>  <code class="c"># create a Person</code>
<code class="gp">&gt;&gt;&gt; </code><code class="k">print</code><code class="p">(</code><code class="n">person</code><code class="p">)</code>  <code class="c"># display the Person</code>
<code class="go">name: "Al"</code>
<code class="go">id: 123</code>
<code class="go">email: "a@b.com"</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">person</code><code class="o">.</code><code class="n">name</code>  <code class="c"># read a field</code>
<code class="go">"Al"</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">person</code><code class="o">.</code><code class="n">name</code> <code class="o">=</code> <code class="s">"Alice"</code>  <code class="c"># modify a field</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">person</code><code class="o">.</code><code class="n">email</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code>  <code class="c"># repeated fields can be accessed like arrays</code>
<code class="go">"a@b.com"</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">person</code><code class="o">.</code><code class="n">email</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="s">"c@d.com"</code><code class="p">)</code>  <code class="c"># add an email address</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">s</code> <code class="o">=</code> <code class="n">person</code><code class="o">.</code><code class="n">SerializeToString</code><code class="p">()</code>  <code class="c"># serialize the object to a byte string</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">s</code>
<code class="go">b'\n\x05Alice\x10{\x1a\x07a@b.com\x1a\x07c@d.com'</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">person2</code> <code class="o">=</code> <code class="n">Person</code><code class="p">()</code>  <code class="c"># create a new Person</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">person2</code><code class="o">.</code><code class="n">ParseFromString</code><code class="p">(</code><code class="n">s</code><code class="p">)</code>  <code class="c"># parse the byte string (27 bytes long)</code>
<code class="go">27</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">person</code> <code class="o">==</code> <code class="n">person2</code>  <code class="c"># now they are equal</code>
<code class="go">True</code></pre>

<p>In short, we import the <code>Person</code> class generated by <code>protoc</code>, we create an instance and we play with it, visualizing it, reading and writing some fields, then we serialize it using the <code>SerializeToString()</code> method. This is the binary data that is ready to be saved or transmitted over the network. When reading or receiving this binary data, we can parse it using the <code>ParseFromString()</code> method, and we get a copy of the object that was serialized.<sup><a data-type="noteref" id="idm46263502758552-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#idm46263502758552" class="totri-footnote">8</a></sup></p>

<p>We could save the serialized <code>Person</code> object to a TFRecord file, then we could load and parse it: everything would work fine. However, <code>SerializeToString()</code> and <code>ParseFromString()</code> are not TensorFlow operations (and neither are the other operations in this code), so they cannot be included in a TensorFlow Function (except by wrapping them in a <code>tf.py_function()</code> operation, which would make the code slower and less portable, as we saw in <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#tensorflow_chapter">Chapter&nbsp;12</a>). Fortunately, TensorFlow does include special protobuf definitions for which it provides parsing operations.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="TensorFlow Protobufs"><div class="sect2" id="idm46263502753192">
<h2>TensorFlow Protobufs</h2>

<p>The main protobuf typically used in a TFRecord file is the <code>Example</code> protobuf, which represents one instance in a dataset. It contains a list of named features, where each feature can either be a list of byte strings, a list of floats, or a list of integers. Here is the protobuf definition:</p>

<pre data-type="programlisting" data-code-language="java"><code class="n">syntax</code> <code class="o">=</code> <code class="s">"proto3"</code><code class="o">;</code>
<code class="n">message</code> <code class="n">BytesList</code> <code class="o">{</code> <code class="n">repeated</code> <code class="n">bytes</code> <code class="n">value</code> <code class="o">=</code> <code class="mi">1</code><code class="o">;</code> <code class="o">}</code>
<code class="n">message</code> <code class="n">FloatList</code> <code class="o">{</code> <code class="n">repeated</code> <code class="kt">float</code> <code class="n">value</code> <code class="o">=</code> <code class="mi">1</code> <code class="o">[</code><code class="n">packed</code> <code class="o">=</code> <code class="kc">true</code><code class="o">];</code> <code class="o">}</code>
<code class="n">message</code> <code class="n">Int64List</code> <code class="o">{</code> <code class="n">repeated</code> <code class="n">int64</code> <code class="n">value</code> <code class="o">=</code> <code class="mi">1</code> <code class="o">[</code><code class="n">packed</code> <code class="o">=</code> <code class="kc">true</code><code class="o">];</code> <code class="o">}</code>
<code class="n">message</code> <code class="n">Feature</code> <code class="o">{</code>
    <code class="n">oneof</code> <code class="n">kind</code> <code class="o">{</code>
        <code class="n">BytesList</code> <code class="n">bytes_list</code> <code class="o">=</code> <code class="mi">1</code><code class="o">;</code>
        <code class="n">FloatList</code> <code class="n">float_list</code> <code class="o">=</code> <code class="mi">2</code><code class="o">;</code>
        <code class="n">Int64List</code> <code class="n">int64_list</code> <code class="o">=</code> <code class="mi">3</code><code class="o">;</code>
    <code class="o">}</code>
<code class="o">};</code>
<code class="n">message</code> <code class="n">Features</code> <code class="o">{</code> <code class="n">map</code><code class="o">&lt;</code><code class="n">string</code><code class="o">,</code> <code class="n">Feature</code><code class="o">&gt;</code> <code class="n">feature</code> <code class="o">=</code> <code class="mi">1</code><code class="o">;</code> <code class="o">};</code>
<code class="n">message</code> <code class="n">Example</code> <code class="o">{</code> <code class="n">Features</code> <code class="n">features</code> <code class="o">=</code> <code class="mi">1</code><code class="o">;</code> <code class="o">};</code></pre>

<p>The definitions of <code>BytesList</code>, <code>FloatList</code>, and <code>Int64List</code> are straightforward enough. Note that <code>[packed = true]</code> is used for repeated numerical fields, for a more efficient <span class="keep-together">encoding. A</span> <code>Feature</code> either contains a <code>BytesList</code>, a <code>FloatList</code> or an <code>Int64List</code>. A <code>Features</code> (with an <em>s</em>) contains a dictionary that maps a feature name to the corresponding feature value. And finally, an <code>Example</code> contains only a <code>Features</code> object.<sup><a data-type="noteref" id="idm46263502621576-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#idm46263502621576" class="totri-footnote">9</a></sup> Here is how you could create a <code>tf.train.Example</code> representing the same person as earlier and write it to a TFRecord file:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">tensorflow.train</code> <code class="kn">import</code> <code class="n">BytesList</code><code class="p">,</code> <code class="n">FloatList</code><code class="p">,</code> <code class="n">Int64List</code>
<code class="kn">from</code> <code class="nn">tensorflow.train</code> <code class="kn">import</code> <code class="n">Feature</code><code class="p">,</code> <code class="n">Features</code><code class="p">,</code> <code class="n">Example</code>

<code class="n">person_example</code> <code class="o">=</code> <code class="n">Example</code><code class="p">(</code>
    <code class="n">features</code><code class="o">=</code><code class="n">Features</code><code class="p">(</code>
        <code class="n">feature</code><code class="o">=</code><code class="p">{</code>
            <code class="s2">"name"</code><code class="p">:</code> <code class="n">Feature</code><code class="p">(</code><code class="n">bytes_list</code><code class="o">=</code><code class="n">BytesList</code><code class="p">(</code><code class="n">value</code><code class="o">=</code><code class="p">[</code><code class="s-Affix">b</code><code class="s2">"Alice"</code><code class="p">])),</code>
            <code class="s2">"id"</code><code class="p">:</code> <code class="n">Feature</code><code class="p">(</code><code class="n">int64_list</code><code class="o">=</code><code class="n">Int64List</code><code class="p">(</code><code class="n">value</code><code class="o">=</code><code class="p">[</code><code class="mi">123</code><code class="p">])),</code>
            <code class="s2">"emails"</code><code class="p">:</code> <code class="n">Feature</code><code class="p">(</code><code class="n">bytes_list</code><code class="o">=</code><code class="n">BytesList</code><code class="p">(</code><code class="n">value</code><code class="o">=</code><code class="p">[</code><code class="s-Affix">b</code><code class="s2">"a@b.com"</code><code class="p">,</code>
                                                          <code class="s-Affix">b</code><code class="s2">"c@d.com"</code><code class="p">]))</code>
        <code class="p">}))</code></pre>

<p>The code is a bit verbose and repetitive, but it’s rather straightforward (and you could easily wrap it inside a small helper function). Now that we have an <code>Example</code> protobuf, we can serialize it by calling its <code>SerializeToString()</code> method, then write the resulting data to a TFRecord file:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">io</code><code class="o">.</code><code class="n">TFRecordWriter</code><code class="p">(</code><code class="s2">"my_contacts.tfrecord"</code><code class="p">)</code> <code class="k">as</code> <code class="n">f</code><code class="p">:</code>
    <code class="n">f</code><code class="o">.</code><code class="n">write</code><code class="p">(</code><code class="n">person_example</code><code class="o">.</code><code class="n">SerializeToString</code><code class="p">())</code></pre>

<p>Normally you would write much more than one example! Typically, you would create a conversion script that reads from your current format (say, CSV files), creates an <code>Example</code> protobuf for each instance, serializes them, and saves them to several TFRecord files, ideally shuffling them in the process. This requires a bit of work, so once again make sure it is really necessary (perhaps your pipeline works fine with CSV files).</p>

<p>Now that we have a nice TFRecord file containing a serialized <code>Example</code>, let’s try to load it.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Loading and Parsing Examples"><div class="sect2" id="idm46263502460856">
<h2>Loading and Parsing Examples</h2>

<p>To load the serialized <code>Example</code> protobufs, we will use a <code>tf.data.TFRecordDataset</code> once again, and we will parse each <code>Example</code> using <code>tf.io.parse_single_example()</code>. This is a TensorFlow operation, so it can be included in a TF Function. It requires at least two arguments: a string scalar tensor containing the serialized data, and a description of each feature. The description is a dictionary that maps each feature name to either a <code>tf.io.FixedLenFeature</code> descriptor indicating the feature’s shape, type, and default value, or a <code>tf.io.VarLenFeature</code> descriptor indicating only the type (if the length of the feature’s list may vary, such as for the <code>"emails"</code> feature). The following code defines a description dictionary, then it iterates over the TFRecordDataset and parses the serialized Example protobuf this dataset contains:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">feature_description</code> <code class="o">=</code> <code class="p">{</code>
    <code class="s2">"name"</code><code class="p">:</code> <code class="n">tf</code><code class="o">.</code><code class="n">io</code><code class="o">.</code><code class="n">FixedLenFeature</code><code class="p">([],</code> <code class="n">tf</code><code class="o">.</code><code class="n">string</code><code class="p">,</code> <code class="n">default_value</code><code class="o">=</code><code class="s2">""</code><code class="p">),</code>
    <code class="s2">"id"</code><code class="p">:</code> <code class="n">tf</code><code class="o">.</code><code class="n">io</code><code class="o">.</code><code class="n">FixedLenFeature</code><code class="p">([],</code> <code class="n">tf</code><code class="o">.</code><code class="n">int64</code><code class="p">,</code> <code class="n">default_value</code><code class="o">=</code><code class="mi">0</code><code class="p">),</code>
    <code class="s2">"emails"</code><code class="p">:</code> <code class="n">tf</code><code class="o">.</code><code class="n">io</code><code class="o">.</code><code class="n">VarLenFeature</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">string</code><code class="p">),</code>
<code class="p">}</code>

<code class="k">for</code> <code class="n">serialized_example</code> <code class="ow">in</code> <code class="n">tf</code><code class="o">.</code><code class="n">data</code><code class="o">.</code><code class="n">TFRecordDataset</code><code class="p">([</code><code class="s2">"my_contacts.tfrecord"</code><code class="p">]):</code>
    <code class="n">parsed_example</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">io</code><code class="o">.</code><code class="n">parse_single_example</code><code class="p">(</code><code class="n">serialized_example</code><code class="p">,</code>
                                                <code class="n">feature_description</code><code class="p">)</code></pre>

<p>The fixed length features are parsed as regular tensors, but the variable length features are parsed as sparse tensors. You can convert a sparse tensor to a dense tensor using <code>tf.sparse.to_dense()</code>, but in this case it is simpler to just access its values:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">tf</code><code class="o">.</code><code class="n">sparse</code><code class="o">.</code><code class="n">to_dense</code><code class="p">(</code><code class="n">parsed_example</code><code class="p">[</code><code class="s">"emails"</code><code class="p">],</code> <code class="n">default_value</code><code class="o">=</code><code class="n">b</code><code class="s">""</code><code class="p">)</code>
<code class="go">&lt;tf.Tensor: [...] dtype=string, numpy=array([b'a@b.com', b'c@d.com'], [...])&gt;</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">parsed_example</code><code class="p">[</code><code class="s">"emails"</code><code class="p">]</code><code class="o">.</code><code class="n">values</code>
<code class="go">&lt;tf.Tensor: [...] dtype=string, numpy=array([b'a@b.com', b'c@d.com'], [...])&gt;</code></pre>

<p>A <code>BytesList</code> can contain any binary data you want, including any serialized object. For example, you can use <code>tf.io.encode_jpeg()</code> to encode an image using the JPEG format and put this binary data in a <code>BytesList</code>. Later, when your code reads the TFRecord, it will start by parsing the <code>Example</code>, then it will need to call <code>tf.io.decode_jpeg()</code> to parse the data and get the original image (or you can use <code>tf.io.decode_image()</code>, which can decode any BMP, GIF, JPEG, or PNG image). You can also store any tensor you want in a <code>BytesList</code> by serializing the tensor using <code>tf.io.serialize_tensor()</code> then putting the resulting byte string in a <code>BytesList</code> feature. Later, when you parse the TFRecord, you can parse this data using <code>tf.io.parse_tensor()</code>.</p>

<p>Instead of parsing examples one by one using <code>tf.io.parse_single_example()</code>, you may want to parse them batch by batch using <code>tf.io.parse_example()</code>:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">dataset</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">data</code><code class="o">.</code><code class="n">TFRecordDataset</code><code class="p">([</code><code class="s2">"my_contacts.tfrecord"</code><code class="p">])</code><code class="o">.</code><code class="n">batch</code><code class="p">(</code><code class="mi">10</code><code class="p">)</code>
<code class="k">for</code> <code class="n">serialized_examples</code> <code class="ow">in</code> <code class="n">dataset</code><code class="p">:</code>
    <code class="n">parsed_examples</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">io</code><code class="o">.</code><code class="n">parse_example</code><code class="p">(</code><code class="n">serialized_examples</code><code class="p">,</code>
                                          <code class="n">feature_description</code><code class="p">)</code></pre>

<p>As you can see, the <code>Example</code> proto will probably be sufficient for most use cases. However, it may be a bit cumbersome to use when you are dealing with lists of lists. For example, suppose you want to classify text documents. Each document may be represented as a list of sentences, where each sentence is represented as a list of words. And perhaps each document also has a list of comments, where each comment is represented as a list of words. Moreover, there may be some contextual data as well, such as the document’s author, title, and publication date. TensorFlow’s <code>SequenceExample</code> protobuf is designed for such use cases.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Handling Lists of Lists Using the SequenceExample Protobuf"><div class="sect2" id="idm46263502190808">
<h2>Handling Lists of Lists Using the SequenceExample Protobuf</h2>

<p>Here is the definition of the <code>SequenceExample</code> protobuf:</p>

<pre data-type="programlisting" data-code-language="java"><code class="n">message</code> <code class="n">FeatureList</code> <code class="o">{</code> <code class="n">repeated</code> <code class="n">Feature</code> <code class="n">feature</code> <code class="o">=</code> <code class="mi">1</code><code class="o">;</code> <code class="o">};</code>
<code class="n">message</code> <code class="n">FeatureLists</code> <code class="o">{</code> <code class="n">map</code><code class="o">&lt;</code><code class="n">string</code><code class="o">,</code> <code class="n">FeatureList</code><code class="o">&gt;</code> <code class="n">feature_list</code> <code class="o">=</code> <code class="mi">1</code><code class="o">;</code> <code class="o">};</code>
<code class="n">message</code> <code class="n">SequenceExample</code> <code class="o">{</code>
    <code class="n">Features</code> <code class="n">context</code> <code class="o">=</code> <code class="mi">1</code><code class="o">;</code>
    <code class="n">FeatureLists</code> <code class="n">feature_lists</code> <code class="o">=</code> <code class="mi">2</code><code class="o">;</code>
<code class="o">};</code></pre>

<p>A <code>SequenceExample</code> contains a <code>Features</code> object for the contextual data and a <code>FeatureLists</code> object, which contains one or more named <code>FeatureList</code> objects (e.g., a <code>FeatureList</code> named <code>"content"</code> and another named <code>"comments"</code>). Each <code>FeatureList</code> contains a list of <code>Feature</code> objects, each of which may be a list of byte strings, a list of 64-bit integers, or a list of floats (in this example, each <code>Feature</code> would represent a sentence or a comment, perhaps in the form of a list of word identifiers). Building a <code>SequenceExample</code>, serializing it, and parsing it is very similar to building, serializing, and parsing an <code>Example</code>, but you must use <code>tf.io.parse_single_sequence_example()</code> to parse a single <code>SequenceExample</code> or <code>tf.io.parse_sequence_example()</code> to parse a batch, and both functions return a tuple containing the context features (as a dictionary) and the feature lists (also as a dictionary). If the feature lists contain sequences of varying sizes (as in the preceding example), you may want to convert them to ragged tensors, using <code>tf.RaggedTensor.from_sparse()</code> (see the notebook for the full code):</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">parsed_context</code><code class="p">,</code> <code class="n">parsed_feature_lists</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">io</code><code class="o">.</code><code class="n">parse_single_sequence_example</code><code class="p">(</code>
    <code class="n">serialized_sequence_example</code><code class="p">,</code> <code class="n">context_feature_descriptions</code><code class="p">,</code>
    <code class="n">sequence_feature_descriptions</code><code class="p">)</code>
<code class="n">parsed_content</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">RaggedTensor</code><code class="o">.</code><code class="n">from_sparse</code><code class="p">(</code><code class="n">parsed_feature_lists</code><code class="p">[</code><code class="s2">"content"</code><code class="p">])</code></pre>

<p>Now that you know how to efficiently store, load, and parse data, the next step is to prepare it so that it can be fed to a neural network.</p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Preprocessing the Input Features"><div class="sect1" id="idm46263503198520">
<h1>Preprocessing the Input Features</h1>

<p>Preparing your data for a neural network requires converting all features into numerical features, generally normalizing them, and more. In particular, if your data contains categorical features or text features, they need to be converted to numbers. This can be done ahead of time when preparing your data files, using any tool you like (e.g., NumPy, Pandas, and Scikit-Learn). Or you can preprocess your data on the fly when loading it with the Data API (e.g., using the dataset’s <code>map()</code> method, as we saw earlier). Or you can include a preprocessing layer directly in your model. Let’s look at this last option now.</p>

<p>For example, here is how you can implement a standardization layer using a <code>Lambda</code> layer. For each feature, it subtracts the mean and divides by its standard deviation (plus a tiny smoothing term to avoid division by zero):</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">means</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">mean</code><code class="p">(</code><code class="n">X_train</code><code class="p">,</code> <code class="n">axis</code><code class="o">=</code><code class="mi">0</code><code class="p">,</code> <code class="n">keepdims</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>
<code class="n">stds</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">std</code><code class="p">(</code><code class="n">X_train</code><code class="p">,</code> <code class="n">axis</code><code class="o">=</code><code class="mi">0</code><code class="p">,</code> <code class="n">keepdims</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>
<code class="n">eps</code> <code class="o">=</code> <code class="n">keras</code><code class="o">.</code><code class="n">backend</code><code class="o">.</code><code class="n">epsilon</code><code class="p">()</code>
<code class="n">model</code> <code class="o">=</code> <code class="n">keras</code><code class="o">.</code><code class="n">models</code><code class="o">.</code><code class="n">Sequential</code><code class="p">([</code>
    <code class="n">keras</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">Lambda</code><code class="p">(</code><code class="k">lambda</code> <code class="n">inputs</code><code class="p">:</code> <code class="p">(</code><code class="n">inputs</code> <code class="o">-</code> <code class="n">means</code><code class="p">)</code> <code class="o">/</code> <code class="p">(</code><code class="n">stds</code> <code class="o">+</code> <code class="n">eps</code><code class="p">)),</code>
    <code class="p">[</code><code class="o">...</code><code class="p">]</code> <code class="c1"># other layers</code>
<code class="p">])</code></pre>

<p>That’s not too hard! However, you may prefer to use a nice self-contained custom layer (much like Scikit-Learn’s <code>StandardScaler</code>), rather than having global variables like <code>means</code> and <code>stds</code> dangling around:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">class</code> <code class="nc">Standardization</code><code class="p">(</code><code class="n">keras</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">Layer</code><code class="p">):</code>
    <code class="k">def</code> <code class="nf">adapt</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">data_sample</code><code class="p">):</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">means_</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">mean</code><code class="p">(</code><code class="n">data_sample</code><code class="p">,</code> <code class="n">axis</code><code class="o">=</code><code class="mi">0</code><code class="p">,</code> <code class="n">keepdims</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">stds_</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">std</code><code class="p">(</code><code class="n">data_sample</code><code class="p">,</code> <code class="n">axis</code><code class="o">=</code><code class="mi">0</code><code class="p">,</code> <code class="n">keepdims</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>
    <code class="k">def</code> <code class="nf">call</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">inputs</code><code class="p">):</code>
        <code class="k">return</code> <code class="p">(</code><code class="n">inputs</code> <code class="o">-</code> <code class="bp">self</code><code class="o">.</code><code class="n">means_</code><code class="p">)</code> <code class="o">/</code> <code class="p">(</code><code class="bp">self</code><code class="o">.</code><code class="n">stds_</code> <code class="o">+</code> <code class="n">keras</code><code class="o">.</code><code class="n">backend</code><code class="o">.</code><code class="n">epsilon</code><code class="p">())</code></pre>

<p>Before you can use this standardization layer, you will need to adapt it to your dataset by calling the <code>adapt()</code> method and passing it a data sample. This will allow it to use the appropriate mean and standard deviation for each feature:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">std_layer</code> <code class="o">=</code> <code class="n">Standardization</code><code class="p">()</code>
<code class="n">std_layer</code><code class="o">.</code><code class="n">adapt</code><code class="p">(</code><code class="n">data_sample</code><code class="p">)</code></pre>

<p>This sample must be large enough to be representative of your dataset, but it does not have to be the full training set: in general, a few hundred randomly selected instances will suffice (however, this depends on your task). Next, you can use this preprocessing layer like a normal layer:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">model</code> <code class="o">=</code> <code class="n">keras</code><code class="o">.</code><code class="n">Sequential</code><code class="p">()</code>
<code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">std_layer</code><code class="p">)</code>
<code class="p">[</code><code class="o">...</code><code class="p">]</code> <code class="c1"># create the rest of the model</code>
<code class="n">model</code><code class="o">.</code><code class="n">compile</code><code class="p">([</code><code class="o">...</code><code class="p">])</code>
<code class="n">model</code><code class="o">.</code><code class="n">fit</code><code class="p">([</code><code class="o">...</code><code class="p">])</code></pre>

<p>If you are thinking that Keras should contain a standardization layer like this one, the good news is that it soon will (by the time you read this, it may already exist): it will be called <code>keras.layers.Normalization</code>. It should work very much like our custom <code>Standardization</code> layer: first create the layer, then adapt it to your dataset by passing a data sample to the <code>adapt()</code> method, and finally use the layer normally. It will be part of a set of new Keras preprocessing layers which will all have a similar API, with an the <code>adapt()</code> method (we will discuss these later in this chapter). Now let’s look at categorical features. We will start by encoding them as one-hot vectors.</p>








<section data-type="sect2" data-pdf-bookmark="Encoding Categorical Features Using One-Hot Vectors"><div class="sect2" id="idm46263501797544">
<h2>Encoding Categorical Features Using One-Hot Vectors</h2>

<p>Consider the <code>ocean_proximity</code> feature in the California housing dataset we explored in <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch02.html#project_chapter">Chapter&nbsp;2</a>: it is a categorical feature with five possible values: <code>"&lt;1H OCEAN"</code>, <code>"INLAND"</code>, <code>"NEAR OCEAN"</code>, <code>"NEAR BAY"</code>, and <code>"ISLAND"</code>. We need to encode this feature before we feed it to a neural network. Since there are very few categories, we can use one-hot encoding. For this, we first need to map each category to its index (0 to 4), which can be done using a lookup table:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">vocab</code> <code class="o">=</code> <code class="p">[</code><code class="s2">"&lt;1H OCEAN"</code><code class="p">,</code> <code class="s2">"INLAND"</code><code class="p">,</code> <code class="s2">"NEAR OCEAN"</code><code class="p">,</code> <code class="s2">"NEAR BAY"</code><code class="p">,</code> <code class="s2">"ISLAND"</code><code class="p">]</code>
<code class="n">indices</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">range</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">vocab</code><code class="p">),</code> <code class="n">dtype</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">int64</code><code class="p">)</code>
<code class="n">table_init</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">lookup</code><code class="o">.</code><code class="n">KeyValueTensorInitializer</code><code class="p">(</code><code class="n">vocab</code><code class="p">,</code> <code class="n">indices</code><code class="p">)</code>
<code class="n">num_oov_buckets</code> <code class="o">=</code> <code class="mi">2</code>
<code class="n">table</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">lookup</code><code class="o">.</code><code class="n">StaticVocabularyTable</code><code class="p">(</code><code class="n">table_init</code><code class="p">,</code> <code class="n">num_oov_buckets</code><code class="p">)</code></pre>

<p>Let’s go through this code:</p>

<ul>
<li>
<p>We first define the <em>vocabulary</em>: this is the list of all possible categories.</p>
</li>
<li>
<p>Then we create a tensor with the corresponding indices (0 to 4).</p>
</li>
<li>
<p>Next, we create an initializer for the lookup table, passing it the list of categories and their corresponding indices. In this example, we already have this data, so we use a <code>KeyValueTensorInitializer</code>; but if the categories were listed in a text file (with one category per line), we would use a <code>TextFileInitializer</code> instead.</p>
</li>
<li>
<p>On the last two lines, we create the lookup table, giving it the initializer and specifying the number of <em>out-of-vocabulary</em> (oov) buckets. If we lookup a category that does not exist in the vocabulary, the lookup table will compute a hash of this category and use it to assign the unknown category to one of the oov buckets. Their indices start after the known categories, so in this example the indices of the two oov buckets are 5 and 6.</p>
</li>
</ul>

<p>Why use oov buckets? Well, if the number of categories is large (e.g., zip codes, cities, words, products, or users) and the dataset is large as well, or it keeps changing, then getting the full list of categories may not be convenient. One solution is to define the vocabulary based on a data sample (rather than the whole training set) and add some oov buckets for the other categories that were not in the data sample. The more unknown categories you expect to find during training, the more oov buckets you should use. Indeed, if there are not enough oov buckets, there will be collisions: different categories will end up in the same bucket, so the neural network will not be able to distinguish them (at least not based on this feature).</p>

<p>Now let’s use the lookup table to encode a small batch of categorical features to one-hot vectors:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">categories</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">constant</code><code class="p">([</code><code class="s">"NEAR BAY"</code><code class="p">,</code> <code class="s">"DESERT"</code><code class="p">,</code> <code class="s">"INLAND"</code><code class="p">,</code> <code class="s">"INLAND"</code><code class="p">])</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">cat_indices</code> <code class="o">=</code> <code class="n">table</code><code class="o">.</code><code class="n">lookup</code><code class="p">(</code><code class="n">categories</code><code class="p">)</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">cat_indices</code>
<code class="go">&lt;tf.Tensor: id=514, shape=(4,), dtype=int64, numpy=array([3, 5, 1, 1])&gt;</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">cat_one_hot</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">one_hot</code><code class="p">(</code><code class="n">cat_indices</code><code class="p">,</code> <code class="n">depth</code><code class="o">=</code><code class="nb">len</code><code class="p">(</code><code class="n">vocab</code><code class="p">)</code> <code class="o">+</code> <code class="n">num_oov_buckets</code><code class="p">)</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">cat_one_hot</code>
<code class="go">&lt;tf.Tensor: id=524, shape=(4, 7), dtype=float32, numpy=</code>
<code class="go">array([[0., 0., 0., 1., 0., 0., 0.],</code>
<code class="go">       [0., 0., 0., 0., 0., 1., 0.],</code>
<code class="go">       [0., 1., 0., 0., 0., 0., 0.],</code>
<code class="go">       [0., 1., 0., 0., 0., 0., 0.]], dtype=float32)&gt;</code></pre>

<p>As you can see, <code>"NEAR BAY"</code> was mapped to index 3, the unknown category <code>"DESERT"</code> was mapped to one of the two oov buckets, at index 5, and <code>"INLAND"</code> was mapped to index 1, twice. Then we used <code>tf.one_hot()</code> to one-hot encode these indices. Notice that we have to tell this function the total number of indices, which is equal to the vocabulary size plus the number of oov buckets. Now you know how to encode categorical features to one-hot vectors using TensorFlow!</p>

<p>Just like earlier, it wouldn’t be too difficult to bundle all of this logic into a nice self-contained class. Its <code>adapt()</code> method would take a data sample and extract all the distinct categories it contains. It would create a lookup table to map each category to its index (including unknown categories using oov buckets). Then its <code>call()</code> method would use the lookup table to map the input categories to their indices. However, by the time you read this, the Keras preprocessing layers may already be available, and they will include a <code>keras.layers.TextVectorization</code> layer that will be capable of doing exactly that: its <code>adapt()</code> method will extract the vocabulary from a data sample, and its <code>call()</code> method will convert each category to its index in the vocabulary. You could add this layer at the beginning of your model, followed by a <code>Lambda</code> layer that would apply the <code>tf.one_hot()</code> function, if you want to convert these indices to one-hot vectors.</p>

<p>However, each one-hot vector has the size of the vocabulary length plus the number of oov buckets. This is fine when there are just a few possible categories, but if the vocabulary is large, it is much more efficient to encode them using <em>embeddings</em> instead.</p>
<div data-type="tip"><h6>Tip</h6>
<p>As a rule of thumb, if the number of categories is lower than 10, then one-hot encoding is generally the way to go (but your mileage may vary!). If the number of categories is greater than 50 (which is often the case when you use hash buckets), then embeddings are usually preferable. In between 10 and 50 categories, you may want to experiment with both options and see which one works best for your use case.</p>
</div>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Encoding Categorical Features Using Embeddings"><div class="sect2" id="idm46263501796952">
<h2>Encoding Categorical Features Using Embeddings</h2>

<p>An embedding is a trainable dense vector that represents a category. By default, embeddings are initialized randomly, so for example the <code>"NEAR BAY"</code> category could be represented initially by a random vector such as <code>[0.131, 0.890]</code>, while the <code>"NEAR OCEAN"</code> category may be represented by another random vector such as <code>[0.631, 0.791]</code>. In this example, we use 2D embeddings, but the number of dimensions is a hyperparameter you can tweak. Since these embeddings are trainable, they will gradually improve during training; and as they represent fairly similar categories, Gradient Descent will certainly end up pushing them closer together, while it will tend to move them away from the <code>"INLAND"</code> category’s embedding (see <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#embedding_diagram">Figure&nbsp;13-4</a>). Indeed, the better the representation, the easier it will be for the neural network to make accurate predictions, so training tends to make embeddings useful representations of the categories. This is called <em>representation learning</em> (we will see other types of representation learning in <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch17.html#autoencoders_chapter">Chapter&nbsp;17</a>).</p>

<figure><div id="embedding_diagram" class="figure">
<img src="./Chapter13_files/mls2_1304.png" alt="mls2 1304" width="1440" height="713" data-mfp-src="/library/view/hands-on-machine-learning/9781492032632/assets/mls2_1304.png">
<h6><span class="label">Figure 13-4. </span>Embeddings will gradually improve during training</h6>
</div></figure>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46263501537336">
<h5>Word Embeddings</h5>
<p>Not only will embeddings generally be useful representations for the task at hand, but quite often these same embeddings can be reused successfully for other tasks. The most common example of this is <em>word embeddings</em> (i.e., embeddings of individual words): when you are working on a natural language processing task, you are often better off reusing pretrained word embeddings than training your own.</p>

<p>The idea of using vectors to represent words dates back to the 1960s, and many sophisticated techniques have been used to generate useful vectors, including using neural networks, but things really took off in 2013, when Tomáš Mikolov and other Google researchers published a <a href="https://homl.info/word2vec">paper</a><sup><a data-type="noteref" id="idm46263501533640-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#idm46263501533640">10</a></sup> describing an efficient technique to learn word embeddings using neural networks, significantly outperforming previous attempts. This allowed them to learn embeddings on a very large corpus of text: they trained a neural network to predict the words near any given word. They obtained astounding word embeddings. For example, synonyms had very close embeddings, and semantically related words such as France, Spain, and Italy ended up clustered together.</p>

<p>But it’s not just about proximity: word embeddings were also organized along meaningful axes in the embedding space. Here is a famous example: if you compute King – Man + Woman (adding and subtracting the embedding vectors of these words), then the result will be very close to the embedding of the word Queen (see <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#word_embedding_diagram">Figure&nbsp;13-5</a>). In other words, the word embeddings encode the concept of gender! Similarly, you can compute Madrid – Spain + France, and the result is close to Paris, which seems to show that the notion of capital city was also encoded in the embeddings.</p>

<figure><div id="word_embedding_diagram" class="figure">
<img src="./Chapter13_files/mls2_1305.png" alt="mls2 1305" width="1288" height="798" data-mfp-src="/library/view/hands-on-machine-learning/9781492032632/assets/mls2_1305.png">
<h6><span class="label">Figure 13-5. </span>Word embeddings of similar words tend to be close, and some axes seem to encode meaningful concepts</h6>
</div></figure>

<p>Unfortunately, word embeddings sometimes capture our worst biases. For example, although they correctly learn that Man is to King as Woman is to Queen, they also seem to learn that Man is to Doctor as Woman is to Nurse: quite a sexist bias! To be fair, this particular example is probably exaggerated, as was pointed out in a <a href="https://homl.info/fairembeds">2019 paper</a><sup><a data-type="noteref" id="idm46263501526680-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#idm46263501526680">11</a></sup> by M. Nissim et al. Nevertheless, ensuring fairness in Deep Learning algorithms is an important and active research topic.</p>
</div></aside>

<p>Let’s look at how we could implement embeddings manually, to understand how they work (then we will use a simple Keras layer instead). First, we need to create an <em>embedding matrix</em> containing each category’s embedding, initialized randomly: it will have one row per category and per oov bucket, and one column per embedding dimension.</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">embedding_dim</code> <code class="o">=</code> <code class="mi">2</code>
<code class="n">embed_init</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">uniform</code><code class="p">([</code><code class="nb">len</code><code class="p">(</code><code class="n">vocab</code><code class="p">)</code> <code class="o">+</code> <code class="n">num_oov_buckets</code><code class="p">,</code> <code class="n">embedding_dim</code><code class="p">])</code>
<code class="n">embedding_matrix</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">Variable</code><code class="p">(</code><code class="n">embed_init</code><code class="p">)</code></pre>

<p>In this example we are using 2D embeddings, but as a rule of thumb embeddings typically have 10 to 300 dimensions, depending on the task and the vocabulary size (you will have to tune this hyperparameter).</p>

<p>This embedding matrix is a random 6 × 2 matrix, stored in a variable (so it can be tweaked by Gradient Descent during training):</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">embedding_matrix</code>
<code class="go">&lt;tf.Variable 'Variable:0' shape=(6, 2) dtype=float32, numpy=</code>
<code class="go">array([[0.6645621 , 0.44100678],</code>
<code class="go">       [0.3528825 , 0.46448255],</code>
<code class="go">       [0.03366041, 0.68467236],</code>
<code class="go">       [0.74011743, 0.8724445 ],</code>
<code class="go">       [0.22632635, 0.22319686],</code>
<code class="go">       [0.3103881 , 0.7223358 ]], dtype=float32)&gt;</code></pre>

<p>Now let’s encode the same batch of categorical features as earlier, but this time using these embeddings:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">categories</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">constant</code><code class="p">([</code><code class="s">"NEAR BAY"</code><code class="p">,</code> <code class="s">"DESERT"</code><code class="p">,</code> <code class="s">"INLAND"</code><code class="p">,</code> <code class="s">"INLAND"</code><code class="p">])</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">cat_indices</code> <code class="o">=</code> <code class="n">table</code><code class="o">.</code><code class="n">lookup</code><code class="p">(</code><code class="n">categories</code><code class="p">)</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">cat_indices</code>
<code class="go">&lt;tf.Tensor: id=741, shape=(4,), dtype=int64, numpy=array([3, 5, 1, 1])&gt;</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">tf</code><code class="o">.</code><code class="n">nn</code><code class="o">.</code><code class="n">embedding_lookup</code><code class="p">(</code><code class="n">embedding_matrix</code><code class="p">,</code> <code class="n">cat_indices</code><code class="p">)</code>
<code class="go">&lt;tf.Tensor: id=864, shape=(4, 2), dtype=float32, numpy=</code>
<code class="go">array([[0.74011743, 0.8724445 ],</code>
<code class="go">       [0.3103881 , 0.7223358 ],</code>
<code class="go">       [0.3528825 , 0.46448255],</code>
<code class="go">       [0.3528825 , 0.46448255]], dtype=float32)&gt;</code></pre>

<p>The <code>tf.nn.embedding_lookup()</code> function looks up the rows in the embedding matrix, at the given indices—that’s all it does. For example, the lookup table says that the <code>"INLAND"</code> category is at index 1, so the <code>tf.nn.embedding_lookup()</code> function returns the embedding at row 1 in the embedding matrix (twice): <code>[0.3528825, 0.46448255]</code>.</p>

<p>Keras provides a <code>keras.layers.Embedding</code> layer that handles the embedding matrix (trainable, by default): when the layer is created, it initializes the embedding matrix randomly; and then when it is called with some category indices, it returns the rows at those indices in the embedding matrix:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">embedding</code> <code class="o">=</code> <code class="n">keras</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">Embedding</code><code class="p">(</code><code class="n">input_dim</code><code class="o">=</code><code class="nb">len</code><code class="p">(</code><code class="n">vocab</code><code class="p">)</code> <code class="o">+</code> <code class="n">num_oov_buckets</code><code class="p">,</code>
<code class="gp">... </code>                                   <code class="n">output_dim</code><code class="o">=</code><code class="n">embedding_dim</code><code class="p">)</code>
<code class="gp">...</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">embedding</code><code class="p">(</code><code class="n">cat_indices</code><code class="p">)</code>
<code class="go">&lt;tf.Tensor: id=814, shape=(4, 2), dtype=float32, numpy=</code>
<code class="go">array([[ 0.02401174,  0.03724445],</code>
<code class="go">       [-0.01896119,  0.02223358],</code>
<code class="go">       [-0.01471175, -0.00355174],</code>
<code class="go">       [-0.01471175, -0.00355174]], dtype=float32)&gt;</code></pre>

<p>Putting everything together, we can now create a Keras model that can process categorical features (along with regular numerical features) and learn an embedding for each category (as well as for each oov bucket):</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">regular_inputs</code> <code class="o">=</code> <code class="n">keras</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">Input</code><code class="p">(</code><code class="n">shape</code><code class="o">=</code><code class="p">[</code><code class="mi">8</code><code class="p">])</code>
<code class="n">categories</code> <code class="o">=</code> <code class="n">keras</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">Input</code><code class="p">(</code><code class="n">shape</code><code class="o">=</code><code class="p">[],</code> <code class="n">dtype</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">string</code><code class="p">)</code>
<code class="n">cat_indices</code> <code class="o">=</code> <code class="n">keras</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">Lambda</code><code class="p">(</code><code class="k">lambda</code> <code class="n">cats</code><code class="p">:</code> <code class="n">table</code><code class="o">.</code><code class="n">lookup</code><code class="p">(</code><code class="n">cats</code><code class="p">))(</code><code class="n">categories</code><code class="p">)</code>
<code class="n">cat_embed</code> <code class="o">=</code> <code class="n">keras</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">Embedding</code><code class="p">(</code><code class="n">input_dim</code><code class="o">=</code><code class="mi">6</code><code class="p">,</code> <code class="n">output_dim</code><code class="o">=</code><code class="mi">2</code><code class="p">)(</code><code class="n">cat_indices</code><code class="p">)</code>
<code class="n">encoded_inputs</code> <code class="o">=</code> <code class="n">keras</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">concatenate</code><code class="p">([</code><code class="n">regular_inputs</code><code class="p">,</code> <code class="n">cat_embed</code><code class="p">])</code>
<code class="n">outputs</code> <code class="o">=</code> <code class="n">keras</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">Dense</code><code class="p">(</code><code class="mi">1</code><code class="p">)(</code><code class="n">encoded_inputs</code><code class="p">)</code>
<code class="n">model</code> <code class="o">=</code> <code class="n">keras</code><code class="o">.</code><code class="n">models</code><code class="o">.</code><code class="n">Model</code><code class="p">(</code><code class="n">inputs</code><code class="o">=</code><code class="p">[</code><code class="n">regular_inputs</code><code class="p">,</code> <code class="n">categories</code><code class="p">],</code>
                           <code class="n">outputs</code><code class="o">=</code><code class="p">[</code><code class="n">outputs</code><code class="p">])</code></pre>

<p>This model takes two inputs: a regular input containing eight numerical features per instance, plus a categorical input (containing one categorical feature per instance). It uses a <code>Lambda</code> layer to look up each category’s index, then it looks up the embeddings for these indices. Next, it concatenates the embeddings and the regular inputs in order to give the encoded inputs, which are ready to be fed to a neural network. We could add any kind of neural network at this point, but we just add a dense output layer, and we create the Keras model.</p>

<p>When the <code>keras.layers.TextVectorization</code> layer is available, you can call its <code>adapt()</code> method to make it extract the vocabulary from a data sample (it will take care of creating the lookup table for you). Then you can add it to your model, and it will perform the index lookup (replacing the <code>Lambda</code> layer in the previous code example).</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>One-hot encoding followed by a dense layer (with no activation function and no biases) is equivalent to an embedding layer. However, the embedding layer uses way fewer computations (the performance difference becomes clear when the size of the embedding matrix grows). The dense layer’s weight matrix plays the role of the embedding matrix. For example, using one-hot vectors of size 20 and a dense layer with 10 units is equivalent to using an embedding layer with <code>input_dim=20</code> and <code>output_dim=10</code>. As a result, it would be wasteful to use more embedding dimensions than the number of units in the layer that follows the embedding layer.</p>
</div>

<p>Now let’s look a bit more closely at the Keras preprocessing layers.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Keras Preprocessing Layers"><div class="sect2" id="idm46263501545576">
<h2>Keras Preprocessing Layers</h2>

<p>As we discussed, the TensorFlow team is working on providing a set of standard Keras preprocessing layers (they may already be available when you read this; however, the API may change slightly by then, so please refer to the notebook for this chapter if anything behaves unexpectedly). This new API will likely supersede the existing Feature Columns API, which is harder to use and less intuitive (but if you want to learn more about the Feature Columns API, please check out the notebook for this chapter).</p>

<p>We already discussed two of these layers: the <code>keras.layers.Normalization</code> layer that will perform feature standardization (it will be equivalent to the <code>Standardization</code> layer we defined earlier), and the <code>TextVectorization</code> layer that will be capable of encoding each word in the inputs into its index in the vocabulary.</p>

<p>The API should also include a <code>keras.layers.Discretization</code> layer that will chop continuous data into different bins and encode each bin as a one-hot vector. For example, you could use it to discretize prices into three categories (low, medium, high), which would be encoded as [1, 0, 0], [0, 1, 0], and [0, 0, 1], respectively. Of course this loses a lot of information, but in some cases it can help the model detect patterns that would otherwise not be obvious when just looking at the continuous values.</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>The <code>Discretization</code> layer will not be differentiable, so it should only be used at the start of your model. Moreover, preprocessing layers will be frozen during training, so their parameters will not be affected by Gradient Descent. Therefore, you should not use an <code>Embedding</code> layer directly in a custom preprocessing layer, if you wish to train it: it should be added separately to your model, as in the previous code example.</p>
</div>

<p>It will also be possible to chain multiple preprocessing layers using the <code>PreprocessingStage</code> class. For example, the following code will create a preprocessing pipeline that will first normalize the inputs, then discretize them (this may remind you of Scikit-Learn pipelines). After you adapt this pipeline to a data sample, you can use it like a regular layer in your models (but again, only at the start of the model, since it contains a nondifferentiable preprocessing layer):</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">normalization</code> <code class="o">=</code> <code class="n">keras</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">Normalization</code><code class="p">()</code>
<code class="n">discretization</code> <code class="o">=</code> <code class="n">keras</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">Discretization</code><code class="p">([</code><code class="o">...</code><code class="p">])</code>
<code class="n">pipeline</code> <code class="o">=</code> <code class="n">keras</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">PreprocessingStage</code><code class="p">([</code><code class="n">normalization</code><code class="p">,</code> <code class="n">discretization</code><code class="p">])</code>
<code class="n">pipeline</code><code class="o">.</code><code class="n">adapt</code><code class="p">(</code><code class="n">data_sample</code><code class="p">)</code></pre>

<p>The <code>TextVectorization</code> layer will also have an option to output word-count vectors instead of word indices. For example, if the vocabulary contains three words, say <code>["and", "basketball", "more"]</code>, then the text <code>"more and more"</code> will be mapped to the vector <code>[1, 0, 2]</code>: indeed, the word <code>"and"</code> appears once, the word <code>"basketball"</code> does not appear at all, and the word <code>"more"</code> appears twice. This text representation is called a <em>bag of words</em>, since it completely loses the order of the words. Common words like <code>"and"</code> will have a large value in most texts, even though they are usually the least interesting: for example, in a sentence like <code>"more and more basketball"</code>, the word <code>"basketball"</code> is clearly the most important, precisely because it is not a very frequent word. So the word counts should be normalized in a way that reduces the importance of frequent words. A common way to do this is to divide each word count by the log of the total number of training instances in which the word appears. This technique is called <em>Term-Frequency</em> × <em>Inverse-Document-Frequency</em> (TF-IDF). For example, let’s imagine that the words <code>"and"</code>, <code>"basketball"</code>, and <code>"more"</code> appear respectively in 200, 10, and 100 text instances in the training set: in this case, the final vector will be <code>[1/log(200), 0/log(10), 2/log(100)]</code>, which is approximately equal to <code>[0.19, 0.,0.43]</code>. The <code>TextVectorization</code> layer will (likely) have an option to perform TF-IDF.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>If the standard preprocessing layers are not enough for your task, you will still have the option to create your own custom preprocessing layer, much like we did earlier with the Standardization class. Just create a subclass of the <code>keras.layers.PreprocessingLayer</code> class, with an <code>adapt()</code> method, which should take a <code>data_sample</code> argument and optionally an extra <code>reset_state</code> argument: if <code>True</code>, then the <code>adapt()</code> method should reset any existing state before computing the new state; if <code>False</code>, it should try to update the existing state.</p>
</div>

<p>As you can see, these Keras preprocessing layers will make preprocessing much easier! Now, whether you choose to write your own preprocessing layers or use the Keras preprocessing layers (or even use the Feature Columns API), all the preprocessing will be done on the fly. During training, it may be preferable to perform preprocessing ahead of time. Let’s see why we’d want to do that and how we’d go about it.</p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="TF Transform"><div class="sect1" id="idm46263502052504">
<h1>TF Transform</h1>

<p>If preprocessing is computationally expensive, then handling it before training rather than on the fly may give you a significant speedup: the data will be preprocessed just once per instance <em>before</em> training, rather than once per instance and per epoch <em>during</em> training. If the dataset is small enough to fit in RAM, you can use its <code>cache()</code> method. But if it is too large, then tools like Apache Beam or Spark will help. They let you run efficient data processing pipelines over large amounts of data, even distributed across multiple servers, so you can use them to preprocess all the training data before training.</p>

<p>This works great and indeed can speed up training, but there is one problem: once your model is trained, suppose you want to deploy it to a mobile app. In that case you will need to write some code in your app to take care of preprocessing the data before it is fed to the model. And suppose you also want to deploy the model to TensorFlow.js so that it runs in a web browser? Once again, you will need to write some preprocessing code. This can become a maintenance nightmare: whenever you want to change the preprocessing logic, you will need to update your Apache Beam code, your mobile app code, and your Javascript code. It is not only time-consuming, but also error prone: you may end up with subtle differences between the preprocessing operations performed before training and the ones performed in your app or in the browser. This <em>training/serving skew</em> will lead to bugs or degraded performance.</p>

<p>One improvement would be to take the trained model (trained on data that was preprocessed by your Apache Beam or Spark code), and before deploying it to your app or the browser, add an extra preprocessing layers to take care of preprocessing on the fly. That’s definitely better, since now you just have two versions of your preprocessing code: the Apache Beam or Spark code, and the preprocessing layers’ code.</p>

<p>But what if you could define your preprocessing operations just once? This is what TF Transform was designed for. It is part of <a href="https://tensorflow.org/tfx">TensorFlow Extended</a> (TFX), an end-to-end platform for productionizing TensorFlow models. First, to use a TFX component such as TF Transform, you must install it; it does not come bundled with TensorFlow. You define your preprocessing function just once (in Python), by using TF Transform functions for scaling, bucketizing, and more. You can also use any TensorFlow operation you need. Here is what this preprocessing function might look like if we just had two features:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">import</code> <code class="nn">tensorflow_transform</code> <code class="kn">as</code> <code class="nn">tft</code>

<code class="k">def</code> <code class="nf">preprocess</code><code class="p">(</code><code class="n">inputs</code><code class="p">):</code>  <code class="c1"># inputs = a batch of input features</code>
    <code class="n">median_age</code> <code class="o">=</code> <code class="n">inputs</code><code class="p">[</code><code class="s2">"housing_median_age"</code><code class="p">]</code>
    <code class="n">ocean_proximity</code> <code class="o">=</code> <code class="n">inputs</code><code class="p">[</code><code class="s2">"ocean_proximity"</code><code class="p">]</code>
    <code class="n">standardized_age</code> <code class="o">=</code> <code class="n">tft</code><code class="o">.</code><code class="n">scale_to_z_score</code><code class="p">(</code><code class="n">median_age</code><code class="p">)</code>
    <code class="n">ocean_proximity_id</code> <code class="o">=</code> <code class="n">tft</code><code class="o">.</code><code class="n">compute_and_apply_vocabulary</code><code class="p">(</code><code class="n">ocean_proximity</code><code class="p">)</code>
    <code class="k">return</code> <code class="p">{</code>
        <code class="s2">"standardized_median_age"</code><code class="p">:</code> <code class="n">standardized_age</code><code class="p">,</code>
        <code class="s2">"ocean_proximity_id"</code><code class="p">:</code> <code class="n">ocean_proximity_id</code>
    <code class="p">}</code></pre>

<p>Next, TF Transform lets you apply this <code>preprocess()</code> function to the whole training set using Apache Beam (it provides an <code>AnalyzeAndTransformDataset</code> class that you can use for this purpose in your Apache Beam pipeline). In the process, it will also compute all the necessary statistics over the whole training set: in this example, the mean and standard deviation of the <code>housing_median_age</code> feature, and the vocabulary for the <code>ocean_proximity</code> feature. The components that compute these statistics are called <em>analyzers</em>.</p>

<p>Importantly, TF Transform will also generate an equivalent TensorFlow Function that you can plug into the model you deploy. This TF Function includes some constants that correspond to all the all the necessary statistics computed by Apache Beam (the mean, standard deviation, and vocabulary).</p>

<p>With the Data API, TFRecords, the Keras preprocessing layers and TF Transform, you can build highly scalable input pipelines for training and benefit from fast and portable data preprocessing in production.</p>

<p>But what if you just wanted to use a standard dataset? Well in that case, things are much simpler: just use TFDS!</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="The TensorFlow Datasets (TFDS) Project"><div class="sect1" id="idm46263501102888">
<h1>The TensorFlow Datasets (TFDS) Project</h1>

<p>The <a href="https://tensorflow.org/datasets">TensorFlow Datasets</a> project makes it very easy to download common datasets, from small ones like MNIST or Fashion MNIST, to huge datasets like ImageNet (you will need quite a bit of disk space!). The list includes image datasets, text datasets (including translation datasets), and audio and video datasets. You can visit <a href="https://homl.info/tfds"><em class="hyperlink">https://homl.info/tfds</em></a> to view the full list, along with a description of each dataset.</p>

<p>TFDS is not bundled with TensorFlow, so you need to install the <code>tensorflow-datasets</code> library (e.g., using pip). Then call the <code>tfds.load()</code> function, and it will download the data you want (unless it was already downloaded earlier) and return the data as a dictionary of <code>Datasets</code> (typically one for training and one for testing, but this depends on the dataset you choose). For example, let’s download MNIST:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">import</code> <code class="nn">tensorflow_datasets</code> <code class="kn">as</code> <code class="nn">tfds</code>

<code class="n">dataset</code> <code class="o">=</code> <code class="n">tfds</code><code class="o">.</code><code class="n">load</code><code class="p">(</code><code class="n">name</code><code class="o">=</code><code class="s2">"mnist"</code><code class="p">)</code>
<code class="n">mnist_train</code><code class="p">,</code> <code class="n">mnist_test</code> <code class="o">=</code> <code class="n">dataset</code><code class="p">[</code><code class="s2">"train"</code><code class="p">],</code> <code class="n">dataset</code><code class="p">[</code><code class="s2">"test"</code><code class="p">]</code></pre>

<p>You can then apply any transformation you want (typically shuffling, batching, and prefetching), and you’re ready to train your model. Here is a simple example:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">mnist_train</code> <code class="o">=</code> <code class="n">mnist_train</code><code class="o">.</code><code class="n">shuffle</code><code class="p">(</code><code class="mi">10000</code><code class="p">)</code><code class="o">.</code><code class="n">batch</code><code class="p">(</code><code class="mi">32</code><code class="p">)</code><code class="o">.</code><code class="n">prefetch</code><code class="p">(</code><code class="mi">1</code><code class="p">)</code>
<code class="k">for</code> <code class="n">item</code> <code class="ow">in</code> <code class="n">mnist_train</code><code class="p">:</code>
    <code class="n">images</code> <code class="o">=</code> <code class="n">item</code><code class="p">[</code><code class="s2">"image"</code><code class="p">]</code>
    <code class="n">labels</code> <code class="o">=</code> <code class="n">item</code><code class="p">[</code><code class="s2">"label"</code><code class="p">]</code>
    <code class="p">[</code><code class="o">...</code><code class="p">]</code></pre>
<div data-type="tip"><h6>Tip</h6>
<p>The <code>load()</code> function shuffles each data shard it downloads (only for the training set). This may not be sufficient, so it’s best to shuffle the training data some more.</p>
</div>

<p>Note that each item in the dataset is a dictionary containing both the features and the labels. But Keras expects each item to be a tuple containing two elements (again, the features and the labels). You could transform the dataset using the <code>map()</code> method, like this:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">mnist_train</code> <code class="o">=</code> <code class="n">mnist_train</code><code class="o">.</code><code class="n">shuffle</code><code class="p">(</code><code class="mi">10000</code><code class="p">)</code><code class="o">.</code><code class="n">batch</code><code class="p">(</code><code class="mi">32</code><code class="p">)</code>
<code class="n">mnist_train</code> <code class="o">=</code> <code class="n">mnist_train</code><code class="o">.</code><code class="n">map</code><code class="p">(</code><code class="k">lambda</code> <code class="n">items</code><code class="p">:</code> <code class="p">(</code><code class="n">items</code><code class="p">[</code><code class="s2">"image"</code><code class="p">],</code> <code class="n">items</code><code class="p">[</code><code class="s2">"label"</code><code class="p">]))</code>
<code class="n">mnist_train</code> <code class="o">=</code> <code class="n">mnist_train</code><code class="o">.</code><code class="n">prefetch</code><code class="p">(</code><code class="mi">1</code><code class="p">)</code></pre>

<p>But it’s simpler to ask the <code>load()</code> function to do this for you by setting <code>as_supervised=True</code> (obviously this works only for labeled datasets). You can also specify the batch size if you want. Then the dataset can be passed directly to your tf.keras model:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">dataset</code> <code class="o">=</code> <code class="n">tfds</code><code class="o">.</code><code class="n">load</code><code class="p">(</code><code class="n">name</code><code class="o">=</code><code class="s2">"mnist"</code><code class="p">,</code> <code class="n">batch_size</code><code class="o">=</code><code class="mi">32</code><code class="p">,</code> <code class="n">as_supervised</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>
<code class="n">mnist_train</code> <code class="o">=</code> <code class="n">dataset</code><code class="p">[</code><code class="s2">"train"</code><code class="p">]</code><code class="o">.</code><code class="n">prefetch</code><code class="p">(</code><code class="mi">1</code><code class="p">)</code>
<code class="n">model</code> <code class="o">=</code> <code class="n">keras</code><code class="o">.</code><code class="n">models</code><code class="o">.</code><code class="n">Sequential</code><code class="p">([</code><code class="o">...</code><code class="p">])</code>
<code class="n">model</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="n">loss</code><code class="o">=</code><code class="s2">"sparse_categorical_crossentropy"</code><code class="p">,</code> <code class="n">optimizer</code><code class="o">=</code><code class="s2">"sgd"</code><code class="p">)</code>
<code class="n">model</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">mnist_train</code><code class="p">,</code> <code class="n">epochs</code><code class="o">=</code><code class="mi">5</code><code class="p">)</code></pre>

<p>This was quite a technical chapter, and you may feel that it is a bit far from the abstract beauty of neural networks, but the fact is Deep Learning often involves large amounts of data, and knowing how to load, parse and preprocess it efficiently is a crucial skill to have. In the next chapter, we will look at convolutional neural networks, which are among the most successful neural net architectures for image processing, and many other applications.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Exercises"><div class="sect1" id="idm46263500931224">
<h1>Exercises</h1>
<ol>
<li>
<p>Why would you want to use the Data API?</p>
</li>
<li>
<p>What are the benefits of splitting a large dataset into multiple files?</p>
</li>
<li>
<p>During training, how can you tell that your input pipeline is the bottleneck? What can you do to fix it?</p>
</li>
<li>
<p>Can you save any binary data to a TFRecord file, or only serialized protocol buffers?</p>
</li>
<li>
<p>Why would you go through the hassle of converting all your data to the <code>Example</code> protobuf format? Why not use your own protobuf definition?</p>
</li>
<li>
<p>When using TFRecords, when would you want to activate compression? Why not do it systematically?</p>
</li>
<li>
<p>Data can be preprocessed directly when writing the data files, or within the tf.data pipeline, or in preprocessing layers within your model, or using TF Transform. Can you list a few pros and cons of each option?</p>
</li>
<li>
<p>Name a few common techniques you can use to encode categorical features? What about text?</p>
</li>
<li>
<p>Load the Fashion MNIST dataset (introduced in <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch10.html#ann_chapter">Chapter&nbsp;10</a>); split it into a training set, a validation set, and a test set; shuffle the training set; and save each dataset to multiple TFRecord files. Each record should be a serialized <code>Example</code> protobuf with two features: the serialized image (use <code>tf.io.serialize_tensor()</code> to serialize each image), and the label.<sup><a data-type="noteref" id="idm46263500652216-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#idm46263500652216">12</a></sup> Then use tf.data to create an efficient <code>Dataset</code> for each set. Finally, use a Keras model to train these datasets, including a preprocessing layer to standardize each input feature. Try to make the input pipeline as efficient as possible, using TensorBoard to visualize profiling data.</p>
</li>
<li>
<p>In this exercise you will download a dataset, split it, create a tf.data.Dataset to load it and preprocess it efficiently, then build and train a binary classification model containing an Embedding layer:</p>
<ol>
<li>
<p>Download the <a href="https://homl.info/imdb">Large Movie Review Dataset</a>, which contains 50,000 movies reviews from the <a href="https://imdb.com/">Internet Movie Database</a>. The data is organized in two directories, <code>train</code> and <code>test</code>, each containing a <code>pos</code> subdirectory with 12,500 positive reviews, and a <code>neg</code> subdirectory with 12,500 negative reviews. Each review is stored in a separate text file. There are other files and folders (including preprocessed bag-of-words), but we will ignore them in this exercise.</p>
</li>
<li>
<p>Split the test set into a validation set (15,000) and a test set (10,000).</p>
</li>
<li>
<p>Use tf.data to create an efficient <code>Dataset</code> for each set.</p>
</li>
<li>
<p>Create a binary classification model, using a <code>TextVectorization</code> layer to preprocess each review. If the <code>TextVectorization</code> layer is not yet available (or if you like a challenge), try to create your own custom preprocessing layer: you can use the functions in the <code>tf.strings</code> package, for example <code>lower()</code> to make everything lower case, <code>regex_replace()</code> to replace punctuation with spaces, and <code>split()</code> to split words on spaces. You should use a lookup table to output word indices, which must be prepared in the <code>adapt()</code> method.</p>
</li>
<li>
<p>Add an <code>Embedding</code> layer, and compute the mean embedding for each review, multiplied by the square root of the number of words (see <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch16.html#nlp_chapter">Chapter&nbsp;16</a>). This rescaled mean embedding can then be passed to the rest of your model.</p>
</li>
<li>
<p>Train the model and see what accuracy you get. Try to optimize your pipelines to make training as fast as possible.</p>
</li>
<li>
<p>Use TFDS to load the same dataset more easily: <code>tfds.load("imdb_reviews")</code>.</p>
</li>

</ol>
</li>

</ol>

<p>Solutions to these exercises are available in <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/app01.html#solutions_appendix">Appendix&nbsp;A</a>.</p>
</div></section>







<div data-type="footnotes"><p data-type="footnote" id="idm46263504438760"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#idm46263504438760-marker" class="totri-footnote">1</a></sup> These layers will likely supersede the Feature Columns API, so I have moved the section about the Feature Columns API to the Jupyter notebook for this chapter, in case you still want to use it.</p><p data-type="footnote" id="idm46263504143880"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#idm46263504143880-marker" class="totri-footnote">2</a></sup> Imagine a sorted deck of cards on your left: suppose you just take the top three cards and shuffle them, then pick one randomly and put it to your right, keeping the other two in your hands. Take another card on your left, shuffle the three cards in your hands and pick one of them randomly, and put it on your right. When you are done going through all the cards like this, you will have a deck of cards on your right: do you think it will be perfectly shuffled?</p><p data-type="footnote" id="idm46263503511288"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#idm46263503511288-marker" class="totri-footnote">3</a></sup> In general, just prefetching one batch is fine, but in some cases you may need to prefetch a few more. Alternatively, you can let TensorFlow decide automatically by passing <code>tf.data.experimental.AUTOTUNE</code> (this is an experimental feature for now).</p><p data-type="footnote" id="idm46263503507400"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#idm46263503507400-marker" class="totri-footnote">4</a></sup> But check out the <code>tf.data.experimental.prefetch_to_device()</code> function, which can prefetch data directly to the GPU.</p><p data-type="footnote" id="idm46263503484808"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#idm46263503484808-marker" class="totri-footnote">5</a></sup> Support for datasets is specific to tf.keras; it will not work on other implementations of the Keras API.</p><p data-type="footnote" id="idm46263503482392"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#idm46263503482392-marker" class="totri-footnote">6</a></sup> The <code>fit()</code> method will take care of repeating the training dataset. Alternatively, you could call <code>repeat()</code> on the training dataset so that it repeats forever and specify the <code>steps_per_epoch</code> argument when calling the <code>fit()</code> method. This may be useful in some rare cases, for example if you want to use a shuffle buffer that crosses over epochs.</p><p data-type="footnote" id="idm46263502886504"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#idm46263502886504-marker" class="totri-footnote">7</a></sup> Since protobuf objects are meant to be serialized and transmitted, they are called <em>messages</em>.</p><p data-type="footnote" id="idm46263502758552"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#idm46263502758552-marker" class="totri-footnote">8</a></sup> This chapter contains the bare minimum you need to know about protobufs to use TFRecords. To learn more about protobufs, please visit <a href="https://homl.info/protobuf"><em class="hyperlink">https://homl.info/protobuf</em></a>.</p><p data-type="footnote" id="idm46263502621576"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#idm46263502621576-marker" class="totri-footnote">9</a></sup> Why was <code>Example</code> even defined, since it contains no more than a <code>Features</code> object? Well, TensorFlow may one day decide to add more fields to it. As long as the new <code>Example</code> definition still contains the <code>features</code> field, with the same ID, it will be backward compatible. This extensibility is one of the great features of protobufs.</p><p data-type="footnote" id="idm46263501533640"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#idm46263501533640-marker">10</a></sup> Tomas Mikolov et al., “Distributed Representations of Words and Phrases and Their Compositionality” in <em>Advances in Neural Information Processing Systems 30 (NeurIPS 2013)</em>: 3111–3119.</p><p data-type="footnote" id="idm46263501526680"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#idm46263501526680-marker">11</a></sup> Malvina Nissim et al., “Fair Is Better Than Sensational: Man Is to Doctor as Woman Is to Doctor” (2019).</p><p data-type="footnote" id="idm46263500652216"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#idm46263500652216-marker">12</a></sup> For large images, you could use <code>tf.io.encode_jpeg()</code> instead. This would save a lot of space, but it would lose a bit of image quality.</p></div></div></section><div class="annotator-outer annotator-viewer viewer annotator-hide">
  <ul class="annotator-widget annotator-listing"></ul>
</div><div class="annotator-modal-wrapper annotator-editor-modal annotator-editor annotator-hide">
	<div class="annotator-outer editor">
		<h2 class="title">Highlight</h2>
		<form class="annotator-widget">
			<ul class="annotator-listing">
			<li class="annotator-item"><textarea id="annotator-field-14" placeholder="Add a note using markdown (optional)" class="js-editor" maxlength="750"></textarea></li></ul>
			<div class="annotator-controls">
				<a class="link-to-markdown" href="https://daringfireball.net/projects/markdown/basics" target="_blank">?</a>
				<ul>
					<li class="delete annotator-hide"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#delete" class="annotator-delete-note button positive">Delete Note</a></li>
					<li class="save"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#save" class="annotator-save annotator-focus button positive">Save Note</a></li>
					<li class="cancel"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#cancel" class="annotator-cancel button">Cancel</a></li>
				</ul>
			</div>
		</form>
	</div>
</div><div class="annotator-modal-wrapper annotator-delete-confirm-modal" style="display: none;">
  <div class="annotator-outer">
    <h2 class="title">Highlight</h2>
      <a class="js-close-delete-confirm annotator-cancel close" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#close">Close</a>
      <div class="annotator-widget">
         <div class="delete-confirm">
            Are you sure you want to permanently delete this note?
         </div>
         <div class="annotator-controls">
            <a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#cancel" class="annotator-cancel button js-cancel-delete-confirm">No, I changed my mind</a>
            <a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#delete" class="annotator-delete button positive js-delete-confirm">Yes, delete it</a>
         </div>
       </div>
   </div>
</div><div class="annotator-adder" style="display: none;">
	<ul class="adders">
		
		<li class="copy"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#">Copy</a></li>
		
		<li class="add-highlight"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#">Add Highlight</a></li>
		<li class="add-note"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#">
			Add Note
		</a></li>
		
	</ul>
</div></div></div>



  <div class="t-sbo-prev sbo-prev sbo-nav-bottom">
  
    
      
        <a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html" class="prev nav-link">
      
          <span aria-hidden="true" class="pagination-label t-prev-label">Prev</span>
          <span class="visuallyhidden">Previous Chapter</span>
          <div class="pagination-title t-prev-title">12. Custom Models and Training with TensorFlow</div>
        </a>
    
  
  </div>

  <div class="t-sbo-next sbo-next sbo-nav-bottom">
  
    
      
        <a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch14.html" class="next nav-link">
      
          <span aria-hidden="true" class="pagination-label t-next-label">Next</span>
          <span class="visuallyhidden">Next Chapter</span>
          <div class="pagination-title t-next-title">14. Deep Computer Vision Using Convolutional Neural Networks</div>
        </a>
    
  
  </div>

</section>
  </div>
<section class="sbo-saved-archives"></section>



          
          
  




    
    



        
      </div>
      



  <footer class="pagefoot">
    <a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#" class="icon-up" style="display: none;"><div class="visuallyhidden">Back to top</div></a>
    <ul class="js-footer-nav">
      <li class="full-support"><a href="https://www.oreilly.com/online-learning/support/">Support</a></li>
      <li><a href="https://www.oreilly.com/online-learning/apps.html">Get the App</a></li>
      
        <li><a href="https://learning.oreilly.com/accounts/logout/">Sign Out</a></li>
      
    </ul>
    <span class="copyright">© 2019 <a href="https://learning.oreilly.com/" target="_blank">Safari</a>.</span>
    <a href="https://learning.oreilly.com/terms/">Terms of Service</a> /
    <a href="https://learning.oreilly.com/membership-agreement/">Membership Agreement</a> /
    <a href="https://www.oreilly.com/privacy.html">Privacy Policy</a>
  </footer>

<script type="text/javascript">window.NREUM||(NREUM={});NREUM.info={"applicationID":"172641827,79672898,93931619","errorBeacon":"bam.nr-data.net","agent":"","applicationTime":451,"licenseKey":"510f1a6865","transactionName":"YgdaZ0NSW0cEB0RdWltNfkZfUEFdCgofXFBHDVYdR1pQQxZeRl1QQj1aWkU=","beacon":"bam.nr-data.net","queueTime":4}</script>


    
    <script src="./Chapter13_files/saved_resource" charset="utf-8"></script><script type="text/javascript" id="">!function(b,e,f,g,a,c,d){b.fbq||(a=b.fbq=function(){a.callMethod?a.callMethod.apply(a,arguments):a.queue.push(arguments)},b._fbq||(b._fbq=a),a.push=a,a.loaded=!0,a.version="2.0",a.queue=[],c=e.createElement(f),c.async=!0,c.src=g,d=e.getElementsByTagName(f)[0],d.parentNode.insertBefore(c,d))}(window,document,"script","https://connect.facebook.net/en_US/fbevents.js");fbq("init","1732687426968531");fbq("track","PageView");</script>
<noscript><img height="1" width="1" style="display:none" src="https://www.facebook.com/tr?id=1732687426968531&amp;ev=PageView&amp;noscript=1"></noscript><script type="text/javascript" id="">(function(){window.medalliaUserIdentifier=document.documentElement.dataset.userUuid;window.medalliaUserName=document.documentElement.dataset.username})();</script>
<script type="text/javascript" id="" src="./Chapter13_files/embed.js.download"></script><script type="text/javascript" id="">adroll_adv_id="BOHFZPCX5ZAM5LXWJURNUB";adroll_pix_id="3QFV44ZHVZG53BOB75QP3D";
(function(){var a=function(){if(document.readyState&&!/loaded|complete/.test(document.readyState))setTimeout(a,10);else if(window.__adroll_loaded){var b=document.createElement("script"),c="https:"==document.location.protocol?"https://s.adroll.com":"http://a.adroll.com";b.setAttribute("async","true");b.type="text/javascript";b.src=c+"/j/roundtrip.js";((document.getElementsByTagName("head")||[null])[0]||document.getElementsByTagName("script")[0].parentNode).appendChild(b)}else __adroll_loaded=!0,setTimeout(a,
50)};window.addEventListener?window.addEventListener("load",a,!1):window.attachEvent("onload",a)})();</script><script type="text/javascript" id="">adroll_adv_id="BOHFZPCX5ZAM5LXWJURNUB";adroll_pix_id="3QFV44ZHVZG53BOB75QP3D";
(function(){var a=function(){if(document.readyState&&!/loaded|complete/.test(document.readyState))setTimeout(a,10);else if(window.__adroll_loaded){var b=document.createElement("script"),c="https:"==document.location.protocol?"https://s.adroll.com":"http://a.adroll.com";b.setAttribute("async","true");b.type="text/javascript";b.src=c+"/j/roundtrip.js";((document.getElementsByTagName("head")||[null])[0]||document.getElementsByTagName("script")[0].parentNode).appendChild(b)}else __adroll_loaded=!0,setTimeout(a,
50)};window.addEventListener?window.addEventListener("load",a,!1):window.attachEvent("onload",a)})();</script>
<script type="text/javascript" id="">!function(b,e,f,g,a,c,d){b.fbq||(a=b.fbq=function(){a.callMethod?a.callMethod.apply(a,arguments):a.queue.push(arguments)},b._fbq||(b._fbq=a),a.push=a,a.loaded=!0,a.version="2.0",a.queue=[],c=e.createElement(f),c.async=!0,c.src=g,d=e.getElementsByTagName(f)[0],d.parentNode.insertBefore(c,d))}(window,document,"script","https://connect.facebook.net/en_US/fbevents.js");fbq("init","443792972845831");fbq("set","agent","tmgoogletagmanager","443792972845831");fbq("track","PageView");</script>
<noscript><img height="1" width="1" style="display:none" src="https://www.facebook.com/tr?id=443792972845831&amp;ev=PageView&amp;noscript=1"></noscript>

<script type="text/javascript" id="">!function(b,e,f,g,a,c,d){b.fbq||(a=b.fbq=function(){a.callMethod?a.callMethod.apply(a,arguments):a.queue.push(arguments)},b._fbq||(b._fbq=a),a.push=a,a.loaded=!0,a.version="2.0",a.queue=[],c=e.createElement(f),c.async=!0,c.src=g,d=e.getElementsByTagName(f)[0],d.parentNode.insertBefore(c,d))}(window,document,"script","https://connect.facebook.net/en_US/fbevents.js");fbq("init","443792972845831");fbq("track","PageView");</script>
<noscript><img height="1" width="1" style="display:none" src="https://www.facebook.com/tr?id=443792972845831&amp;ev=PageView&amp;noscript=1"></noscript>
<div style="width:0px; height:0px; display:none; visibility:hidden;" id="batBeacon0.09556792590964802"><img style="width:0px; height:0px; display:none; visibility:hidden;" id="batBeacon0.5229133033930915" width="0" height="0" alt="" src="./Chapter13_files/0"></div>
    <script src="./Chapter13_files/saved_resource(1)" charset="utf-8"></script>
  

<script src="./Chapter13_files/saved_resource(2)" type="text/javascript"></script><script type="text/javascript" id="">window._pp=window._pp||[];if("\/library\/view\/hands-on-machine-learning\/9781492032632\/part01.html"=="/confirmation/nnv/"&&"https:\/\/learning.oreilly.com\/library\/view\/hands-on-machine-learning\/9781492032632\/"=="https://learning.oreilly.com/register/")_pp.targetUrl="/confirm/trial";else if("\/library\/view\/hands-on-machine-learning\/9781492032632\/part01.html"=="/confirmation/nv/"&&"https:\/\/learning.oreilly.com\/library\/view\/hands-on-machine-learning\/9781492032632\/"=="https://learning.oreilly.com/subscribe/")_pp.targetUrl="/confirm/paid";else if("\/library\/view\/hands-on-machine-learning\/9781492032632\/part01.html"=="/confirmation/nnv/"&&"https:\/\/learning.oreilly.com\/library\/view\/hands-on-machine-learning\/9781492032632\/"=="https://learning.oreilly.com/signup/")_pp.targetUrl="/confirm/paid";_pp.siteId="2508";
_pp.siteUId="d59baa21-c0cd-4fcf-9c68-a2b8d4f52a79";_pp.orderValue="undefined";_pp.orderId="undefined";(function(){var ppjs=document.createElement("script");ppjs.type="text/javascript";ppjs.async=true;ppjs.src=("https:"==document.location.protocol?"https:":"http:")+"//cdn.pbbl.co/r/"+_pp.siteId+".js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(ppjs,s)})();</script><div class="annotator-notice"></div><div class="font-flyout" style="top: 201px; left: 1194px;"><div class="font-controls-panel">
	<div class="nightmodes">
		<ul>
			<li class="day"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#" id="day-mode" title="Day Mode">
				<i class="fa fa-sun-o"></i>
				<span>Day Mode</span></a></li>
			<li class="cloudy"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#" id="cloudy-mode" title="Cloudy Mode">
				<i class="fa fa-cloud"></i>
				<span>Cloud Mode</span>
			</a></li>
			<li class="night"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#" id="night-mode" title="Night Mode">
				<i class="fa fa-moon-o"></i>
				<span>Night Mode</span>
			</a></li>
		</ul>
	</div>

	<div class="font-resizer resizer">
		<div class="draggable-containment-wrapper">
			<i class="fa fa-font left"></i>
			<span class="filler" style="width: 50%;"></span>
			<div id="js-font-size-draggable" class="draggable ui-widget-content ui-draggable ui-draggable-handle" style="position: relative; left: 80px;"></div>
			<i class="fa fa-font right"></i>
		</div>
	</div>

	<div class="column-resizer resizer">
		<div class="draggable-containment-wrapper">
			<i class="fa fa-compress left"></i>
			<span class="filler" style="width: 50%;"></span>
			<div id="js-column-size-draggable" class="draggable ui-widget-content ui-draggable ui-draggable-handle" style="position: relative; left: 80px;"></div>
			<i class="fa fa-expand right"></i>
		</div>
	</div>

	<a id="reset" class="button" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#">Reset</a>
</div>
</div><script type="text/javascript" async="" src="./Chapter13_files/generic1566415868241.js.download" charset="UTF-8"></script><div style="display: none; visibility: hidden;"><script>(function(){if(null!==document.querySelector('iframe[title\x3d"fb:share_button Facebook Social Plugin"]')&&void 0!==document.querySelector('iframe[title\x3d"fb:share_button Facebook Social Plugin"]')){var a=!1;window.addEventListener("blur",function(){a&&dataLayer.push({event:"eventTracker",eventCat:"social",eventAct:"share",eventLbl:"facebook",eventVal:0,nonInteraction:0})});document.querySelector('iframe[title\x3d"fb:share_button Facebook Social Plugin"]').addEventListener("mouseover",function(){window.focus();
a=!0});document.querySelector('iframe[title\x3d"fb:share_button Facebook Social Plugin"]').addEventListener("mouseout",function(){a=!1})}try{window.twttr=function(b,a,d){var c,e=b.getElementsByTagName(a)[0];if(!b.getElementById(d))return b=b.createElement(a),b.id=d,b.src="//platform.twitter.com/widgets.js",e.parentNode.insertBefore(b,e),window.twttr||(c={_e:[],ready:function(a){c._e.push(a)}})}(document,"script","twitter-wjs"),twttr.ready(function(a){a.events.bind("tweet",trackTwitter)})}catch(b){}})();
null!==document.querySelector(".IN-widget")&&void 0!==document.querySelector(".IN-widget")&&document.querySelector(".IN-widget").addEventListener("click",function(){dataLayer.push({event:"eventTracker",eventCat:"social",eventAct:"share",eventLbl:"linkedin",eventVal:0,nonInteraction:0})});
function trackTwitter(a){a&&(a.target&&"IFRAME"==a.target.nodeName&&(opt_target=extractParamFromUri(a.target.src,"url")),dataLayer.push({event:"eventTracker",eventCat:"social",eventAct:"share",eventLbl:"twitter",eventVal:0,nonInteraction:0}))}function extractParamFromUri(a,b){if(a){var c=new RegExp("[\\?\x26#]"+b+"\x3d([^\x26#]*)");c=c.exec(a);if(null!=c)return unescape(c[1])}};</script></div><span><div id="KampyleAnimationContainer" style="z-index: 2147483000; border: 0px; position: fixed; display: block; width: 0px; height: 0px;"></div></span><iframe scrolling="no" frameborder="0" allowtransparency="true" src="./Chapter13_files/widget_iframe.097c1f5038f9e8a0d62a39a892838d66.html" title="Twitter settings iframe" style="display: none;"></iframe><div style="position: absolute; width: 0px; height: 0px; overflow: hidden; padding: 0px; border: 0px; margin: 0px;"><div id="MathJax_Font_Test" style="position: absolute; visibility: hidden; top: 0px; left: 0px; width: auto; padding: 0px; border: 0px; margin: 0px; white-space: nowrap; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; font-size: 40px; font-weight: normal; font-style: normal; font-family: MathJax_AMS, sans-serif;"></div></div></body></html>