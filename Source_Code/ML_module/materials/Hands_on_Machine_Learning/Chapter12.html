<!DOCTYPE html>
<!-- saved from url=(0091)https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html -->
<html class=" js flexbox flexboxlegacy no-touch websqldatabase indexeddb history csscolumns csstransforms localstorage sessionstorage applicationcache svg inlinesvg zoom" lang="en" prefix="og: http://ogp.me/ns/# og:book: http://ogp.me/ns/book# og:video: http://ogp.me/ns/video#" itemscope="" itemtype="http://schema.org/Book http://schema.org/ItemPage" data-login-url="/accounts/login/" data-offline-url="/" data-url="/library/view/hands-on-machine-learning/9781492032632/part01.html" data-csrf-cookie="csrfsafari" data-highlight-privacy="" data-user-id="4626953" data-user-uuid="d59baa21-c0cd-4fcf-9c68-a2b8d4f52a79" data-username="17481074" data-account-type="B2B" data-activated-trial-date="" data-archive="9781492032632" data-publishers="O&#39;Reilly Media, Inc." data-htmlfile-name="part01.html" data-epub-title="Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition" data-debug="0" data-testing="0" style=""><!--<![endif]--><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="author" content="Safari Books Online"><meta name="format-detection" content="telephone=no"><meta http-equiv="cleartype" content="on"><meta name="HandheldFriendly" content="True"><meta name="MobileOptimized" content="320"><meta name="apple-itunes-app" content="app-id=881697395, app-argument=safaridetail://9781492032632"><meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, maximum-scale=1.0"><meta property="twitter:account_id" content="4503599627559754"><script type="text/javascript" async="" src="./Chapter12_files/cool-2.1.15.min.js.download"></script><script type="text/javascript" src="./Chapter12_files/510f1a6865"></script><script id="twitter-wjs" src="./Chapter12_files/widgets.js.download"></script><script src="./Chapter12_files/nr-1130.min.js.download"></script><script type="text/javascript" async="" src="./Chapter12_files/2508.js.download"></script><script async="" src="./Chapter12_files/fbevents.js.download"></script><script type="text/javascript" async="" src="./Chapter12_files/f.txt"></script><script type="text/javascript" async="" src="./Chapter12_files/f.txt"></script><script type="text/javascript" async="" src="./Chapter12_files/f.txt"></script><script type="text/javascript" async="" src="./Chapter12_files/analytics.js.download"></script><script type="text/javascript" async="" src="./Chapter12_files/ec.js.download"></script><script type="text/javascript" async="" src="./Chapter12_files/bat.js.download"></script><script type="text/javascript" async="" src="./Chapter12_files/f.txt"></script><script type="text/javascript" async="" src="./Chapter12_files/insight.min.js.download"></script><script type="text/javascript" async="" src="./Chapter12_files/f.txt"></script><script type="text/javascript" async="" src="./Chapter12_files/linkid.js.download"></script><script async="" src="./Chapter12_files/gtm.js.download"></script><script async="" src="./Chapter12_files/analytics.js.download"></script><script type="text/javascript">window.NREUM||(NREUM={}),__nr_require=function(e,n,t){function r(t){if(!n[t]){var o=n[t]={exports:{}};e[t][0].call(o.exports,function(n){var o=e[t][1][n];return r(o||n)},o,o.exports)}return n[t].exports}if("function"==typeof __nr_require)return __nr_require;for(var o=0;o<t.length;o++)r(t[o]);return r}({1:[function(e,n,t){function r(){}function o(e,n,t){return function(){return i(e,[c.now()].concat(u(arguments)),n?null:this,t),n?void 0:this}}var i=e("handle"),a=e(3),u=e(4),f=e("ee").get("tracer"),c=e("loader"),s=NREUM;"undefined"==typeof window.newrelic&&(newrelic=s);var p=["setPageViewName","setCustomAttribute","setErrorHandler","finished","addToTrace","inlineHit","addRelease"],d="api-",l=d+"ixn-";a(p,function(e,n){s[n]=o(d+n,!0,"api")}),s.addPageAction=o(d+"addPageAction",!0),s.setCurrentRouteName=o(d+"routeName",!0),n.exports=newrelic,s.interaction=function(){return(new r).get()};var m=r.prototype={createTracer:function(e,n){var t={},r=this,o="function"==typeof n;return i(l+"tracer",[c.now(),e,t],r),function(){if(f.emit((o?"":"no-")+"fn-start",[c.now(),r,o],t),o)try{return n.apply(this,arguments)}catch(e){throw f.emit("fn-err",[arguments,this,e],t),e}finally{f.emit("fn-end",[c.now()],t)}}}};a("actionText,setName,setAttribute,save,ignore,onEnd,getContext,end,get".split(","),function(e,n){m[n]=o(l+n)}),newrelic.noticeError=function(e,n){"string"==typeof e&&(e=new Error(e)),i("err",[e,c.now(),!1,n])}},{}],2:[function(e,n,t){function r(e,n){if(!o)return!1;if(e!==o)return!1;if(!n)return!0;if(!i)return!1;for(var t=i.split("."),r=n.split("."),a=0;a<r.length;a++)if(r[a]!==t[a])return!1;return!0}var o=null,i=null,a=/Version\/(\S+)\s+Safari/;if(navigator.userAgent){var u=navigator.userAgent,f=u.match(a);f&&u.indexOf("Chrome")===-1&&u.indexOf("Chromium")===-1&&(o="Safari",i=f[1])}n.exports={agent:o,version:i,match:r}},{}],3:[function(e,n,t){function r(e,n){var t=[],r="",i=0;for(r in e)o.call(e,r)&&(t[i]=n(r,e[r]),i+=1);return t}var o=Object.prototype.hasOwnProperty;n.exports=r},{}],4:[function(e,n,t){function r(e,n,t){n||(n=0),"undefined"==typeof t&&(t=e?e.length:0);for(var r=-1,o=t-n||0,i=Array(o<0?0:o);++r<o;)i[r]=e[n+r];return i}n.exports=r},{}],5:[function(e,n,t){n.exports={exists:"undefined"!=typeof window.performance&&window.performance.timing&&"undefined"!=typeof window.performance.timing.navigationStart}},{}],ee:[function(e,n,t){function r(){}function o(e){function n(e){return e&&e instanceof r?e:e?f(e,u,i):i()}function t(t,r,o,i){if(!d.aborted||i){e&&e(t,r,o);for(var a=n(o),u=v(t),f=u.length,c=0;c<f;c++)u[c].apply(a,r);var p=s[y[t]];return p&&p.push([b,t,r,a]),a}}function l(e,n){h[e]=v(e).concat(n)}function m(e,n){var t=h[e];if(t)for(var r=0;r<t.length;r++)t[r]===n&&t.splice(r,1)}function v(e){return h[e]||[]}function g(e){return p[e]=p[e]||o(t)}function w(e,n){c(e,function(e,t){n=n||"feature",y[t]=n,n in s||(s[n]=[])})}var h={},y={},b={on:l,addEventListener:l,removeEventListener:m,emit:t,get:g,listeners:v,context:n,buffer:w,abort:a,aborted:!1};return b}function i(){return new r}function a(){(s.api||s.feature)&&(d.aborted=!0,s=d.backlog={})}var u="nr@context",f=e("gos"),c=e(3),s={},p={},d=n.exports=o();d.backlog=s},{}],gos:[function(e,n,t){function r(e,n,t){if(o.call(e,n))return e[n];var r=t();if(Object.defineProperty&&Object.keys)try{return Object.defineProperty(e,n,{value:r,writable:!0,enumerable:!1}),r}catch(i){}return e[n]=r,r}var o=Object.prototype.hasOwnProperty;n.exports=r},{}],handle:[function(e,n,t){function r(e,n,t,r){o.buffer([e],r),o.emit(e,n,t)}var o=e("ee").get("handle");n.exports=r,r.ee=o},{}],id:[function(e,n,t){function r(e){var n=typeof e;return!e||"object"!==n&&"function"!==n?-1:e===window?0:a(e,i,function(){return o++})}var o=1,i="nr@id",a=e("gos");n.exports=r},{}],loader:[function(e,n,t){function r(){if(!E++){var e=x.info=NREUM.info,n=l.getElementsByTagName("script")[0];if(setTimeout(s.abort,3e4),!(e&&e.licenseKey&&e.applicationID&&n))return s.abort();c(y,function(n,t){e[n]||(e[n]=t)}),f("mark",["onload",a()+x.offset],null,"api");var t=l.createElement("script");t.src="https://"+e.agent,n.parentNode.insertBefore(t,n)}}function o(){"complete"===l.readyState&&i()}function i(){f("mark",["domContent",a()+x.offset],null,"api")}function a(){return O.exists&&performance.now?Math.round(performance.now()):(u=Math.max((new Date).getTime(),u))-x.offset}var u=(new Date).getTime(),f=e("handle"),c=e(3),s=e("ee"),p=e(2),d=window,l=d.document,m="addEventListener",v="attachEvent",g=d.XMLHttpRequest,w=g&&g.prototype;NREUM.o={ST:setTimeout,SI:d.setImmediate,CT:clearTimeout,XHR:g,REQ:d.Request,EV:d.Event,PR:d.Promise,MO:d.MutationObserver};var h=""+location,y={beacon:"bam.nr-data.net",errorBeacon:"bam.nr-data.net",agent:"js-agent.newrelic.com/nr-1130.min.js"},b=g&&w&&w[m]&&!/CriOS/.test(navigator.userAgent),x=n.exports={offset:u,now:a,origin:h,features:{},xhrWrappable:b,userAgent:p};e(1),l[m]?(l[m]("DOMContentLoaded",i,!1),d[m]("load",r,!1)):(l[v]("onreadystatechange",o),d[v]("onload",r)),f("mark",["firstbyte",u],null,"api");var E=0,O=e(5)},{}]},{},["loader"]);</script><link rel="apple-touch-icon" href="https://learning.oreilly.com/static/images/apple-touch-icon.0c29511d2d72.png"><link rel="shortcut icon" href="https://learning.oreilly.com/favicon.ico" type="image/x-icon"><link href="./Chapter12_files/css" rel="stylesheet" type="text/css"><title>12. Custom Models and Training with TensorFlow - Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition</title><link rel="stylesheet" href="./Chapter12_files/output.68851547a55f.css" type="text/css"><link rel="stylesheet" type="text/css" href="./Chapter12_files/annotator.e3b0c44298fc.css"><link rel="stylesheet" href="./Chapter12_files/font-awesome.min.css"><style type="text/css" title="ibis-book">@charset "utf-8";#sbo-rt-content html,#sbo-rt-content div,#sbo-rt-content div,#sbo-rt-content span,#sbo-rt-content applet,#sbo-rt-content object,#sbo-rt-content iframe,#sbo-rt-content h1,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5,#sbo-rt-content h6,#sbo-rt-content p,#sbo-rt-content blockquote,#sbo-rt-content pre,#sbo-rt-content a,#sbo-rt-content abbr,#sbo-rt-content acronym,#sbo-rt-content address,#sbo-rt-content big,#sbo-rt-content cite,#sbo-rt-content code,#sbo-rt-content del,#sbo-rt-content dfn,#sbo-rt-content em,#sbo-rt-content img,#sbo-rt-content ins,#sbo-rt-content kbd,#sbo-rt-content q,#sbo-rt-content s,#sbo-rt-content samp,#sbo-rt-content small,#sbo-rt-content strike,#sbo-rt-content strong,#sbo-rt-content sub,#sbo-rt-content sup,#sbo-rt-content tt,#sbo-rt-content var,#sbo-rt-content b,#sbo-rt-content u,#sbo-rt-content i,#sbo-rt-content center,#sbo-rt-content dl,#sbo-rt-content dt,#sbo-rt-content dd,#sbo-rt-content ol,#sbo-rt-content ul,#sbo-rt-content li,#sbo-rt-content fieldset,#sbo-rt-content form,#sbo-rt-content label,#sbo-rt-content legend,#sbo-rt-content table,#sbo-rt-content caption,#sbo-rt-content tdiv,#sbo-rt-content tfoot,#sbo-rt-content thead,#sbo-rt-content tr,#sbo-rt-content th,#sbo-rt-content td,#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content canvas,#sbo-rt-content details,#sbo-rt-content embed,#sbo-rt-content figure,#sbo-rt-content figcaption,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content output,#sbo-rt-content ruby,#sbo-rt-content section,#sbo-rt-content summary,#sbo-rt-content time,#sbo-rt-content mark,#sbo-rt-content audio,#sbo-rt-content video{margin:0;padding:0;border:0;font-size:100%;font:inherit;vertical-align:baseline}#sbo-rt-content article,#sbo-rt-content aside,#sbo-rt-content details,#sbo-rt-content figcaption,#sbo-rt-content figure,#sbo-rt-content footer,#sbo-rt-content header,#sbo-rt-content hgroup,#sbo-rt-content menu,#sbo-rt-content nav,#sbo-rt-content section{display:block}#sbo-rt-content div{line-height:1}#sbo-rt-content ol,#sbo-rt-content ul{list-style:none}#sbo-rt-content blockquote,#sbo-rt-content q{quotes:none}#sbo-rt-content blockquote:before,#sbo-rt-content blockquote:after,#sbo-rt-content q:before,#sbo-rt-content q:after{content:none}#sbo-rt-content table{border-collapse:collapse;border-spacing:0}@page{margin:5px !important}#sbo-rt-content p{margin:10px 0 0;line-height:125%;text-align:left}#sbo-rt-content p.byline{text-align:left;margin:-33px auto 35px;font-style:italic;font-weight:bold}#sbo-rt-content div.preface p+p.byline{margin:1em 0 0 !important}#sbo-rt-content div.preface p.byline+p.byline{margin:0 !important}#sbo-rt-content div.sect1>p.byline{margin:-.25em 0 1em}#sbo-rt-content div.sect1>p.byline+p.byline{margin-top:-1em}#sbo-rt-content em{font-style:italic;font-family:inherit}#sbo-rt-content em strong,#sbo-rt-content strong em{font-weight:bold;font-style:italic;font-family:inherit}#sbo-rt-content strong,#sbo-rt-content span.bold{font-weight:bold}#sbo-rt-content em.replaceable{font-style:italic}#sbo-rt-content strong.userinput{font-weight:bold;font-style:normal}#sbo-rt-content span.bolditalic{font-weight:bold;font-style:italic}#sbo-rt-content a.ulink,#sbo-rt-content a.xref,#sbo-rt-content a.email,#sbo-rt-content a.link,#sbo-rt-content a{text-decoration:none;color:#8e0012}#sbo-rt-content span.lineannotation{font-style:italic;color:#a62a2a;font-family:serif}#sbo-rt-content span.underline{text-decoration:underline}#sbo-rt-content span.strikethrough{text-decoration:line-through}#sbo-rt-content span.smallcaps{font-variant:small-caps}#sbo-rt-content span.cursor{background:#000;color:#fff}#sbo-rt-content span.smaller{font-size:75%}#sbo-rt-content .boxedtext,#sbo-rt-content .keycap{border-style:solid;border-width:1px;border-color:#000;padding:1px}#sbo-rt-content span.gray50{color:#7F7F7F;}#sbo-rt-content h1,#sbo-rt-content div.toc-title,#sbo-rt-content h2,#sbo-rt-content h3,#sbo-rt-content h4,#sbo-rt-content h5{-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;font-weight:bold;text-align:left;page-break-after:avoid !important;font-family:sans-serif,"DejaVuSans"}#sbo-rt-content div.toc-title{font-size:1.5em;margin-top:20px !important;margin-bottom:30px !important}#sbo-rt-content section[data-type="sect1"] h1{font-size:1.3em;color:#8e0012;margin:40px 0 8px 0}#sbo-rt-content section[data-type="sect2"] h2{font-size:1.1em;margin:30px 0 8px 0 !important}#sbo-rt-content section[data-type="sect3"] h3{font-size:1em;color:#555;margin:20px 0 8px 0 !important}#sbo-rt-content section[data-type="sect4"] h4{font-size:1em;font-weight:normal;font-style:italic;margin:15px 0 6px 0 !important}#sbo-rt-content section[data-type="chapter"]>div>h1,#sbo-rt-content section[data-type="preface"]>div>h1,#sbo-rt-content section[data-type="appendix"]>div>h1,#sbo-rt-content section[data-type="glossary"]>div>h1,#sbo-rt-content section[data-type="bibliography"]>div>h1,#sbo-rt-content section[data-type="index"]>div>h1{font-size:2em;line-height:1;margin-bottom:50px;color:#000;padding-bottom:10px;border-bottom:1px solid #000}#sbo-rt-content span.label,#sbo-rt-content span.keep-together{font-size:inherit;font-weight:inherit}#sbo-rt-content div[data-type="part"] h1{font-size:2em;text-align:center;margin-top:0 !important;margin-bottom:50px;padding:50px 0 10px 0;border-bottom:1px solid #000}#sbo-rt-content img.width-ninety{width:90%}#sbo-rt-content img{max-width:95%;margin:0 auto;padding:0}#sbo-rt-content div.figure{background-color:transparent;text-align:center !important;margin:15px 0 15px 0 !important;page-break-inside:avoid}#sbo-rt-content figure{margin:15px 0 15px 0 !important;page-break-inside:avoid}#sbo-rt-content div.figure h6,#sbo-rt-content figure h6,#sbo-rt-content figure figcaption{font-size:.9rem !important;text-align:center;font-weight:normal !important;font-style:italic;font-family:serif !important;text-transform:none !important;letter-spacing:normal !important;color:#000 !important;padding-top:10px !important;page-break-before:avoid}#sbo-rt-content div.informalfigure{text-align:center !important;padding:5px 0 !important}#sbo-rt-content div.sidebar{margin:15px 0 10px 0 !important;border:1px solid #DCDCDC;background-color:#F7F7F7;padding:15px !important;page-break-inside:avoid}#sbo-rt-content aside[data-type="sidebar"]{margin:15px 0 10px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar-title,#sbo-rt-content aside[data-type="sidebar"] h5{font-weight:bold;font-size:1em;font-family:sans-serif;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px 0 !important;page-break-inside:avoid}#sbo-rt-content div.sidebar ol,#sbo-rt-content div.sidebar ul,#sbo-rt-content aside[data-type="sidebar"] ol,#sbo-rt-content aside[data-type="sidebar"] ul{margin-left:1.25em !important}#sbo-rt-content div.sidebar div.figure p.title,#sbo-rt-content aside[data-type="sidebar"] figcaption,#sbo-rt-content div.sidebar div.informalfigure div.caption{font-size:90%;text-align:center;font-weight:normal;font-style:italic;font-family:serif !important;color:#000;padding:5px !important;page-break-before:avoid;page-break-after:avoid}#sbo-rt-content div.sidebar div.tip,#sbo-rt-content div.sidebar div[data-type="tip"],#sbo-rt-content div.sidebar div.note,#sbo-rt-content div.sidebar div[data-type="note"],#sbo-rt-content div.sidebar div.warning,#sbo-rt-content div.sidebar div[data-type="warning"],#sbo-rt-content div.sidebar div[data-type="caution"],#sbo-rt-content div.sidebar div[data-type="important"]{margin:20px auto 20px auto !important;font-size:90%;width:85%}#sbo-rt-content aside[data-type="sidebar"] p.byline{font-size:90%;font-weight:bold;font-style:italic;text-align:center;text-indent:0;margin:5px auto 6px;page-break-after:avoid}#sbo-rt-content pre{white-space:pre-wrap;font-family:"Ubuntu Mono",monospace;margin:25px 0 25px 20px;font-size:85%;display:block;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content div.note pre.programlisting,#sbo-rt-content div.tip pre.programlisting,#sbo-rt-content div.warning pre.programlisting,#sbo-rt-content div.caution pre.programlisting,#sbo-rt-content div.important pre.programlisting{margin-bottom:0}#sbo-rt-content code{font-family:"Ubuntu Mono",monospace;-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none;overflow-wrap:break-word}#sbo-rt-content code strong em,#sbo-rt-content code em strong,#sbo-rt-content pre em strong,#sbo-rt-content pre strong em,#sbo-rt-content strong code em code,#sbo-rt-content em code strong code,#sbo-rt-content span.bolditalic code{font-weight:bold;font-style:italic;font-family:"Ubuntu Mono BoldItal",monospace}#sbo-rt-content code em,#sbo-rt-content em code,#sbo-rt-content pre em,#sbo-rt-content em.replaceable{font-family:"Ubuntu Mono Ital",monospace;font-style:italic}#sbo-rt-content code strong,#sbo-rt-content strong code,#sbo-rt-content pre strong,#sbo-rt-content strong.userinput{font-family:"Ubuntu Mono Bold",monospace;font-weight:bold}#sbo-rt-content div[data-type="example"]{margin:10px 0 15px 0 !important}#sbo-rt-content div[data-type="example"] h1,#sbo-rt-content div[data-type="example"] h2,#sbo-rt-content div[data-type="example"] h3,#sbo-rt-content div[data-type="example"] h4,#sbo-rt-content div[data-type="example"] h5,#sbo-rt-content div[data-type="example"] h6{font-style:italic;font-weight:normal;text-align:left !important;text-transform:none !important;font-family:serif !important;margin:10px 0 5px 0 !important;border-bottom:1px solid #000}#sbo-rt-content li pre.example{padding:10px 0 !important}#sbo-rt-content div[data-type="example"] pre[data-type="programlisting"],#sbo-rt-content div[data-type="example"] pre[data-type="screen"]{margin:0}#sbo-rt-content section[data-type="titlepage"]>div>h1{font-size:2em;margin:50px 0 10px 0 !important;line-height:1;text-align:center}#sbo-rt-content section[data-type="titlepage"] h2,#sbo-rt-content section[data-type="titlepage"] p.subtitle,#sbo-rt-content section[data-type="titlepage"] p[data-type="subtitle"]{font-size:1.3em;font-weight:normal;text-align:center;margin-top:.5em;color:#555}#sbo-rt-content section[data-type="titlepage"]>div>h2[data-type="author"],#sbo-rt-content section[data-type="titlepage"] p.author{font-size:1.3em;font-family:serif !important;font-weight:bold;margin:50px 0 !important;text-align:center}#sbo-rt-content section[data-type="titlepage"] p.edition{text-align:center;text-transform:uppercase;margin-top:2em}#sbo-rt-content section[data-type="titlepage"]{text-align:center}#sbo-rt-content section[data-type="titlepage"]:after{content:url(css_assets/titlepage_footer_ebook.png);margin:0 auto;max-width:80%}#sbo-rt-content div.book div.titlepage div.publishername{margin-top:60%;margin-bottom:20px;text-align:center;font-size:1.25em}#sbo-rt-content div.book div.titlepage div.locations p{margin:0;text-align:center}#sbo-rt-content div.book div.titlepage div.locations p.cities{font-size:80%;text-align:center;margin-top:5px}#sbo-rt-content section.preface[title="Dedication"]>div.titlepage h2.title{text-align:center;text-transform:uppercase;font-size:1.5em;margin-top:50px;margin-bottom:50px}#sbo-rt-content ul.stafflist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.stafflist li{list-style-type:none;padding:5px 0}#sbo-rt-content ul.printings li{list-style-type:none}#sbo-rt-content section.preface[title="Dedication"] p{font-style:italic;text-align:center}#sbo-rt-content div.colophon h1.title{font-size:1.3em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon h2.subtitle{margin:0 !important;color:#000;font-family:serif !important;font-size:1em;font-weight:normal}#sbo-rt-content div.colophon div.author h3.author{font-size:1.1em;font-family:serif !important;margin:10px 0 0 !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h4,#sbo-rt-content div.colophon div.editor h3.editor{color:#000;font-size:.8em;margin:15px 0 0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.editor h3.editor{font-size:.8em;margin:0 !important;font-family:serif !important;font-weight:normal}#sbo-rt-content div.colophon div.publisher{margin-top:10px}#sbo-rt-content div.colophon div.publisher p,#sbo-rt-content div.colophon div.publisher span.publishername{margin:0;font-size:.8em}#sbo-rt-content div.legalnotice p,#sbo-rt-content div.timestamp p{font-size:.8em}#sbo-rt-content div.timestamp p{margin-top:10px}#sbo-rt-content div.colophon[title="About the Author"] h1.title,#sbo-rt-content div.colophon[title="Colophon"] h1.title{font-size:1.5em;margin:0 !important;font-family:sans-serif !important}#sbo-rt-content section.chapter div.titlepage div.author{margin:10px 0 10px 0}#sbo-rt-content section.chapter div.titlepage div.author div.affiliation{font-style:italic}#sbo-rt-content div.attribution{margin:5px 0 0 50px !important}#sbo-rt-content h3.author span.orgname{display:none}#sbo-rt-content div.epigraph{margin:10px 0 10px 20px !important;page-break-inside:avoid;font-size:90%}#sbo-rt-content div.epigraph p{font-style:italic}#sbo-rt-content blockquote,#sbo-rt-content div.blockquote{margin:10px !important;page-break-inside:avoid;font-size:95%}#sbo-rt-content blockquote p,#sbo-rt-content div.blockquote p{font-style:italic;margin:.75em 0 0 !important}#sbo-rt-content blockquote div.attribution,#sbo-rt-content blockquote p[data-type="attribution"]{margin:5px 0 10px 30px !important;text-align:right;width:80%}#sbo-rt-content blockquote div.attribution p,#sbo-rt-content blockquote p[data-type="attribution"]{font-style:normal;margin-top:5px}#sbo-rt-content blockquote div.attribution p:before,#sbo-rt-content blockquote p[data-type="attribution"]:before{font-style:normal;content:"—";-webkit-hyphens:none;hyphens:none;adobe-hyphenate:none}#sbo-rt-content p.right{text-align:right;margin:0}#sbo-rt-content div[data-type="footnotes"]{border-top:1px solid black;margin-top:2em}#sbo-rt-content sub,#sbo-rt-content sup{font-size:75%;line-height:0;position:relative}#sbo-rt-content sup{top:-.5em}#sbo-rt-content sub{bottom:-.25em}#sbo-rt-content p[data-type="footnote"]{font-size:90% !important;line-height:1.2em !important;margin-left:2.5em !important;text-indent:-2.3em !important}#sbo-rt-content p[data-type="footnote"] sup{display:inline-block !important;position:static !important;width:2em !important;text-align:right !important;font-size:100% !important;padding-right:.5em !important}#sbo-rt-content p[data-type="footnote"] a[href$="-marker"]{font-family:sans-serif !important;font-size:90% !important;color:#8e0012 !important}#sbo-rt-content p[data-type="footnote"] a[data-type="xref"]{margin:0 !important;padding:0 !important;text-indent:0 !important}#sbo-rt-content a[data-type="noteref"]{font-family:sans-serif !important;color:#8e0012;margin-left:0;padding-left:0}#sbo-rt-content div.refentry p.refname{font-size:1em;font-family:sans-serif,"DejaVuSans";font-weight:bold;margin-bottom:5px;overflow:auto;width:100%}#sbo-rt-content div.refentry{width:100%;display:block;margin-top:2em}#sbo-rt-content div.refsynopsisdiv{display:block;clear:both}#sbo-rt-content div.refentry header{page-break-inside:avoid !important;display:block;break-inside:avoid !important;padding-top:0;border-bottom:1px solid #000}#sbo-rt-content div.refsect1 h6{font-size:.9em;font-family:sans-serif,"DejaVuSans";font-weight:bold}#sbo-rt-content div.refsect1{margin-top:3em}#sbo-rt-content dt{padding-top:10px !important;padding-bottom:0 !important}#sbo-rt-content dd{margin-left:1.5em !important;margin-bottom:.25em}#sbo-rt-content dd ol,#sbo-rt-content dd ul{padding-left:1em}#sbo-rt-content dd li{margin-top:0;margin-bottom:0}#sbo-rt-content dd,#sbo-rt-content li{text-align:left}#sbo-rt-content ul,#sbo-rt-content ul>li,#sbo-rt-content ol ul,#sbo-rt-content ol ul>li,#sbo-rt-content ul ol ul,#sbo-rt-content ul ol ul>li{list-style-type:disc}#sbo-rt-content ul ul,#sbo-rt-content ul ul>li{list-style-type:square}#sbo-rt-content ul ul ul,#sbo-rt-content ul ul ul>li{list-style-type:circle}#sbo-rt-content ol,#sbo-rt-content ol>li,#sbo-rt-content ol ul ol,#sbo-rt-content ol ul ol>li,#sbo-rt-content ul ol,#sbo-rt-content ul ol>li{list-style-type:decimal}#sbo-rt-content ol ol,#sbo-rt-content ol ol>li{list-style-type:lower-alpha}#sbo-rt-content ol ol ol,#sbo-rt-content ol ol ol>li{list-style-type:lower-roman}#sbo-rt-content ol,#sbo-rt-content ul{list-style-position:outside;margin:15px 0 15px 1.25em;padding-left:2.25em}#sbo-rt-content ol li,#sbo-rt-content ul li{margin:.5em 0 .65em;line-height:125%}#sbo-rt-content div.orderedlistalpha{list-style-type:upper-alpha}#sbo-rt-content table.simplelist,#sbo-rt-content ul.simplelist{margin:15px 0 15px 20px !important}#sbo-rt-content ul.simplelist li{list-style-type:none;padding:5px 0}#sbo-rt-content table.simplelist td{border:none}#sbo-rt-content table.simplelist tr{border-bottom:none}#sbo-rt-content table.simplelist tr:nth-of-type(even){background-color:transparent}#sbo-rt-content dl.calloutlist p:first-child{margin-top:-25px !important}#sbo-rt-content dl.calloutlist dd{padding-left:0;margin-top:-25px}#sbo-rt-content dl.calloutlist img,#sbo-rt-content a.co img{padding:0}#sbo-rt-content div.toc ol{margin-top:8px !important;margin-bottom:8px !important;margin-left:0 !important;padding-left:0 !important}#sbo-rt-content div.toc ol ol{margin-left:30px !important;padding-left:0 !important}#sbo-rt-content div.toc ol li{list-style-type:none}#sbo-rt-content div.toc a{color:#8e0012}#sbo-rt-content div.toc ol a{font-size:1em;font-weight:bold}#sbo-rt-content div.toc ol>li>ol a{font-weight:bold;font-size:1em}#sbo-rt-content div.toc ol>li>ol>li>ol a{text-decoration:none;font-weight:normal;font-size:1em}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"],#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{margin:30px !important;font-size:90%;padding:10px 8px 20px 8px !important;page-break-inside:avoid}#sbo-rt-content div.tip ol,#sbo-rt-content div.tip ul,#sbo-rt-content div[data-type="tip"] ol,#sbo-rt-content div[data-type="tip"] ul,#sbo-rt-content div.note ol,#sbo-rt-content div.note ul,#sbo-rt-content div[data-type="note"] ol,#sbo-rt-content div[data-type="note"] ul,#sbo-rt-content div.warning ol,#sbo-rt-content div.warning ul,#sbo-rt-content div[data-type="warning"] ol,#sbo-rt-content div[data-type="warning"] ul,#sbo-rt-content div[data-type="caution"] ol,#sbo-rt-content div[data-type="caution"] ul,#sbo-rt-content div[data-type="important"] ol,#sbo-rt-content div[data-type="important"] ul{margin-left:1.5em !important}#sbo-rt-content div.tip,#sbo-rt-content div[data-type="tip"],#sbo-rt-content div.note,#sbo-rt-content div[data-type="note"]{border:1px solid #BEBEBE;background-color:transparent}#sbo-rt-content div.warning,#sbo-rt-content div[data-type="warning"],#sbo-rt-content div[data-type="caution"],#sbo-rt-content div[data-type="important"]{border:1px solid #BC8F8F}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="note"] h1,#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1,#sbo-rt-content div[data-type="important"] h6{font-weight:bold;font-size:110%;font-family:sans-serif !important;text-transform:uppercase;letter-spacing:1px;text-align:center;margin:4px 0 6px !important}#sbo-rt-content div[data-type="tip"] figure h6,#sbo-rt-content div[data-type="note"] figure h6,#sbo-rt-content div[data-type="warning"] figure h6,#sbo-rt-content div[data-type="caution"] figure h6,#sbo-rt-content div[data-type="important"] figure h6{font-family:serif !important}#sbo-rt-content div.tip h3,#sbo-rt-content div[data-type="tip"] h6,#sbo-rt-content div.note h3,#sbo-rt-content div[data-type="note"] h6,#sbo-rt-content div[data-type="tip"] h1,#sbo-rt-content div[data-type="note"] h1{color:#737373}#sbo-rt-content div.warning h3,#sbo-rt-content div[data-type="warning"] h6,#sbo-rt-content div[data-type="caution"] h6,#sbo-rt-content div[data-type="important"] h6,#sbo-rt-content div[data-type="warning"] h1,#sbo-rt-content div[data-type="caution"] h1,#sbo-rt-content div[data-type="important"] h1{color:#C67171}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note,#sbo-rt-content div.safarienabled{background-color:transparent;margin:8px 0 0 !important;border:0 solid #BEBEBE;font-size:100%;padding:0 !important;page-break-inside:avoid}#sbo-rt-content div.sect1[title="Safari® Books Online"] div.note h3,#sbo-rt-content div.safarienabled h6{display:none}#sbo-rt-content div.table,#sbo-rt-content table{margin:15px 0 30px 0 !important;max-width:95%;border:none !important;background:none;display:table !important}#sbo-rt-content div.table,#sbo-rt-content div.informaltable,#sbo-rt-content table{page-break-inside:avoid}#sbo-rt-content tr,#sbo-rt-content tr td{border-bottom:1px solid #c3c3c3}#sbo-rt-content thead td,#sbo-rt-content thead th{border-bottom:#9d9d9d 1px solid !important;border-top:#9d9d9d 1px solid !important}#sbo-rt-content tr:nth-of-type(even){background-color:#f1f6fc}#sbo-rt-content thead{font-family:sans-serif;font-weight:bold}#sbo-rt-content td,#sbo-rt-content th{display:table-cell;padding:.3em;text-align:left;vertical-align:middle;font-size:80%}#sbo-rt-content div.informaltable table{margin:10px auto !important}#sbo-rt-content div.informaltable table tr{border-bottom:none}#sbo-rt-content div.informaltable table tr:nth-of-type(even){background-color:transparent}#sbo-rt-content div.informaltable td,#sbo-rt-content div.informaltable th{border:#9d9d9d 1px solid}#sbo-rt-content div.table-title,#sbo-rt-content table caption{font-weight:normal;font-style:italic;font-family:serif;font-size:1em;margin:10px 0 10px 0 !important;padding:0;page-break-after:avoid;text-align:left !important}#sbo-rt-content table code{font-size:smaller}#sbo-rt-content table.border tbody>tr:last-child>td{border-bottom:transparent}#sbo-rt-content div.equation,#sbo-rt-content div[data-type="equation"]{margin:10px 0 15px 0 !important}#sbo-rt-content div.equation-title,#sbo-rt-content div[data-type="equation"] h5{font-style:italic;font-weight:normal;font-family:serif !important;font-size:90%;margin:20px 0 10px 0 !important;page-break-after:avoid}#sbo-rt-content div.equation-contents{margin-left:20px}#sbo-rt-content div[data-type="equation"] math{font-size:calc(.35em + 1vw)}#sbo-rt-content span.inlinemediaobject{height:.85em;display:inline-block;margin-bottom:.2em}#sbo-rt-content span.inlinemediaobject img{margin:0;height:.85em}#sbo-rt-content div.informalequation{margin:20px 0 20px 20px;width:75%}#sbo-rt-content div.informalequation img{width:75%}#sbo-rt-content div.index{text-indent:0}#sbo-rt-content div.index h3{padding:.25em;margin-top:1em !important;background-color:#F0F0F0}#sbo-rt-content div.index li{line-height:130%;list-style-type:none}#sbo-rt-content div.index a.indexterm{color:#8e0012 !important}#sbo-rt-content div.index ul{margin-left:0 !important;padding-left:0 !important}#sbo-rt-content div.index ul ul{margin-left:1em !important;margin-top:0 !important}#sbo-rt-content code.boolean,#sbo-rt-content .navy{color:rgb(0,0,128);}#sbo-rt-content code.character,#sbo-rt-content .olive{color:rgb(128,128,0);}#sbo-rt-content code.comment,#sbo-rt-content .blue{color:rgb(0,0,255);}#sbo-rt-content code.conditional,#sbo-rt-content .limegreen{color:rgb(50,205,50);}#sbo-rt-content code.constant,#sbo-rt-content .darkorange{color:rgb(255,140,0);}#sbo-rt-content code.debug,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.define,#sbo-rt-content .darkgoldenrod,#sbo-rt-content .gold{color:rgb(184,134,11);}#sbo-rt-content code.delimiter,#sbo-rt-content .dimgray{color:rgb(105,105,105);}#sbo-rt-content code.error,#sbo-rt-content .red{color:rgb(255,0,0);}#sbo-rt-content code.exception,#sbo-rt-content .salmon{color:rgb(250,128,11);}#sbo-rt-content code.float,#sbo-rt-content .steelblue{color:rgb(70,130,180);}#sbo-rt-content pre code.function,#sbo-rt-content .green{color:rgb(0,128,0);}#sbo-rt-content code.identifier,#sbo-rt-content .royalblue{color:rgb(65,105,225);}#sbo-rt-content code.ignore,#sbo-rt-content .gray{color:rgb(128,128,128);}#sbo-rt-content code.include,#sbo-rt-content .purple{color:rgb(128,0,128);}#sbo-rt-content code.keyword,#sbo-rt-content .sienna{color:rgb(160,82,45);}#sbo-rt-content code.label,#sbo-rt-content .deeppink{color:rgb(255,20,147);}#sbo-rt-content code.macro,#sbo-rt-content .orangered{color:rgb(255,69,0);}#sbo-rt-content code.number,#sbo-rt-content .brown{color:rgb(165,42,42);}#sbo-rt-content code.operator,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.preCondit,#sbo-rt-content .teal{color:rgb(0,128,128);}#sbo-rt-content code.preProc,#sbo-rt-content .fuschia{color:rgb(255,0,255);}#sbo-rt-content code.repeat,#sbo-rt-content .indigo{color:rgb(75,0,130);}#sbo-rt-content code.special,#sbo-rt-content .saddlebrown{color:rgb(139,69,19);}#sbo-rt-content code.specialchar,#sbo-rt-content .magenta{color:rgb(255,0,255);}#sbo-rt-content code.specialcomment,#sbo-rt-content .seagreen{color:rgb(46,139,87);}#sbo-rt-content code.statement,#sbo-rt-content .forestgreen{color:rgb(34,139,34);}#sbo-rt-content code.storageclass,#sbo-rt-content .plum{color:rgb(221,160,221);}#sbo-rt-content code.string,#sbo-rt-content .darkred{color:rgb(139,0,0);}#sbo-rt-content code.structure,#sbo-rt-content .chocolate{color:rgb(210,106,30);}#sbo-rt-content code.tag,#sbo-rt-content .darkcyan{color:rgb(0,139,139);}#sbo-rt-content code.todo,#sbo-rt-content .black{color:#000;}#sbo-rt-content code.type,#sbo-rt-content .mediumslateblue{color:rgb(123,104,238);}#sbo-rt-content code.typedef,#sbo-rt-content .darkgreen{color:rgb(0,100,0);}#sbo-rt-content code.underlined{text-decoration:underline;}#sbo-rt-content pre code.hll{background-color:#ffc}#sbo-rt-content pre code.c{color:#09F;font-style:italic}#sbo-rt-content pre code.err{color:#A00}#sbo-rt-content pre code.k{color:#069;font-weight:bold}#sbo-rt-content pre code.o{color:#555}#sbo-rt-content pre code.cm{color:#35586C;font-style:italic}#sbo-rt-content pre code.cp{color:#099}#sbo-rt-content pre code.c1{color:#35586C;font-style:italic}#sbo-rt-content pre code.cs{color:#35586C;font-weight:bold;font-style:italic}#sbo-rt-content pre code.gd{background-color:#FCC}#sbo-rt-content pre code.ge{font-style:italic}#sbo-rt-content pre code.gr{color:#F00}#sbo-rt-content pre code.gh{color:#030;font-weight:bold}#sbo-rt-content pre code.gi{background-color:#CFC}#sbo-rt-content pre code.go{color:#000}#sbo-rt-content pre code.gp{color:#009;font-weight:bold}#sbo-rt-content pre code.gs{font-weight:bold}#sbo-rt-content pre code.gu{color:#030;font-weight:bold}#sbo-rt-content pre code.gt{color:#9C6}#sbo-rt-content pre code.kc{color:#069;font-weight:bold}#sbo-rt-content pre code.kd{color:#069;font-weight:bold}#sbo-rt-content pre code.kn{color:#069;font-weight:bold}#sbo-rt-content pre code.kp{color:#069}#sbo-rt-content pre code.kr{color:#069;font-weight:bold}#sbo-rt-content pre code.kt{color:#078;font-weight:bold}#sbo-rt-content pre code.m{color:#F60}#sbo-rt-content pre code.s{color:#C30}#sbo-rt-content pre code.na{color:#309}#sbo-rt-content pre code.nb{color:#366}#sbo-rt-content pre code.nc{color:#0A8;font-weight:bold}#sbo-rt-content pre code.no{color:#360}#sbo-rt-content pre code.nd{color:#99F}#sbo-rt-content pre code.ni{color:#999;font-weight:bold}#sbo-rt-content pre code.ne{color:#C00;font-weight:bold}#sbo-rt-content pre code.nf{color:#C0F}#sbo-rt-content pre code.nl{color:#99F}#sbo-rt-content pre code.nn{color:#0CF;font-weight:bold}#sbo-rt-content pre code.nt{color:#309;font-weight:bold}#sbo-rt-content pre code.nv{color:#033}#sbo-rt-content pre code.ow{color:#000;font-weight:bold}#sbo-rt-content pre code.w{color:#bbb}#sbo-rt-content pre code.mf{color:#F60}#sbo-rt-content pre code.mh{color:#F60}#sbo-rt-content pre code.mi{color:#F60}#sbo-rt-content pre code.mo{color:#F60}#sbo-rt-content pre code.sb{color:#C30}#sbo-rt-content pre code.sc{color:#C30}#sbo-rt-content pre code.sd{color:#C30;font-style:italic}#sbo-rt-content pre code.s2{color:#C30}#sbo-rt-content pre code.se{color:#C30;font-weight:bold}#sbo-rt-content pre code.sh{color:#C30}#sbo-rt-content pre code.si{color:#A00}#sbo-rt-content pre code.sx{color:#C30}#sbo-rt-content pre code.sr{color:#3AA}#sbo-rt-content pre code.s1{color:#C30}#sbo-rt-content pre code.ss{color:#A60}#sbo-rt-content pre code.bp{color:#366}#sbo-rt-content pre code.vc{color:#033}#sbo-rt-content pre code.vg{color:#033}#sbo-rt-content pre code.vi{color:#033}#sbo-rt-content pre code.il{color:#F60}#sbo-rt-content pre code.g{color:#050}#sbo-rt-content pre code.l{color:#C60}#sbo-rt-content pre code.l{color:#F90}#sbo-rt-content pre code.n{color:#008}#sbo-rt-content pre code.nx{color:#008}#sbo-rt-content pre code.py{color:#96F}#sbo-rt-content pre code.p{color:#000}#sbo-rt-content pre code.x{color:#F06}#sbo-rt-content div.blockquote_sampler_toc{width:95%;margin:5px 5px 5px 10px !important}#sbo-rt-content div{font-family:serif;text-align:left}#sbo-rt-content .gray-background,#sbo-rt-content .reverse-video{background:#2E2E2E;color:#FFF}#sbo-rt-content .light-gray-background{background:#A0A0A0}#sbo-rt-content .preserve-whitespace{white-space:pre-wrap}#sbo-rt-content span.gray{color:#4C4C4C}#sbo-rt-content .width-10{width:10vw !important}#sbo-rt-content .width-20{width:20vw !important}#sbo-rt-content .width-30{width:30vw !important}#sbo-rt-content .width-40{width:40vw !important}#sbo-rt-content .width-50{width:50vw !important}#sbo-rt-content .width-60{width:60vw !important}#sbo-rt-content .width-70{width:70vw !important}#sbo-rt-content .width-80{width:80vw !important}#sbo-rt-content .width-90{width:90vw !important}#sbo-rt-content .width-full,#sbo-rt-content .width-100{width:100vw !important}#sbo-rt-content div[data-type="equation"].fifty-percent img{width:50%}</style><script> // <![CDATA[
    var g = {
      position_cache: {
        
          "chapter": "/api/v1/book/9781492032632/chapter/part01.html",
          "book_id": "9781492032632",
          "chapter_uri": "part01.html",
          "position": 100.0,
          "user_uuid": "d59baa21-c0cd-4fcf-9c68-a2b8d4f52a79",
          "next_chapter_uri": "/library/view/hands-on-machine-learning/9781492032632/ch01.html"
        
      },
      title: "Hands\u002Don Machine Learning with Scikit\u002DLearn, Keras, and TensorFlow, 2nd Edition",
      author_list: "Aurélien Géron",
      format: "book",
      source: "application/epub+zip",
      is_system_book: true,
      is_public: false,
      loaded_from_server: true,
      allow_scripts: false,
      has_mathml: true
    };
    // ]]></script><script src="./Chapter12_files/modernizr.8e35451ddb64.js.download"></script><script>
    
      

      
        
          window.PUBLIC_ANNOTATIONS = true;
        
      

      window.MOBILE_PUBLIC_ANNOTATIONS = false;

    

    
      window.PRIVACY_CONTROL_OVERRIDE = false;
    

      window.PRIVACY_CONTROL_SWITCH = true;

      window.PUBLISHER_PAGES = true;

      window.SBO = {
        "constants": {
          "SITB_ENDPOINT": "/api/v2/sitb/",
          "SEARCH_SELECT_ENDPOINT": "https://learning.oreilly.com/api/v2/search/select/",
          "ENABLE_ONLINE_TRAINING": false
        }
      };
  </script><link rel="canonical" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/part01.html"><meta name="description" content=" Part I. The Fundamentals of Machine Learning "><meta property="og:title" content="I. The Fundamentals of Machine Learning"><meta itemprop="isPartOf" content="/library/view/hands-on-machine-learning/9781492032632/"><meta itemprop="name" content="I. The Fundamentals of Machine Learning"><meta property="og:url" itemprop="url" content="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/part01.html"><meta property="og:site_name" content="Safari"><meta property="og:image" itemprop="thumbnailUrl" content="https://learning.oreilly.com/library/cover/9781492032632/"><meta property="og:description" itemprop="description" content=" Part I. The Fundamentals of Machine Learning "><meta itemprop="inLanguage" content="en"><meta itemprop="publisher" content="O&#39;Reilly Media, Inc."><meta property="og:type" content="book"><meta property="og:book:isbn" itemprop="isbn" content="9781492032649"><meta property="og:book:author" itemprop="author" content="Aurélien Géron"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@safari"><style type="text/css" id="font-styles" data-template="#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-size: &lt;%= font_size %&gt; !important; }"></style><style type="text/css" id="font-family" data-template="#sbo-rt-content, #sbo-rt-content p, #sbo-rt-content div { font-family: &lt;%= font_family %&gt; !important; }"></style><style type="text/css" id="column-width" data-template="#sbo-rt-content { max-width: &lt;%= column_width %&gt;% !important; margin: 0 auto !important; }"></style><noscript><meta http-equiv="refresh" content="0; url=/library/no-js/" /></noscript><script type="text/javascript">
    (function(i,s,o,g,r,a,m) {
      i['GoogleAnalyticsObject']=r;
      i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();
      a=s.createElement(o),m=s.getElementsByTagName(o)[0];
      a.async=1;
      a.src=g;
      m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    var matches = document.cookie.match(/BrowserCookie\s*=\s*([a-f0-9\-]{36})/),
      user_uuid = null;

    if (matches && matches.length === 2) {
      user_uuid = matches[1];
    }

  
    ga('create', 'UA-39299553-7', {'userId': 'd59baa21-c0cd-4fcf-9c68-a2b8d4f52a79' });
  

  
    
      ga('set', 'dimension1', 'B2B');
    
  

  ga('set', 'dimension6', user_uuid);

  
    ga('set', 'dimension2', 'd59baa21-c0cd-4fcf-9c68-a2b8d4f52a79');
    
      ga('set', 'dimension7', '0012M0000229keZQAQ');
    
  

  

  

  //enable enhanced link tracking
  ga('require', 'linkid', 'linkid.js');

  // reading interface will track pageviews itself
  if (document.location.pathname.indexOf("/library/view") !== 0) {
    ga('send', 'pageview');
  }
  </script><script>
    var dataLayer = window.dataLayer || [];

    
      window.medalliaVsgUserIdentifier = 'd59baa21-c0cd-4fcf-9c68-a2b8d4f52a79';
      dataLayer.push({userIdentifier: 'd59baa21-c0cd-4fcf-9c68-a2b8d4f52a79'});
      dataLayer.push({loggedIn: 'yes'});

      
        window.medalliaVsgAccountIdentifier = '21bed0a7-6b7b-470c-8fa0-40a52db0b491';
        
        dataLayer.push({orgID: '21bed0a7-6b7b-470c-8fa0-40a52db0b491'});
        

        window.medalliaVsgIsIndividual = false;
        
          
          dataLayer.push({learningAccountType: 'enterprise'});
          
        

        
          dataLayer.push({learningPaidAccount: 'yes'});
        
      
    

    (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    '//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-5P4V6Z');
    (function () {
      var VERSION = 'V1.1';
      var AUTHOR = 'Awwad';
      if (!window.GtmHelper)
        window.GtmHelper = function () {
          var instance = this;
          var loc = document.location;
          this.version = VERSION;
          this.author = AUTHOR;
          this.readCookie = function (name) {
            var nameEQ = name + "=";
            var ca = document.cookie.split(';');
            for (var i = 0; i < ca.length; i++) {
              var c = ca[i];
              while (c.charAt(0) == ' ') c = c.substring(1, c.length);
              if (c.indexOf(nameEQ) == 0) return c.substring(nameEQ.length, c.length);
            }
            return null;
          };
          this.createCookie = function (name, value, days, cookieDomain) {
            var domain = "";
            var expires = "";

            if (days) {
              var date = new Date();
              date.setTime(date.getTime() + Math.ceil(days * 24 * 60 * 60 * 1000));
              var expires = " expires=" + date.toGMTString() + ";";
            }

            if (typeof (cookieDomain) != 'undefined')
              domain = " domain=" + cookieDomain + "; ";

            document.cookie = name + "=" + value + ";" + expires + domain + "path=/";
          };

          this.isDuplicated = function (currentTransactionId) {
            // the previous transaction id:
            var previousTransIdValue = this.readCookie("previousTransId");

            if (currentTransactionId === previousTransIdValue) {
              return true; // Duplication
            } else {
              return false;
            }
          };
        }
    })()
  </script><script defer="" src="./Chapter12_files/vendor.a48a756c5182.js.download"></script><script defer="" src="./Chapter12_files/reader.f2a0c6bd2fee.js.download"></script><script src="./Chapter12_files/f(1).txt"></script><script src="./Chapter12_files/f(2).txt"></script><script src="./Chapter12_files/f(3).txt"></script><script src="./Chapter12_files/f(4).txt"></script><script async="" src="./Chapter12_files/MathJax.js.download"></script><style id="annotator-dynamic-style">.annotator-adder, .annotator-outer, .annotator-notice {
  z-index: 2147483020;
}
.annotator-filter {
  z-index: 2147483010;
}</style><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 2px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 2px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: 1em}
.MathJax_MenuRadioCheck.RTL {right: 1em; left: auto}
.MathJax_MenuLabel {padding: 2px 2em 4px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #CCCCCC; margin: 4px 1px 0px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: Highlight; color: HighlightText}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MathJax_Preview .MJXf-math {color: inherit!important}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
</style><script async="true" type="text/javascript" src="./Chapter12_files/roundtrip.js.download"></script><style type="text/css" id="kampyleStyle">.noOutline{outline: none !important;}.wcagOutline:focus{outline: 1px dashed #595959 !important;outline-offset: 2px !important;transition: none !important;}</style><script async="true" type="text/javascript" src="./Chapter12_files/roundtrip.js.download"></script><style type="text/css">.MathJax_Display {text-align: center; margin: 1em 0em; position: relative; display: block!important; text-indent: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; width: 100%}
.MathJax .merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MathJax .MJX-monospace {font-family: monospace}
.MathJax .MJX-sans-serif {font-family: sans-serif}
#MathJax_Tooltip {background-color: InfoBackground; color: InfoText; border: 1px solid black; box-shadow: 2px 2px 5px #AAAAAA; -webkit-box-shadow: 2px 2px 5px #AAAAAA; -moz-box-shadow: 2px 2px 5px #AAAAAA; -khtml-box-shadow: 2px 2px 5px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true'); padding: 3px 4px; z-index: 401; position: absolute; left: 0; top: 0; width: auto; height: auto; display: none}
.MathJax {display: inline; font-style: normal; font-weight: normal; line-height: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; padding: 0; margin: 0}
.MathJax:focus, body :focus .MathJax {display: inline-table}
.MathJax.MathJax_FullWidth {text-align: center; display: table-cell!important; width: 10000em!important}
.MathJax img, .MathJax nobr, .MathJax a {border: 0; padding: 0; margin: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; vertical-align: 0; line-height: normal; text-decoration: none}
img.MathJax_strut {border: 0!important; padding: 0!important; margin: 0!important; vertical-align: 0!important}
.MathJax span {display: inline; position: static; border: 0; padding: 0; margin: 0; vertical-align: 0; line-height: normal; text-decoration: none}
.MathJax nobr {white-space: nowrap!important}
.MathJax img {display: inline!important; float: none!important}
.MathJax * {transition: none; -webkit-transition: none; -moz-transition: none; -ms-transition: none; -o-transition: none}
.MathJax_Processing {visibility: hidden; position: fixed; width: 0; height: 0; overflow: hidden}
.MathJax_Processed {display: none!important}
.MathJax_ExBox {display: block!important; overflow: hidden; width: 1px; height: 60ex; min-height: 0; max-height: none}
.MathJax .MathJax_EmBox {display: block!important; overflow: hidden; width: 1px; height: 60em; min-height: 0; max-height: none}
.MathJax_LineBox {display: table!important}
.MathJax_LineBox span {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MathJax .MathJax_HitBox {cursor: text; background: white; opacity: 0; filter: alpha(opacity=0)}
.MathJax .MathJax_HitBox * {filter: none; opacity: 1; background: transparent}
#MathJax_Tooltip * {filter: none; opacity: 1; background: transparent}
@font-face {font-family: MathJax_Main; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf?V=2.7.1') format('opentype')}
@font-face {font-family: MathJax_Main-bold; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf?V=2.7.1') format('opentype')}
@font-face {font-family: MathJax_Main-italic; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf?V=2.7.1') format('opentype')}
@font-face {font-family: MathJax_Math-italic; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf?V=2.7.1') format('opentype')}
@font-face {font-family: MathJax_Caligraphic; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf?V=2.7.1') format('opentype')}
@font-face {font-family: MathJax_Size1; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf?V=2.7.1') format('opentype')}
@font-face {font-family: MathJax_Size2; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf?V=2.7.1') format('opentype')}
@font-face {font-family: MathJax_Size3; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf?V=2.7.1') format('opentype')}
@font-face {font-family: MathJax_Size4; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf?V=2.7.1') format('opentype')}
</style><style type="text/css">@font-face {font-family: MathJax_Math-bold-italic; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf?V=2.7.1') format('opentype')}
</style><style type="text/css">@font-face {font-family: MathJax_Script; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf?V=2.7.1') format('opentype')}
</style><style type="text/css">@font-face {font-family: MathJax_AMS; src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff?V=2.7.1') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf?V=2.7.1') format('opentype')}
</style></head>


<body class="reading sidenav  scalefonts library nav-collapsed"><div style="visibility: hidden; overflow: hidden; position: absolute; top: 0px; height: 1px; width: auto; padding: 0px; border: 0px; margin: 0px; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal;"><div id="MathJax_Hidden"></div></div><div id="MathJax_Message" style="display: none;"></div>

    
  <noscript> 
    <iframe src="//www.googletagmanager.com/ns.html?id=GTM-5P4V6Z"
            height="0" width="0"
            style="display:none;visibility:hidden">
    </iframe>
  </noscript>



    
      <div class="hide working" role="status">
        <div class="working-image"></div>
      </div>
      <div class="sbo-site-nav">
        





<a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#container" class="skip">Skip to content</a><header class="topbar t-topbar"><nav role="navigation" class="js-site-nav"><ul class="topnav"><li class="t-logo"><a href="https://learning.oreilly.com/home/" class="l0 None safari-home nav-icn js-keyboard-nav-home"><svg width="16" height="16" viewBox="0 0 16 16" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M11.738 14H9.254v-3.676a.617.617 0 0 0-.621-.613H7.39a.617.617 0 0 0-.62.613V14H4.284a.617.617 0 0 1-.622-.613V10.22c0-.327.132-.64.367-.87l3.547-3.493a.627.627 0 0 1 .875 0l3.54 3.499c.234.229.366.54.367.864v3.167a.617.617 0 0 1-.62.613zM7.57 2.181a.625.625 0 0 1 .882 0l5.77 5.692-.93.92-5.28-5.209-5.28 5.208-.932-.919 5.77-5.692z"></path></svg><span>Safari Home</span></a></li><li><a href="https://learning.oreilly.com/resource-centers/" class="t-resource-centers-nav l0 nav-icn"><!--?xml version="1.0" encoding="UTF-8"?--><svg width="16px" height="16px" viewBox="0 0 16 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><g id="Topic-Page-Design" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g id="Heron-Button" transform="translate(-20.000000, -78.000000)" fill="#4A3A30"><g id="Group-9" transform="translate(20.000000, 78.000000)"><rect id="Rectangle" x="9.6" y="0" width="6.4" height="6.4" rx="0.503118"></rect><rect id="Rectangle" x="9.6" y="9.6" width="6.4" height="6.4" rx="0.503118"></rect><rect id="Rectangle" x="0" y="9.6" width="6.4" height="6.4" rx="0.503118"></rect></g></g></g></svg><span>Resource Centers</span></a></li><li><a href="https://learning.oreilly.com/playlists/" class="t-queue-nav l0 nav-icn None"><!--?xml version="1.0" encoding="UTF-8"?--><svg width="21px" height="17px" viewBox="0 0 21 17" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><!-- Generator: Sketch 46.2 (44496) - http://www.bohemiancoding.com/sketch --><title>icon_Playlist_sml</title><desc>Created with Sketch.</desc><defs></defs><g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g id="icon_Playlist_sml" fill-rule="nonzero" fill="#000000"><g id="playlist-icon"><g id="Group-6"><rect id="Rectangle-path" x="5" y="0" width="16" height="3" rx="0.5"></rect><circle id="Oval" cx="1.5" cy="1.5" r="1.5"></circle></g><g id="Group-5" transform="translate(0.000000, 7.000000)"><circle id="Oval" cx="1.5" cy="1.5" r="1.5"></circle><rect id="Rectangle-path" x="5" y="0" width="16" height="3" rx="0.5"></rect></g><g id="Group-5-Copy" transform="translate(0.000000, 14.000000)"><circle id="Oval" cx="1.5" cy="1.5" r="1.5"></circle><rect id="Rectangle-path" x="5" y="0" width="16" height="3" rx="0.5"></rect></g></g></g></g></svg><span>
               Playlists
            </span></a></li><li class="search"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#" class="t-search-nav trigger nav-icn l0" data-dropdown-selector=".searchbox"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>search icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M31.3 0C20.9 0 12.5 8.4 12.5 18.8 12.5 22.5 13.6 25.9 15.4 28.8L1.2 42.9C-0.4 44.5-0.4 47.2 1.2 48.8 2 49.6 3.1 50 4.2 50 5.2 50 6.3 49.6 7.1 48.8L21.2 34.6C24.1 36.5 27.5 37.5 31.3 37.5 41.6 37.5 50 29.1 50 18.8 50 8.4 41.6 0 31.3 0ZM31.3 31.3C24.4 31.3 18.8 25.6 18.8 18.8 18.8 11.9 24.4 6.3 31.3 6.3 38.1 6.3 43.8 11.9 43.8 18.8 43.8 25.6 38.1 31.3 31.3 31.3Z"></path></g></svg><span>Search</span></a></li><li class="usermenu dropdown"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#" class="trigger l0 nav-icn nav-dropdown"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="20" height="20" version="1.1" fill="#4A3C31"><desc>navigation arrow</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M0.1 12.5L9.7 3.1C9.8 3 9.9 3 10 3 10.1 3 10.2 3 10.3 3.1L19.9 12.5C20 12.5 20 12.6 20 12.8 20 12.9 20 13 19.9 13L17 15.9C16.9 16 16.8 16 16.7 16 16.5 16 16.4 16 16.4 15.9L10 9.7 3.6 15.9C3.6 16 3.5 16 3.3 16 3.2 16 3.1 16 3 15.9L0.1 13C0 12.9 0 12.8 0 12.7 0 12.7 0 12.6 0.1 12.5Z"></path></g></svg><span>Expand Nav</span></a><div class="drop-content"><ul><li><a href="https://learning.oreilly.com/history/" class="t-recent-nav l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="20" height="20" version="1.1" fill="#4A3C31"><desc>recent items icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 0C11.2 0 0 11.2 0 25 0 38.8 11.2 50 25 50 38.8 50 50 38.8 50 25 50 11.2 38.8 0 25 0ZM6.3 25C6.3 14.6 14.6 6.3 25 6.3 35.4 6.3 43.8 14.6 43.8 25 43.8 35.4 35.4 43.8 25 43.8 14.6 43.8 6.3 35.4 6.3 25ZM31.8 31.5C32.5 30.5 32.4 29.2 31.6 28.3L27.1 23.8 27.1 12.8C27.1 11.5 26.2 10.4 25 10.4 23.9 10.4 22.9 11.5 22.9 12.8L22.9 25.7 28.8 31.7C29.2 32.1 29.7 32.3 30.2 32.3 30.8 32.3 31.3 32 31.8 31.5Z"></path></g></svg><span>History</span></a></li><li><a href="https://learning.oreilly.com/topics" class="t-topics-link l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 55" width="20" height="20" version="1.1" fill="#4A3C31"><desc>topics icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M25 55L50 41.262 50 13.762 25 0 0 13.762 0 41.262 25 55ZM8.333 37.032L8.333 17.968 25 8.462 41.667 17.968 41.667 37.032 25 46.538 8.333 37.032Z"></path></g></svg><span>Topics</span></a></li><li><a href="https://learning.oreilly.com/learning-paths/" class="l1 nav-icn t-learningpaths-nav js-toggle-menu-item"><!--?xml version="1.0" encoding="UTF-8"?--><svg width="32px" height="32px" viewBox="0 0 32 32" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><!-- Generator: Sketch 52.5 (67469) - http://www.bohemiancoding.com/sketch --><title>Mask</title><desc>Created with Sketch.</desc><g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><path d="M0,16.0214227 C0,15.0387209 0.796453294,14.2411658 1.77779753,14.2411658 C2.75914177,14.2411658 3.55559506,15.0387209 3.55559506,16.0214227 C3.55559506,17.0041246 2.75914177,17.8016797 1.77779753,17.8016797 C0.796453294,17.8016797 0,17.0041246 0,16.0214227 Z M9.77788642,5.22914885 C8.9280992,5.72049977 7.84008711,5.42853763 7.34941499,4.57757479 C6.85874287,3.72661195 7.15030167,2.63709467 8.00008889,2.14574375 C8.84987611,1.65439282 9.9378882,1.94635496 10.4285603,2.7973178 C10.9192324,3.64828064 10.6276736,4.73779792 9.77788642,5.22914885 Z M4.57213969,7.35869225 C5.42192691,7.85004318 5.71348571,8.93956046 5.22281359,9.79052329 C4.73214147,10.6414861 3.64412938,10.9334483 2.79434216,10.4420974 C1.94455494,9.95074642 1.65299614,8.86122915 2.14366826,8.01026631 C2.63434038,7.15930347 3.72235247,6.86734132 4.57213969,7.35869225 Z M2.79434216,21.6007481 C3.64412938,21.1093972 4.73214147,21.4013594 5.22281359,22.2523222 C5.71348571,23.103285 5.42192691,24.1928023 4.57213969,24.6841532 C3.72235247,25.1755042 2.63434038,24.883542 2.14366826,24.0325792 C1.65299614,23.1816163 1.94455494,22.0920991 2.79434216,21.6007481 Z M7.34941499,27.4652707 C7.84008711,26.6143079 8.9280992,26.3223457 9.77788642,26.8136966 C10.6276736,27.3050476 10.9192324,28.3945649 10.4285603,29.2455277 C9.9378882,30.0964905 8.84987611,30.3884527 8.00008889,29.8971017 C7.15030167,29.4057508 6.85874287,28.3162335 7.34941499,27.4652707 Z M18.7118524,11.3165596 C21.3074367,12.8173162 22.1963355,16.1392758 20.6976522,18.738451 C19.1989689,21.3358459 15.8815987,22.2259744 13.2860143,20.726998 C10.6922077,19.2262414 9.80330893,15.9042818 11.3002144,13.3051066 C12.7988978,10.7059314 16.116268,9.81580294 18.7118524,11.3165596 Z M26.7821642,27.8093944 L30.1315348,31.1633985 C30.3982044,31.4304371 30.2097579,31.8844026 29.8346426,31.8844026 L21.5945511,31.8844026 C21.1287681,31.8844026 20.751875,31.5069881 20.751875,31.0405608 L20.751875,22.7890697 C20.751875,22.4134355 21.2052134,22.2247282 21.4701052,22.4899865 L24.2843587,25.3081333 C26.8337204,23.0240636 28.4444049,19.7092251 28.4444049,16.0223129 C28.4444049,9.15052091 22.8621207,3.56051397 15.9998222,3.56051397 L15.9998222,0 C24.8230314,0 32,7.18689745 32,16.0223129 C32,20.6919269 29.9750886,24.8790914 26.7821642,27.8093944 Z" id="Mask" fill="#8B889A"></path></g></svg><span>Learning Paths</span></a></li><li class="nav-highlights"><a href="https://learning.oreilly.com/u/d59baa21-c0cd-4fcf-9c68-a2b8d4f52a79/" class="t-highlights-nav l1 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 35" width="20" height="20" fill="#4A3C31"><path d="M13.325 18.071H8.036c0-6.736 4.324-10.925 14.464-12.477V0C6.37 1.113 0 10.632 0 22.113 0 29.406 3.477 35 10.403 35c5.142 0 9.175-3.515 9.175-8.816 0-4.628-2.367-7.293-6.253-8.113zm27.5 0h-5.26c0-6.736 4.295-10.925 14.435-12.477V0C33.899 1.113 27.5 10.632 27.5 22.113 27.5 29.406 30.977 35 37.932 35c5.113 0 9.146-3.515 9.146-8.816 0-4.628-2.338-7.293-6.253-8.113z" fill-rule="evenodd"></path></svg><span>Highlights</span></a></li><li><a href="https://learning.oreilly.com/u/preferences/" class="t-settings-nav l1 js-settings nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 53" width="20" height="20" version="1.1" fill="#4A3C31"><desc>settings icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M44.6 29.6C44.7 28.6 44.8 27.5 44.8 26.5 44.8 25.5 44.7 24.4 44.6 23.4L49.6 19C50 18.8 50.1 18.3 49.9 17.9 48.9 14.7 47.1 11.7 44.9 9.1 44.6 8.8 44.2 8.7 43.8 8.8L37.4 11.1C35.8 9.8 34 8.7 32.1 8L30.9 1.4C30.8 0.9 30.4 0.6 30 0.5 26.7-0.2 23.3-0.2 20 0.5 19.6 0.6 19.2 0.9 19.1 1.4L17.9 8C16 8.7 14.1 9.8 12.6 11.1L6.2 8.8C5.8 8.7 5.4 8.8 5.1 9.1 2.9 11.7 1.1 14.7 0.1 17.9 -0.1 18.3 0 18.8 0.4 19L5.4 23.4C5.3 24.4 5.2 25.5 5.2 26.5 5.2 27.5 5.3 28.6 5.4 29.6L0.4 34C0 34.2-0.1 34.7 0.1 35.1 1.1 38.3 2.9 41.4 5.1 43.9 5.4 44.2 5.8 44.4 6.2 44.2L12.6 42C14.1 43.2 16 44.3 17.9 45L19.1 51.7C19.2 52.1 19.6 52.5 20 52.5 21.6 52.8 23.3 53 25 53 26.7 53 28.4 52.8 30 52.5 30.4 52.5 30.8 52.1 30.9 51.7L32.1 45C34 44.3 35.8 43.2 37.4 42L43.8 44.2C44.2 44.4 44.6 44.2 44.9 43.9 47.1 41.4 48.9 38.3 49.9 35.1 50.1 34.7 50 34.2 49.6 34L44.6 29.6ZM25 36.4C19.6 36.4 15.2 32 15.2 26.5 15.2 21 19.6 16.6 25 16.6 30.4 16.6 34.8 21 34.8 26.5 34.8 32 30.4 36.4 25 36.4Z"></path></g></svg><span>Settings</span></a></li><li><a href="https://www.oreilly.com/online-learning/support/" class="l1 no-icon">Support</a></li><li><a href="https://learning.oreilly.com/accounts/logout/" class="l1 no-icon">Sign Out</a></li></ul><ul class="profile"><li><a href="https://learning.oreilly.com/u/preferences/" class="l2 nav-icn None"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 53" width="20" height="20" version="1.1" fill="#4A3C31"><desc>settings icon</desc><g stroke="none" stroke-width="1" fill-rule="evenodd"><path d="M44.6 29.6C44.7 28.6 44.8 27.5 44.8 26.5 44.8 25.5 44.7 24.4 44.6 23.4L49.6 19C50 18.8 50.1 18.3 49.9 17.9 48.9 14.7 47.1 11.7 44.9 9.1 44.6 8.8 44.2 8.7 43.8 8.8L37.4 11.1C35.8 9.8 34 8.7 32.1 8L30.9 1.4C30.8 0.9 30.4 0.6 30 0.5 26.7-0.2 23.3-0.2 20 0.5 19.6 0.6 19.2 0.9 19.1 1.4L17.9 8C16 8.7 14.1 9.8 12.6 11.1L6.2 8.8C5.8 8.7 5.4 8.8 5.1 9.1 2.9 11.7 1.1 14.7 0.1 17.9 -0.1 18.3 0 18.8 0.4 19L5.4 23.4C5.3 24.4 5.2 25.5 5.2 26.5 5.2 27.5 5.3 28.6 5.4 29.6L0.4 34C0 34.2-0.1 34.7 0.1 35.1 1.1 38.3 2.9 41.4 5.1 43.9 5.4 44.2 5.8 44.4 6.2 44.2L12.6 42C14.1 43.2 16 44.3 17.9 45L19.1 51.7C19.2 52.1 19.6 52.5 20 52.5 21.6 52.8 23.3 53 25 53 26.7 53 28.4 52.8 30 52.5 30.4 52.5 30.8 52.1 30.9 51.7L32.1 45C34 44.3 35.8 43.2 37.4 42L43.8 44.2C44.2 44.4 44.6 44.2 44.9 43.9 47.1 41.4 48.9 38.3 49.9 35.1 50.1 34.7 50 34.2 49.6 34L44.6 29.6ZM25 36.4C19.6 36.4 15.2 32 15.2 26.5 15.2 21 19.6 16.6 25 16.6 30.4 16.6 34.8 21 34.8 26.5 34.8 32 30.4 36.4 25 36.4Z"></path></g></svg><span>Settings</span></a></li><li><a href="https://www.oreilly.com/online-learning/support/" class="l2">Support</a></li><li><a href="https://learning.oreilly.com/accounts/logout/" class="l2">Sign Out</a></li></ul></div></li></ul></nav></header>


      </div>
      <div id="container" class="application" style="height: auto;">
        
          <div class="nav-container clearfix">
            


            
            
          </div>

          

  <div class="js-toc">
    
      <div class="sbo-reading-menu sbo-menu-top"><section class="sbo-toc-container toc-menu"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#" class="sbo-toc-thumb"><span class="sbo-title ss-list"><h1><div class="visuallyhidden">Table of Contents for </div>
      
      Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition
      
    </h1></span></a><div class="toc-contents"></div></section></div>

    

    <div class="interface-controls interface-controls-top">
      <ul class="interface-control-btns js-bitlist js-reader">
        <li class="js-search-in-archive search-in-archive t-search-in-archive"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#" title="Search in archive" class="js-search-controls search-controls"><span class="icon">Search in book...</span></a><form class="search-archive-bar js-search-form"><input type="search" name="query" placeholder="Search inside this book..." autocomplete="off"></form><div class="search-archive-results"><div class="js-sitb-results-region"></div></div></li><li class="queue-control"><div class="js-content-uri" data-content-uri="/api/v1/book/9781492032632/chapter/part01.html"><div class="js-collections-dropdown collections-dropdown menu-bit-cards"><div data-reactroot="" class="menu-dropdown-wrapper js-menu-dropdown-wrapper align-right"><img class="hidden" src="./Chapter12_files/ajax-transp.gif" alt="loading spinner"><div class="menu-control"><div class="control "><div class="js-playlists-menu"><button class="js-playlist-icon"><svg class="icon-add-to-playlist-sml" viewBox="0 0 16 14" version="1.1" xmlns="http://www.w3.org/2000/svg"><g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g fill-rule="nonzero" fill="#000000"><g transform="translate(-1.000000, 0.000000)"><rect x="5" y="0" width="12" height="2"></rect><title>Playlists</title><path d="M4.5,14 C6.43299662,14 8,12.4329966 8,10.5 C8,8.56700338 6.43299662,7 4.5,7 C2.56700338,7 1,8.56700338 1,10.5 C1,12.4329966 2.56700338,14 4.5,14 Z M2.5,10 L4,10 L4,8.5 L5,8.5 L5,10 L6.5,10 L6.5,11 L5,11 L5,12.5 L4,12.5 L4,11 L2.5,11 L2.5,10 Z"></path><circle cx="2" cy="5" r="1"></circle><circle cx="1.94117647" cy="1" r="1"></circle><rect x="5" y="4" width="12" height="2"></rect><rect x="9" y="8" width="8" height="2"></rect><rect x="9" y="12" width="8" height="2"></rect></g></g></g></svg><div class="js-playlist-addto-label">Add&nbsp;To</div></button></div></div></div></div></div></div></li><li class="js-font-control-panel font-control-activator"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#" data-push-state="false" id="font-controls" title="Change font size" aria-label="Change font size"><span class="icon">Toggle Font Controls</span></a></li><li class="dropdown sharing-controls"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#" class="trigger" data-push-state="false" title="Share" aria-label="Share"><i class="fa fa-share"></i></a><ul class="social-sharing dropdown-menu"><li><a class="twitter share-button t-twitter" target="_blank" aria-label="Share this section on Twitter" title="Share this section on Twitter" href="https://twitter.com/share?url=https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/part01.html&amp;text=Hands-on%20Machine%20Learning%20with%20Scikit-Learn%2C%20Keras%2C%20and%20TensorFlow%2C%202nd%20Edition&amp;via=safari"><span>Twitter</span></a></li><li><a class="facebook share-button t-facebook" target="_blank" aria-label="Share this section on Facebook" title="Share this section on Facebook" href="https://www.facebook.com/sharer/sharer.php?u=https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/part01.html"><span>Facebook</span></a></li><li><a class="googleplus share-button t-googleplus" target="_blank" aria-label="Share this secton on Google Plus" title="Share this secton on Google Plus" href="https://plus.google.com/share?url=https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/part01.html"><span>Google Plus</span></a></li><li><a class="email share-button t-email" aria-label="Share this section via email" title="Share this section via email" href="mailto:?subject=Safari:%20I.%20The%20Fundamentals%20of%20Machine%20Learning&amp;body=https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/part01.html%0D%0Afrom%20Hands-on%20Machine%20Learning%20with%20Scikit-Learn%2C%20Keras%2C%20and%20TensorFlow%2C%202nd%20Edition%0D%0A"><span>Email</span></a></li></ul></li>
      </ul>
    </div>

    
    <section role="document">
	  <div class="t-sbo-prev sbo-prev sbo-nav-top">
  
    
      
        <a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch11.html" class="prev nav-link">
      
          <span aria-hidden="true" class="pagination-label t-prev-label">Prev</span>
          <span class="visuallyhidden">Previous Chapter</span>
          <div class="pagination-title t-prev-title">11. Training Deep Neural Networks</div>
        </a>
    
  
  </div>

  <div class="t-sbo-next sbo-next sbo-nav-top">
  
    
      
        <a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html" class="next nav-link">
      
          <span aria-hidden="true" class="pagination-label t-next-label">Next</span>
          <span class="visuallyhidden">Next Chapter</span>
          <div class="pagination-title t-next-title">13. Loading and Preprocessing Data with TensorFlow</div>
        </a>
    
  
  </div>



<div id="sbo-rt-content"><div class="annotator-wrapper"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 12. Custom Models and Training with TensorFlow"><div class="chapter" id="tensorflow_chapter">
<h1><span class="label">Chapter 12. </span>Custom Models and Training with TensorFlow</h1>


<p>Up until now, we’ve used only TensorFlow’s high-level API, tf.keras, but it already got us pretty far: we built various neural network architectures, including regression and classification nets, wide and deep nets, and self-normalizing nets, using all sorts of techniques, such as Batch Normalization, dropout, and learning rate schedules. In fact, 95% of the use cases you will encounter will not require anything else than tf.keras (and tf.data, see <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#data_chapter">Chapter&nbsp;13</a>). But now it’s time to dive deeper into TensorFlow and take a look at its lower-level <a href="https://homl.info/tf2api">Python API</a>. This will be useful when you need extra control to write custom loss functions, custom metrics, layers, models, initializers, regularizers, weight constraints, and more. You may even need to fully control the training loop itself, for example, to apply special transformations or constraints to the gradients (beyond just clipping them) or to use multiple optimizers for different parts of the network. We will cover all these cases in this chapter, then we will also look at how you can boost your custom models and training algorithms using TensorFlow’s automatic graph generation feature. But first, let’s take a quick tour of TensorFlow.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>TensorFlow&nbsp;2.0 (beta) was released in June 2019, making TensorFlow much easier to use. The first edition of this book used TF&nbsp;1, while this edition uses TF&nbsp;2.</p>
</div>






<section data-type="sect1" data-pdf-bookmark="A Quick Tour of TensorFlow"><div class="sect1" id="idm46263509702952">
<h1>A Quick Tour of TensorFlow</h1>

<p>As you know, <em>TensorFlow</em> is a powerful library for numerical computation, particularly well suited and fine-tuned for large-scale Machine Learning (but you could use it for anything else that requires heavy computations). It was developed by the Google Brain team, and it powers many of Google’s large-scale services, such as Google Cloud Speech, Google Photos, and Google Search. It was open sourced in November 2015, and it is now the most popular deep learning library (in terms of citations in papers, adoption in companies, stars on github, etc.). Countless projects use TensorFlow for all sorts of Machine Learning tasks, such as image classification, natural language processing (NLP), recommender systems, and time series forecasting.</p>

<p>So what does TensorFlow offer? Here’s a summary:</p>

<ul>
<li>
<p>Its core is very similar to NumPy, but with GPU support.</p>
</li>
<li>
<p>It supports distributed computing (across multiple devices and servers).</p>
</li>
<li>
<p>It includes a kind of just-in-time (JIT) compiler that allows it to optimize computations for speed and memory usage. It works by extracting the <em>computation graph</em> from a Python function, then optimizing it (e.g., by pruning unused nodes), and finally running it efficiently (e.g., by automatically running independent operations in parallel).</p>
</li>
<li>
<p>Computation graphs can be exported to a portable format, so you can train a TensorFlow model in one environment (e.g., using Python on Linux) and run it in another (e.g., using Java on an Android device).</p>
</li>
<li>
<p>It implements autodiff (see <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch10.html#ann_chapter">Chapter&nbsp;10</a> and <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/app04.html#autodiff_appendix">Appendix&nbsp;D</a>), and provides some excellent optimizers, such as RMSProp and Nadam (see <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch11.html#deep_chapter">Chapter&nbsp;11</a>), so you can easily minimize all sorts of loss functions.</p>
</li>
<li>
<p>TensorFlow offers many more features, built on top of these core features: the most important is of course tf.keras,<sup><a data-type="noteref" id="idm46263509690504-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#idm46263509690504" class="totri-footnote">1</a></sup> but it also has data loading and preprocessing ops (tf.data, tf.io, etc.), image processing ops (tf.image), signal processing ops (tf.signal), and more (see <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#tensorflow_api_diagram">Figure&nbsp;12-1</a> for an overview of TensorFlow’s Python API).</p>
</li>
</ul>

<figure><div id="tensorflow_api_diagram" class="figure">
<img src="./Chapter12_files/mls2_1201.png" alt="mls2 1201" width="1440" height="993" data-mfp-src="/library/view/hands-on-machine-learning/9781492032632/assets/mls2_1201.png">
<h6><span class="label">Figure 12-1. </span>TensorFlow’s Python API</h6>
</div></figure>
<div data-type="tip"><h6>Tip</h6>
<p>We will cover many of the packages and functions of the TensorFlow API, but it’s impossible to cover them all, so you should really take some time to browse through the API; you will find that it is quite rich and well documented.</p>
</div>

<p>At the lowest level, each TensorFlow operation is implemented using highly efficient C++ code.<sup><a data-type="noteref" id="idm46263509684072-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#idm46263509684072" class="totri-footnote">2</a></sup> Many operations (or <em>ops</em> for short) have multiple implementations called <em>kernels</em>: each kernel is dedicated to a specific device type, such as CPUs, GPUs, or even TPUs (<em>Tensor Processing Units</em>). As you may know, GPUs can dramatically speed up computations by splitting them into many smaller chunks and running them in parallel across many GPU threads. TPUs are even faster, as they are custom ASIC chips, built specifically for Deep Learning operations<sup><a data-type="noteref" id="idm46263509681576-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#idm46263509681576" class="totri-footnote">3</a></sup> (we will discuss how to use TensorFlow with GPUs or TPUs in <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch19.html#deployment_chapter">Chapter&nbsp;19</a>).</p>

<p>TensorFlow’s architecture is shown in <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#tensorflow_architecture_diagram">Figure&nbsp;12-2</a>. Most of the time your code will use the high level APIs (especially tf.keras and tf.data); but when you need more flexibility, you will use the lower-level Python API, handling tensors directly. Note that APIs for other languages are also available. In any case, TensorFlow’s execution engine will take care of running the operations efficiently, even across multiple devices and machines if you tell it to.</p>

<figure><div id="tensorflow_architecture_diagram" class="figure">
<img src="./Chapter12_files/mls2_1202.png" alt="mls2 1202" width="1440" height="785" data-mfp-src="/library/view/hands-on-machine-learning/9781492032632/assets/mls2_1202.png">
<h6><span class="label">Figure 12-2. </span>TensorFlow’s architecture</h6>
</div></figure>

<p>TensorFlow runs not only on Windows, Linux, and MacOS, but also on mobile devices (using <em>TensorFlow Lite</em>), including both iOS and Android (see <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch19.html#deployment_chapter">Chapter&nbsp;19</a>). If you do not want to use the Python API, there are C++, Java, Go, and Swift APIs. There is even a Javascript implementation called <em>TensorFlow.js</em> that makes it possible to run your models directly in your browser.</p>

<p>There’s more to TensorFlow than the library. TensorFlow is at the center of an extensive ecosystem of libraries. First, there’s TensorBoard for visualization (see <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch10.html#ann_chapter">Chapter&nbsp;10</a>). Next, there’s <a href="https://tensorflow.org/tfx">TensorFlow Extended (TFX)</a>, which is a set of libraries built by Google to productionize TensorFlow projects: it includes tools for data validation, preprocessing, model analysis, and serving (with TF Serving, see <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch19.html#deployment_chapter">Chapter&nbsp;19</a>). Google also launched <em>TensorFlow Hub</em>, a way to easily download and reuse pretrained neural networks. You can also get many neural network architectures, some of them pretrained, in TensorFlow’s <a href="https://github.com/tensorflow/models/">model garden</a>. Check out the <a href="https://www.tensorflow.org/resources">TensorFlow Resources</a>, and <a href="https://github.com/jtoy/awesome-tensorflow"><em class="hyperlink">https://github.com/jtoy/awesome-tensorflow</em></a> for more TensorFlow-based projects. You will find hundreds of TensorFlow projects on GitHub, so it is often easy to find existing code for whatever you are trying to do.</p>
<div data-type="tip"><h6>Tip</h6>
<p>More and more ML papers are released along with their implementation, and sometimes even with pretrained models. Check out <a href="https://paperswithcode.com/"><em class="hyperlink">https://paperswithcode.com/</em></a> to easily find them.</p>
</div>

<p>Last but not least, TensorFlow has a dedicated team of passionate and helpful developers, as well as a large community contributing to improving it. To ask technical questions, you should use <a href="http://stackoverflow.com/"><em class="hyperlink">http://stackoverflow.com/</em></a> and tag your question with <em>tensorflow</em> and <em>python</em>. You can file bugs and feature requests through GitHub. For general discussions, join the <a href="https://homl.info/41">Google group</a>.</p>

<p>OK, it’s time to start coding!</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Using TensorFlow like NumPy"><div class="sect1" id="idm46263509702328">
<h1>Using TensorFlow like NumPy</h1>

<p>TensorFlow’s API revolves around <em>tensors</em>, which flow from operation to operation, hence the name Tensor-Flow. A tensor is usually a multidimensional array (exactly like a NumPy <code>ndarray</code>), but it can also hold a scalar (a simple value, such as 42). These tensors will be important when we create custom cost functions, custom metrics, custom layers, and more, so let’s see how to create and manipulate them.</p>








<section data-type="sect2" data-pdf-bookmark="Tensors and Operations"><div class="sect2" id="idm46263509656856">
<h2>Tensors and Operations</h2>

<p>You can create a tensor with <code>tf.constant()</code>. For example, here is a tensor representing a matrix with two rows and three columns of floats:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">tf</code><code class="o">.</code><code class="n">constant</code><code class="p">([[</code><code class="mf">1.</code><code class="p">,</code> <code class="mf">2.</code><code class="p">,</code> <code class="mf">3.</code><code class="p">],</code> <code class="p">[</code><code class="mf">4.</code><code class="p">,</code> <code class="mf">5.</code><code class="p">,</code> <code class="mf">6.</code><code class="p">]])</code> <code class="c"># matrix</code>
<code class="go">&lt;tf.Tensor: id=0, shape=(2, 3), dtype=float32, numpy=</code>
<code class="go">array([[1., 2., 3.],</code>
<code class="go">       [4., 5., 6.]], dtype=float32)&gt;</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">tf</code><code class="o">.</code><code class="n">constant</code><code class="p">(</code><code class="mi">42</code><code class="p">)</code> <code class="c"># scalar</code>
<code class="go">&lt;tf.Tensor: id=1, shape=(), dtype=int32, numpy=42&gt;</code></pre>

<p>Just like an <code>ndarray</code>, a <code>tf.Tensor</code> has a shape and a data type (<code>dtype</code>):</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">t</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">constant</code><code class="p">([[</code><code class="mf">1.</code><code class="p">,</code> <code class="mf">2.</code><code class="p">,</code> <code class="mf">3.</code><code class="p">],</code> <code class="p">[</code><code class="mf">4.</code><code class="p">,</code> <code class="mf">5.</code><code class="p">,</code> <code class="mf">6.</code><code class="p">]])</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">t</code><code class="o">.</code><code class="n">shape</code>
<code class="go">TensorShape([2, 3])</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">t</code><code class="o">.</code><code class="n">dtype</code>
<code class="go">tf.float32</code></pre>

<p>Indexing works much like in NumPy:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">t</code><code class="p">[:,</code> <code class="mi">1</code><code class="p">:]</code>
<code class="go">&lt;tf.Tensor: id=5, shape=(2, 2), dtype=float32, numpy=</code>
<code class="go">array([[2., 3.],</code>
<code class="go">       [5., 6.]], dtype=float32)&gt;</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">t</code><code class="p">[</code><code class="o">...</code><code class="p">,</code> <code class="mi">1</code><code class="p">,</code> <code class="n">tf</code><code class="o">.</code><code class="n">newaxis</code><code class="p">]</code>
<code class="go">&lt;tf.Tensor: id=15, shape=(2, 1), dtype=float32, numpy=</code>
<code class="go">array([[2.],</code>
<code class="go">       [5.]], dtype=float32)&gt;</code></pre>

<p>Most importantly, all sorts of tensor operations are available:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">t</code> <code class="o">+</code> <code class="mi">10</code>
<code class="go">&lt;tf.Tensor: id=18, shape=(2, 3), dtype=float32, numpy=</code>
<code class="go">array([[11., 12., 13.],</code>
<code class="go">       [14., 15., 16.]], dtype=float32)&gt;</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">tf</code><code class="o">.</code><code class="n">square</code><code class="p">(</code><code class="n">t</code><code class="p">)</code>
<code class="go">&lt;tf.Tensor: id=20, shape=(2, 3), dtype=float32, numpy=</code>
<code class="go">array([[ 1.,  4.,  9.],</code>
<code class="go">       [16., 25., 36.]], dtype=float32)&gt;</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">t</code> <code class="err">@</code> <code class="n">tf</code><code class="o">.</code><code class="n">transpose</code><code class="p">(</code><code class="n">t</code><code class="p">)</code>
<code class="go">&lt;tf.Tensor: id=24, shape=(2, 2), dtype=float32, numpy=</code>
<code class="go">array([[14., 32.],</code>
<code class="go">       [32., 77.]], dtype=float32)&gt;</code></pre>

<p>Note that writing <code>t + 10</code> is equivalent to calling <code>tf.add(t, 10)</code> (indeed, Python calls the magic method <code>t.__add__(10)</code>, which just calls <code>tf.add(t, 10)</code>). Other operators like <code>-</code> and <code>*</code> are also supported. The <code>@</code> operator was added in Python 3.5, for matrix multiplication: it is equivalent to calling the <code>tf.matmul()</code> function.</p>

<p>You will find all the basic math operations you need (e.g., <code>tf.add()</code>, <code>tf.multiply()</code>, <code>tf.square()</code>, <code>tf.exp()</code>, <code>tf.sqrt()</code>…) and most operations that you can find in NumPy (e.g., <code>tf.reshape()</code>, <code>tf.squeeze()</code>, <code>tf.tile()</code>). Some functions have a different name than in NumPy, for example <code>tf.reduce_mean()</code>, <code>tf.reduce_sum()</code>, <code>tf.reduce_max()</code>, <code>tf.math.log()</code> are the equivalent of <code>np.mean()</code>, <code>np.sum()</code>, <code>np.max()</code> and <code>np.log()</code>. When the name differs, there is often a good reason for it: for example, in TensorFlow you must write <code>tf.transpose(t)</code>; you cannot just write <code>t.T</code> like in NumPy. The reason is that the <code>tf.transpose()</code> function does not do exactly the same thing as NumPy’s <code>T</code> attribute: in TensorFlow, a new tensor is created with its own copy of the transposed data, while in NumPy, <code>t.T</code> is just a transposed view on the same data. Similarly, the <code>tf.reduce_sum()</code> operation is named this way because its GPU kernel (i.e., GPU implementation) uses a reduce algorithm that does not guarantee the order in which the elements are added: because 32-bit floats have limited precision, the result may change ever so slightly every time you call this operation. The same is true of <code>tf.reduce_mean()</code> (but of course <code>tf.reduce_max()</code> is deterministic).</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Many functions and classes have aliases. For example, <code>tf.add()</code> and <code>tf.math.add()</code> are the same function. This allows TensorFlow to have concise names for the most common operations<sup><a data-type="noteref" id="idm46263509408760-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#idm46263509408760" class="totri-footnote">4</a></sup> while preserving well-organized packages.</p>
</div>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="idm46263509406760">
<h5>Keras’ Low-Level API</h5>
<p>The Keras API has its own low-level API, located in <code>keras.backend</code>. It includes functions like <code>square()</code>, <code>exp()</code>, and <code>sqrt()</code>. In tf.keras, these functions generally just call the corresponding TensorFlow operations. If you want to write code that will be portable to other Keras implementations, you should use these Keras functions. However, they only cover a subset of all functions available in TensorFlow, so in this book we will use the TensorFlow operations directly. Here is as simple example using <code>keras.backend</code>, which is commonly named <code>K</code> for short:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="kn">from</code> <code class="nn">tensorflow</code> <code class="kn">import</code> <code class="n">keras</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">K</code> <code class="o">=</code> <code class="n">keras</code><code class="o">.</code><code class="n">backend</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">K</code><code class="o">.</code><code class="n">square</code><code class="p">(</code><code class="n">K</code><code class="o">.</code><code class="n">transpose</code><code class="p">(</code><code class="n">t</code><code class="p">))</code> <code class="o">+</code> <code class="mi">10</code>
<code class="go">&lt;tf.Tensor: id=39, shape=(3, 2), dtype=float32, numpy=</code>
<code class="go">array([[11., 26.],</code>
<code class="go">       [14., 35.],</code>
<code class="go">       [19., 46.]], dtype=float32)&gt;</code></pre>
</div></aside>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Tensors and NumPy"><div class="sect2" id="idm46263509656232">
<h2>Tensors and NumPy</h2>

<p>Tensors play nice with NumPy: you can create a tensor from a NumPy array, and vice versa. You can even apply TensorFlow operations to NumPy arrays and NumPy operations to tensors:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">a</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">([</code><code class="mf">2.</code><code class="p">,</code> <code class="mf">4.</code><code class="p">,</code> <code class="mf">5.</code><code class="p">])</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">tf</code><code class="o">.</code><code class="n">constant</code><code class="p">(</code><code class="n">a</code><code class="p">)</code>
<code class="go">&lt;tf.Tensor: id=111, shape=(3,), dtype=float64, numpy=array([2., 4., 5.])&gt;</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">t</code><code class="o">.</code><code class="n">numpy</code><code class="p">()</code> <code class="c"># or np.array(t)</code>
<code class="go">array([[1., 2., 3.],</code>
<code class="go">       [4., 5., 6.]], dtype=float32)</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">tf</code><code class="o">.</code><code class="n">square</code><code class="p">(</code><code class="n">a</code><code class="p">)</code>
<code class="go">&lt;tf.Tensor: id=116, shape=(3,), dtype=float64, numpy=array([4., 16., 25.])&gt;</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">np</code><code class="o">.</code><code class="n">square</code><code class="p">(</code><code class="n">t</code><code class="p">)</code>
<code class="go">array([[ 1.,  4.,  9.],</code>
<code class="go">       [16., 25., 36.]], dtype=float32)</code></pre>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>Notice that NumPy uses 64-bit precision by default, while TensorFlow uses 32-bit. This is because 32-bit precision is generally more than enough for neural networks, plus it runs faster and uses less RAM. So when you create a tensor from a NumPy array, make sure to set <code>dtype=tf.float32</code>.</p>
</div>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Type Conversions"><div class="sect2" id="idm46263509277944">
<h2>Type Conversions</h2>

<p>Type conversions can significantly hurt performance, and they can easily go unnoticed when they are done automatically. To avoid this, TensorFlow does not perform any type conversions automatically: it just raises an exception if you try to execute an operation on tensors with incompatible types. For example, you cannot add a float tensor and an integer tensor, and you cannot even add a 32-bit float and a 64-bit float:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">tf</code><code class="o">.</code><code class="n">constant</code><code class="p">(</code><code class="mf">2.</code><code class="p">)</code> <code class="o">+</code> <code class="n">tf</code><code class="o">.</code><code class="n">constant</code><code class="p">(</code><code class="mi">40</code><code class="p">)</code>
<code class="go">Traceback[...]InvalidArgumentError[...]expected to be a float[...]</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">tf</code><code class="o">.</code><code class="n">constant</code><code class="p">(</code><code class="mf">2.</code><code class="p">)</code> <code class="o">+</code> <code class="n">tf</code><code class="o">.</code><code class="n">constant</code><code class="p">(</code><code class="mf">40.</code><code class="p">,</code> <code class="n">dtype</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">float64</code><code class="p">)</code>
<code class="go">Traceback[...]InvalidArgumentError[...]expected to be a double[...]</code></pre>

<p>This may be a bit annoying at first, but remember that it’s for a good cause! And of course you can use <code>tf.cast()</code> when you really need to convert types:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">t2</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">constant</code><code class="p">(</code><code class="mf">40.</code><code class="p">,</code> <code class="n">dtype</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">float64</code><code class="p">)</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">tf</code><code class="o">.</code><code class="n">constant</code><code class="p">(</code><code class="mf">2.0</code><code class="p">)</code> <code class="o">+</code> <code class="n">tf</code><code class="o">.</code><code class="n">cast</code><code class="p">(</code><code class="n">t2</code><code class="p">,</code> <code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">)</code>
<code class="go">&lt;tf.Tensor: id=136, shape=(), dtype=float32, numpy=42.0&gt;</code></pre>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Variables"><div class="sect2" id="idm46263509260520">
<h2>Variables</h2>

<p>The <code>tf.Tensor</code> values we’ve seen so far are immutable: you cannot modify them. However, the weights in a neural network need to be tweaked by backpropagation, and other parameters may also need to change over time (e.g., a momentum optimizer keeps track of past gradients). What we need is a <code>tf.Variable</code>:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">v</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">Variable</code><code class="p">([[</code><code class="mf">1.</code><code class="p">,</code> <code class="mf">2.</code><code class="p">,</code> <code class="mf">3.</code><code class="p">],</code> <code class="p">[</code><code class="mf">4.</code><code class="p">,</code> <code class="mf">5.</code><code class="p">,</code> <code class="mf">6.</code><code class="p">]])</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">v</code>
<code class="go">&lt;tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=</code>
<code class="go">array([[1., 2., 3.],</code>
<code class="go">       [4., 5., 6.]], dtype=float32)&gt;</code></pre>

<p>A <code>tf.Variable</code> acts much like a <code>tf.Tensor</code>: you can perform the same operations with it, it plays nicely with NumPy as well, and it is just as picky with types. But it can also be modified in place using the <code>assign()</code> method (or <code>assign_add()</code> or <code>assign_sub()</code>, which increment or decrement the variable by the given value). You can also modify individual cells (or slices), using the cell’s (or slice’s) <code>assign()</code> method (direct item assignment will not work), or by using the <code>scatter_update()</code> or <code>scatter_nd_update()</code> methods:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">v</code><code class="o">.</code><code class="n">assign</code><code class="p">(</code><code class="mi">2</code> <code class="o">*</code> <code class="n">v</code><code class="p">)</code>           <code class="c1"># =&gt; [[2., 4., 6.], [8., 10., 12.]]</code>
<code class="n">v</code><code class="p">[</code><code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">]</code><code class="o">.</code><code class="n">assign</code><code class="p">(</code><code class="mi">42</code><code class="p">)</code>        <code class="c1"># =&gt; [[2., 42., 6.], [8., 10., 12.]]</code>
<code class="n">v</code><code class="p">[:,</code> <code class="mi">2</code><code class="p">]</code><code class="o">.</code><code class="n">assign</code><code class="p">([</code><code class="mf">0.</code><code class="p">,</code> <code class="mf">1.</code><code class="p">])</code>  <code class="c1"># =&gt; [[2., 42., 0.], [8., 10., 1.]]</code>
<code class="n">v</code><code class="o">.</code><code class="n">scatter_nd_update</code><code class="p">(</code><code class="n">indices</code><code class="o">=</code><code class="p">[[</code><code class="mi">0</code><code class="p">,</code> <code class="mi">0</code><code class="p">],</code> <code class="p">[</code><code class="mi">1</code><code class="p">,</code> <code class="mi">2</code><code class="p">]],</code> <code class="n">updates</code><code class="o">=</code><code class="p">[</code><code class="mf">100.</code><code class="p">,</code> <code class="mf">200.</code><code class="p">])</code>
                          <code class="c1"># =&gt; [[100., 42., 0.], [8., 10., 200.]]</code></pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>In practice you will rarely have to create variables manually, since Keras provides an <code>add_weight()</code> method that will take care of it for you, as we will see. Moreover, model parameters will generally be updated directly by the optimizers, so you will rarely need to update variables manually.</p>
</div>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Other Data Structures"><div class="sect2" id="idm46263508981896">
<h2>Other Data Structures</h2>

<p>TensorFlow supports several other data structures, including the following (please see the notebook or <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/app06.html#structures_appendix">Appendix&nbsp;F</a> for more details):</p>
<dl>
<dt>Sparse tensors (<code>tf.SparseTensor</code>)</dt>
<dd>
<p>Efficiently represent tensors containing mostly 0s. The <code>tf.sparse</code> package contains operations for sparse tensors.</p>
</dd>
<dt>Tensor arrays (<code>tf.TensorArray</code>)</dt>
<dd>
<p>Are lists of tensors. They have a fixed size by default but can optionally be made dynamic. All tensors they contain must have the same shape and data type.</p>
</dd>
<dt>Ragged tensors (<code>tf.RaggedTensor</code>)</dt>
<dd>
<p>Represent static lists of lists of tensors, where every tensor has the same shape and data type. The <code>tf.ragged</code> package contains operations for ragged tensors.</p>
</dd>
<dt>String tensors</dt>
<dd>
<p>Are regular tensors of type <code>tf.string</code>. These represent byte strings, not Unicode strings, so if you create a string tensor using a Unicode string (e.g., a regular Python 3 string like <code>"café"</code>), then it will get encoded to UTF-8 automatically (e.g., <code>b"caf\xc3\xa9"</code>). Alternatively, you can represent Unicode strings using tensors of type <code>tf.int32</code>, where each item represents a Unicode codepoint (e.g., <code>[99,  97, 102, 233]</code>). The <code>tf.strings</code> package (with an <code>s</code>) contains ops for byte strings and Unicode strings (and to convert one into the other). It’s important to note that a <code>tf.string</code> is atomic, meaning that its length does not appear in the tensor’s shape. Once you convert it to a Unicode tensor (i.e., a tensor of type <code>tf.int32</code> holding Unicode codepoints), the length appears in the shape.</p>
</dd>
<dt>Sets</dt>
<dd>
<p>Are represented as regular tensors (or sparse tensors). For example, <code>tf.constant([[1, 2], [3, 4]])</code> represents the two sets {1, 2} and {3, 4}. More generally, each set is represented by a vector in the tensor’s last axis. You can manipulate sets using operations from the <code>tf.sets</code> package.</p>
</dd>
<dt>Queues (including First In, First Out [FIFO] queues [<code>FIFOQueue</code>])</dt>
<dd>
<p>Can prioritize some items (<code>PriorityQueue</code>), queues that shuffle their items (<code>RandomShuffleQueue</code>), and queues that can batch items of different shapes by padding (<code>PaddingFIFOQueue</code>). These classes are all in the <code>tf.queue</code> package.</p>
</dd>
</dl>

<p>With tensors, operations, variables, and various data structures at your disposal, you are now ready to customize your models and training algorithms!</p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Customizing Models and Training Algorithms"><div class="sect1" id="idm46263508960344">
<h1>Customizing Models and Training Algorithms</h1>

<p>Let’s start by creating a custom loss function, which is a simple and common use case.</p>








<section data-type="sect2" data-pdf-bookmark="Custom Loss Functions"><div class="sect2" id="idm46263508958376">
<h2>Custom Loss Functions</h2>

<p>Suppose you want to train a regression model, but your training set is a bit noisy. Of course, you start by trying to clean up your dataset by removing or fixing the outliers, but that turns out to be insufficient; the dataset is still noisy. Which loss function should you use? The mean squared error might penalize large errors too much and cause your model to be imprecise. The mean absolute error would not penalize outliers as much, but training might take a while to converge, and the trained model might not be very precise. This is probably a good time to use the Huber loss (introduced in <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch10.html#ann_chapter">Chapter&nbsp;10</a>) instead of the good old MSE. The Huber loss is not currently part of the official Keras API, but it is available in tf.keras (just use an instance of the <code>keras.losses.Huber</code> class). But let’s pretend it’s not there: implementing it is easy as pie! Just create a function that takes the labels and predictions as arguments, and use TensorFlow operations to compute every instance’s loss:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">huber_fn</code><code class="p">(</code><code class="n">y_true</code><code class="p">,</code> <code class="n">y_pred</code><code class="p">):</code>
    <code class="n">error</code> <code class="o">=</code> <code class="n">y_true</code> <code class="o">-</code> <code class="n">y_pred</code>
    <code class="n">is_small_error</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">abs</code><code class="p">(</code><code class="n">error</code><code class="p">)</code> <code class="o">&lt;</code> <code class="mi">1</code>
    <code class="n">squared_loss</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">square</code><code class="p">(</code><code class="n">error</code><code class="p">)</code> <code class="o">/</code> <code class="mi">2</code>
    <code class="n">linear_loss</code>  <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">abs</code><code class="p">(</code><code class="n">error</code><code class="p">)</code> <code class="o">-</code> <code class="mf">0.5</code>
    <code class="k">return</code> <code class="n">tf</code><code class="o">.</code><code class="n">where</code><code class="p">(</code><code class="n">is_small_error</code><code class="p">,</code> <code class="n">squared_loss</code><code class="p">,</code> <code class="n">linear_loss</code><code class="p">)</code></pre>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>For better performance, you should use a vectorized implementation, as in this example. Moreover, if you want to benefit from TensorFlow’s graph features, you should use only TensorFlow operations.</p>
</div>

<p>It is also preferable to return a tensor containing one loss per instance, rather than returning the mean loss. This way, Keras can apply class weights or sample weights when requested (see <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch10.html#ann_chapter">Chapter&nbsp;10</a>).</p>

<p>Next, you can just use this loss when you compile the Keras model, then train your model:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">model</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="n">loss</code><code class="o">=</code><code class="n">huber_fn</code><code class="p">,</code> <code class="n">optimizer</code><code class="o">=</code><code class="s2">"nadam"</code><code class="p">)</code>
<code class="n">model</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train</code><code class="p">,</code> <code class="n">y_train</code><code class="p">,</code> <code class="p">[</code><code class="o">...</code><code class="p">])</code></pre>

<p>And that’s it! For each batch during training, Keras will call the <code>huber_fn()</code> function to compute the loss and use it to perform a Gradient Descent step. Moreover, it will keep track of the total loss since the beginning of the epoch, and it will display the mean loss.</p>

<p>But what happens to this custom loss when we save the model?</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Saving and Loading Models That Contain Custom Components"><div class="sect2" id="idm46263508801864">
<h2>Saving and Loading Models That Contain Custom Components</h2>

<p>Saving a model containing a custom loss function works fine, as Keras saves the name of the function. Whenever you load it, you’ll need to provide a dictionary that maps the function name to the actual function. More generally, when you load a model containing custom objects, you need to map the names to the objects:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">model</code> <code class="o">=</code> <code class="n">keras</code><code class="o">.</code><code class="n">models</code><code class="o">.</code><code class="n">load_model</code><code class="p">(</code><code class="s2">"my_model_with_a_custom_loss.h5"</code><code class="p">,</code>
                                <code class="n">custom_objects</code><code class="o">=</code><code class="p">{</code><code class="s2">"huber_fn"</code><code class="p">:</code> <code class="n">huber_fn</code><code class="p">})</code></pre>

<p>With the current implementation, any error between -1 and 1 is considered “small.” But what if we want a different threshold? One solution is to create a function that creates a configured loss function:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">create_huber</code><code class="p">(</code><code class="n">threshold</code><code class="o">=</code><code class="mf">1.0</code><code class="p">):</code>
    <code class="k">def</code> <code class="nf">huber_fn</code><code class="p">(</code><code class="n">y_true</code><code class="p">,</code> <code class="n">y_pred</code><code class="p">):</code>
        <code class="n">error</code> <code class="o">=</code> <code class="n">y_true</code> <code class="o">-</code> <code class="n">y_pred</code>
        <code class="n">is_small_error</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">abs</code><code class="p">(</code><code class="n">error</code><code class="p">)</code> <code class="o">&lt;</code> <code class="n">threshold</code>
        <code class="n">squared_loss</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">square</code><code class="p">(</code><code class="n">error</code><code class="p">)</code> <code class="o">/</code> <code class="mi">2</code>
        <code class="n">linear_loss</code>  <code class="o">=</code> <code class="n">threshold</code> <code class="o">*</code> <code class="n">tf</code><code class="o">.</code><code class="n">abs</code><code class="p">(</code><code class="n">error</code><code class="p">)</code> <code class="o">-</code> <code class="n">threshold</code><code class="o">**</code><code class="mi">2</code> <code class="o">/</code> <code class="mi">2</code>
        <code class="k">return</code> <code class="n">tf</code><code class="o">.</code><code class="n">where</code><code class="p">(</code><code class="n">is_small_error</code><code class="p">,</code> <code class="n">squared_loss</code><code class="p">,</code> <code class="n">linear_loss</code><code class="p">)</code>
    <code class="k">return</code> <code class="n">huber_fn</code></pre>

<pre data-type="programlisting" data-code-language="python"><code class="n">model</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="n">loss</code><code class="o">=</code><code class="n">create_huber</code><code class="p">(</code><code class="mf">2.0</code><code class="p">),</code> <code class="n">optimizer</code><code class="o">=</code><code class="s2">"nadam"</code><code class="p">)</code></pre>

<p>Unfortunately, when you save the model, the <code>threshold</code> will not be saved. This means that you will have to specify the <code>threshold</code> value when loading the model (note that the name to use is <code>"huber_fn"</code>, which is the name of the function we gave Keras, not the name of the function that created it):</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">model</code> <code class="o">=</code> <code class="n">keras</code><code class="o">.</code><code class="n">models</code><code class="o">.</code><code class="n">load_model</code><code class="p">(</code><code class="s2">"my_model_with_a_custom_loss_threshold_2.h5"</code><code class="p">,</code>
                                <code class="n">custom_objects</code><code class="o">=</code><code class="p">{</code><code class="s2">"huber_fn"</code><code class="p">:</code> <code class="n">create_huber</code><code class="p">(</code><code class="mf">2.0</code><code class="p">)})</code></pre>

<p>You can solve this by creating a subclass of the <code>keras.losses.Loss</code> class, and then implementing its <code>get_config()</code> method:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">class</code> <code class="nc">HuberLoss</code><code class="p">(</code><code class="n">keras</code><code class="o">.</code><code class="n">losses</code><code class="o">.</code><code class="n">Loss</code><code class="p">):</code>
    <code class="k">def</code> <code class="nf-Magic">__init__</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">threshold</code><code class="o">=</code><code class="mf">1.0</code><code class="p">,</code> <code class="o">**</code><code class="n">kwargs</code><code class="p">):</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">threshold</code> <code class="o">=</code> <code class="n">threshold</code>
        <code class="nb">super</code><code class="p">()</code><code class="o">.</code><code class="nf-Magic">__init__</code><code class="p">(</code><code class="o">**</code><code class="n">kwargs</code><code class="p">)</code>
    <code class="k">def</code> <code class="nf">call</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">y_true</code><code class="p">,</code> <code class="n">y_pred</code><code class="p">):</code>
        <code class="n">error</code> <code class="o">=</code> <code class="n">y_true</code> <code class="o">-</code> <code class="n">y_pred</code>
        <code class="n">is_small_error</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">abs</code><code class="p">(</code><code class="n">error</code><code class="p">)</code> <code class="o">&lt;</code> <code class="bp">self</code><code class="o">.</code><code class="n">threshold</code>
        <code class="n">squared_loss</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">square</code><code class="p">(</code><code class="n">error</code><code class="p">)</code> <code class="o">/</code> <code class="mi">2</code>
        <code class="n">linear_loss</code>  <code class="o">=</code> <code class="bp">self</code><code class="o">.</code><code class="n">threshold</code> <code class="o">*</code> <code class="n">tf</code><code class="o">.</code><code class="n">abs</code><code class="p">(</code><code class="n">error</code><code class="p">)</code> <code class="o">-</code> <code class="bp">self</code><code class="o">.</code><code class="n">threshold</code><code class="o">**</code><code class="mi">2</code> <code class="o">/</code> <code class="mi">2</code>
        <code class="k">return</code> <code class="n">tf</code><code class="o">.</code><code class="n">where</code><code class="p">(</code><code class="n">is_small_error</code><code class="p">,</code> <code class="n">squared_loss</code><code class="p">,</code> <code class="n">linear_loss</code><code class="p">)</code>
    <code class="k">def</code> <code class="nf">get_config</code><code class="p">(</code><code class="bp">self</code><code class="p">):</code>
        <code class="n">base_config</code> <code class="o">=</code> <code class="nb">super</code><code class="p">()</code><code class="o">.</code><code class="n">get_config</code><code class="p">()</code>
        <code class="k">return</code> <code class="p">{</code><code class="o">**</code><code class="n">base_config</code><code class="p">,</code> <code class="s2">"threshold"</code><code class="p">:</code> <code class="bp">self</code><code class="o">.</code><code class="n">threshold</code><code class="p">}</code></pre>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>The Keras API currently only specifies how to use subclassing to define layers, models, callbacks, and regularizers. If you build other components (such as losses, metrics, initializers, or constraints) using subclassing, they may not be portable to other Keras implementations. It’s likely that the Keras API will be updated to specify subclassing for all these components as well.</p>
</div>

<p>Let’s walk through this code:</p>

<ul>
<li>
<p>The constructor accepts <code>**kwargs</code> and passes them to the parent constructor, which handles standard hyperparameters: the <code>name</code> of the loss and the <code>reduction</code> algorithm to use to aggregate the individual instance losses. By default, it is <code>"sum_over_batch_size"</code>, which means that the loss will be the sum of the instance losses, possibly weighted by the sample weights, if any, and will then divide the result by the batch size (not by the sum of weights, so this is <em>not</em> the weighted mean).<sup><a data-type="noteref" id="idm46263508450888-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#idm46263508450888" class="totri-footnote">5</a></sup> Other possible values are <code>"sum"</code> and <code>None</code>.</p>
</li>
<li>
<p>The <code>call()</code> method takes the labels and predictions, computes all the instance losses, and returns them.</p>
</li>
<li>
<p>The <code>get_config()</code> method returns a dictionary mapping each hyperparameter name to its value. It first calls the parent class’s <code>get_config()</code> method, then adds the new hyperparameters to this dictionary (note that the convenient <code>{**x}</code> syntax was added in Python 3.5).</p>
</li>
</ul>

<p>You can then use any instance of this class when you compile the model:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">model</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="n">loss</code><code class="o">=</code><code class="n">HuberLoss</code><code class="p">(</code><code class="mf">2.</code><code class="p">),</code> <code class="n">optimizer</code><code class="o">=</code><code class="s2">"nadam"</code><code class="p">)</code></pre>

<p>When you save the model, the threshold will be saved along with it; and when you load the model, you just need to map the class name to the class itself:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">model</code> <code class="o">=</code> <code class="n">keras</code><code class="o">.</code><code class="n">models</code><code class="o">.</code><code class="n">load_model</code><code class="p">(</code><code class="s2">"my_model_with_a_custom_loss_class.h5"</code><code class="p">,</code>
                                <code class="n">custom_objects</code><code class="o">=</code><code class="p">{</code><code class="s2">"HuberLoss"</code><code class="p">:</code> <code class="n">HuberLoss</code><code class="p">})</code></pre>

<p>When you save a model, Keras calls the loss instance’s <code>get_config()</code> method and saves the config as JSON in the HDF5 file. When you load the model, it calls the <code>from_config()</code> class method on the <code>HuberLoss</code> class: this method is implemented by the base class (<code>Loss</code>) and creates an instance of the class, passing <code>**config</code> to the constructor.</p>

<p>That’s it for losses! That wasn’t too hard, was it? Just as simple are custom activation functions, initializers, regularizers, and constraints. Let’s look at these now.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Custom Activation Functions, Initializers, Regularizers, and Constraints"><div class="sect2" id="idm46263508801272">
<h2>Custom Activation Functions, Initializers, Regularizers, and Constraints</h2>

<p>Most Keras functionalities, such as losses, regularizers, constraints, initializers, metrics, activation functions, layers, and even full models, can be customized in very much the same way. Most of the time, you will just need to write a simple function with the appropriate inputs and outputs. Here are examples of a custom activation function (equivalent to <code>keras.activations.softplus</code> or <code>tf.nn.softplus</code>), a custom Glorot initializer (equivalent to <code>keras.initializers.glorot_normal</code>), a custom ℓ<sub>1</sub> regularizer (equivalent to <code>keras.regularizers.l1(0.01)</code>) and a custom constraint that ensures weights are all positive (equivalent to <code>keras.constraints.nonneg()</code> or <code>tf.nn.relu</code>):</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">my_softplus</code><code class="p">(</code><code class="n">z</code><code class="p">):</code> <code class="c1"># return value is just tf.nn.softplus(z)</code>
    <code class="k">return</code> <code class="n">tf</code><code class="o">.</code><code class="n">math</code><code class="o">.</code><code class="n">log</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">exp</code><code class="p">(</code><code class="n">z</code><code class="p">)</code> <code class="o">+</code> <code class="mf">1.0</code><code class="p">)</code>

<code class="k">def</code> <code class="nf">my_glorot_initializer</code><code class="p">(</code><code class="n">shape</code><code class="p">,</code> <code class="n">dtype</code><code class="o">=</code><code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">):</code>
    <code class="n">stddev</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">sqrt</code><code class="p">(</code><code class="mf">2.</code> <code class="o">/</code> <code class="p">(</code><code class="n">shape</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code> <code class="o">+</code> <code class="n">shape</code><code class="p">[</code><code class="mi">1</code><code class="p">]))</code>
    <code class="k">return</code> <code class="n">tf</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">normal</code><code class="p">(</code><code class="n">shape</code><code class="p">,</code> <code class="n">stddev</code><code class="o">=</code><code class="n">stddev</code><code class="p">,</code> <code class="n">dtype</code><code class="o">=</code><code class="n">dtype</code><code class="p">)</code>

<code class="k">def</code> <code class="nf">my_l1_regularizer</code><code class="p">(</code><code class="n">weights</code><code class="p">):</code>
    <code class="k">return</code> <code class="n">tf</code><code class="o">.</code><code class="n">reduce_sum</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">abs</code><code class="p">(</code><code class="mf">0.01</code> <code class="o">*</code> <code class="n">weights</code><code class="p">))</code>

<code class="k">def</code> <code class="nf">my_positive_weights</code><code class="p">(</code><code class="n">weights</code><code class="p">):</code> <code class="c1"># return value is just tf.nn.relu(weights)</code>
    <code class="k">return</code> <code class="n">tf</code><code class="o">.</code><code class="n">where</code><code class="p">(</code><code class="n">weights</code> <code class="o">&lt;</code> <code class="mf">0.</code><code class="p">,</code> <code class="n">tf</code><code class="o">.</code><code class="n">zeros_like</code><code class="p">(</code><code class="n">weights</code><code class="p">),</code> <code class="n">weights</code><code class="p">)</code></pre>

<p>As you can see, the arguments depend on the type of custom function. These custom functions can then be used normally, for example:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">layer</code> <code class="o">=</code> <code class="n">keras</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">Dense</code><code class="p">(</code><code class="mi">30</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="n">my_softplus</code><code class="p">,</code>
                           <code class="n">kernel_initializer</code><code class="o">=</code><code class="n">my_glorot_initializer</code><code class="p">,</code>
                           <code class="n">kernel_regularizer</code><code class="o">=</code><code class="n">my_l1_regularizer</code><code class="p">,</code>
                           <code class="n">kernel_constraint</code><code class="o">=</code><code class="n">my_positive_weights</code><code class="p">)</code></pre>

<p>The activation function will be applied to the output of this <code>Dense</code> layer, and its result will be passed on to the next layer. The layer’s weights will be initialized using the value returned by the initializer. At each training step the weights will be passed to the regularization function to compute the regularization loss, which will be added to the main loss to get the final loss used for training. Finally, the constraint function will be called after each training step, and the layer’s weights will be replaced by the constrained weights.</p>

<p>If a function has some hyperparameters that need to be saved along with the model, then you will want to subclass the appropriate class, such as <code>keras.regularizers.Regularizer</code>, <code>keras.constraints.Constraint</code>, <code>keras.initializers.Initializer</code>, or <code>keras.layers.Layer</code> (for any layer, including activation functions). Much like we did for the custom loss, here is a simple class for ℓ<sub>1</sub> regularization, that saves its <code>factor</code> hyperparameter (this time we do not need to call the parent constructor or the <code>get_config()</code> method, as they are not defined by the parent class):</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">class</code> <code class="nc">MyL1Regularizer</code><code class="p">(</code><code class="n">keras</code><code class="o">.</code><code class="n">regularizers</code><code class="o">.</code><code class="n">Regularizer</code><code class="p">):</code>
    <code class="k">def</code> <code class="nf-Magic">__init__</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">factor</code><code class="p">):</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">factor</code> <code class="o">=</code> <code class="n">factor</code>
    <code class="k">def</code> <code class="nf-Magic">__call__</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">weights</code><code class="p">):</code>
        <code class="k">return</code> <code class="n">tf</code><code class="o">.</code><code class="n">reduce_sum</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">abs</code><code class="p">(</code><code class="bp">self</code><code class="o">.</code><code class="n">factor</code> <code class="o">*</code> <code class="n">weights</code><code class="p">))</code>
    <code class="k">def</code> <code class="nf">get_config</code><code class="p">(</code><code class="bp">self</code><code class="p">):</code>
        <code class="k">return</code> <code class="p">{</code><code class="s2">"factor"</code><code class="p">:</code> <code class="bp">self</code><code class="o">.</code><code class="n">factor</code><code class="p">}</code></pre>

<p>Note that you must implement the <code>call()</code> method for losses, layers (including activation functions), and models, or the <code>__call__()</code> method for regularizers, initializers, and constraints. For metrics, things are a bit different, as we will see now.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Custom Metrics"><div class="sect2" id="idm46263507793128">
<h2>Custom Metrics</h2>

<p>Losses and metrics are conceptually not the same thing: losses are used by Gradient Descent to <em>train</em> a model, so they must be differentiable (at least where they are evaluated), and their gradients should not be 0 everywhere. Plus, it’s OK if they are not easily interpretable by humans (e.g., cross-entropy). In contrast, metrics are used to <em>evaluate</em> a model: they must be more easily interpretable, and they can be non-differentiable or have 0 gradients everywhere (e.g., accuracy).</p>

<p>That said, in most cases, defining a custom metric function is exactly the same as defining a custom loss function. In fact, we could even use the Huber loss function we created earlier as a metric;<sup><a data-type="noteref" id="idm46263507789496-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#idm46263507789496" class="totri-footnote">6</a></sup> it would work just fine (and persistence would also work the same way, in this case only saving the name of the function, <code>"huber_fn"</code>):</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">model</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="n">loss</code><code class="o">=</code><code class="s2">"mse"</code><code class="p">,</code> <code class="n">optimizer</code><code class="o">=</code><code class="s2">"nadam"</code><code class="p">,</code> <code class="n">metrics</code><code class="o">=</code><code class="p">[</code><code class="n">create_huber</code><code class="p">(</code><code class="mf">2.0</code><code class="p">)])</code></pre>

<p>For each batch during training, Keras will compute this metric and keep track of its mean since the beginning of the epoch. Most of the time, this is exactly what you want. But not always! Consider a binary classifier’s precision, for example. As we saw in <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch03.html#classification_chapter">Chapter&nbsp;3</a>, precision is the number of true positives divided by the number of positive predictions (including both true positives and false positives). Suppose the model made five positive predictions in the first batch, four of which were correct: that’s 80% precision. Then suppose the model made three positive predictions in the second batch, but they were all incorrect: that’s 0% precision for the second batch. If you just compute the mean of these two precisions, you get 40%. But wait a second, this is <em>not</em> the model’s precision over these two batches! Indeed, there were a total of four true positives (4 + 0) out of eight positive predictions (5 + 3), so the overall precision is 50%, not 40%. What we need is an object that can keep track of the number of true positives and the number of false positives and that can compute their ratio when requested. This is precisely what the <code>keras.metrics.Precision</code> class does:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">precision</code> <code class="o">=</code> <code class="n">keras</code><code class="o">.</code><code class="n">metrics</code><code class="o">.</code><code class="n">Precision</code><code class="p">()</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">precision</code><code class="p">([</code><code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">,</code> <code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">,</code> <code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">],</code> <code class="p">[</code><code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">,</code> <code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">,</code> <code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">,</code> <code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">])</code>
<code class="go">&lt;tf.Tensor: id=581729, shape=(), dtype=float32, numpy=0.8&gt;</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">precision</code><code class="p">([</code><code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">,</code> <code class="mi">0</code><code class="p">,</code> <code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">,</code> <code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">],</code> <code class="p">[</code><code class="mi">1</code><code class="p">,</code> <code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">,</code> <code class="mi">0</code><code class="p">,</code> <code class="mi">0</code><code class="p">,</code> <code class="mi">0</code><code class="p">,</code> <code class="mi">0</code><code class="p">])</code>
<code class="go">&lt;tf.Tensor: id=581780, shape=(), dtype=float32, numpy=0.5&gt;</code></pre>

<p>In this example, we created a <code>Precision</code> object, then we used it like a function, passing it the labels and predictions for the first batch, then for the second batch (note that we could also have passed sample weights). We used the same number of true and false positives as in the example we just discussed. After the first batch, it returns the precision of 80%; then after the second batch, it returns 50% (which is the overall precision so far, not the second batch’s precision). This is called a <em>streaming metric</em> (or <em>stateful metric</em>), as it is gradually updated, batch after batch.</p>

<p>At any point, we can call the <code>result()</code> method to get the current value of the metric. We can also look at its variables (tracking the number of true and false positives) by using the <code>variables</code> attribute, and we can reset these variables using the <code>reset_states()</code> method:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">p</code><code class="o">.</code><code class="n">result</code><code class="p">()</code>
<code class="go">&lt;tf.Tensor: id=581794, shape=(), dtype=float32, numpy=0.5&gt;</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">p</code><code class="o">.</code><code class="n">variables</code>
<code class="go">[&lt;tf.Variable 'true_positives:0' [...] numpy=array([4.], dtype=float32)&gt;,</code>
<code class="go"> &lt;tf.Variable 'false_positives:0' [...] numpy=array([4.], dtype=float32)&gt;]</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">p</code><code class="o">.</code><code class="n">reset_states</code><code class="p">()</code> <code class="c"># both variables get reset to 0.0</code></pre>

<p>If you need to create such a streaming metric, create a subclass of the <code>keras.metrics.Metric</code> class. Here is a simple example that keeps track of the total Huber loss and the number of instances seen so far. When asked for the result, it returns the ratio, which is simply the mean Huber loss:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">class</code> <code class="nc">HuberMetric</code><code class="p">(</code><code class="n">keras</code><code class="o">.</code><code class="n">metrics</code><code class="o">.</code><code class="n">Metric</code><code class="p">):</code>
    <code class="k">def</code> <code class="nf-Magic">__init__</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">threshold</code><code class="o">=</code><code class="mf">1.0</code><code class="p">,</code> <code class="o">**</code><code class="n">kwargs</code><code class="p">):</code>
        <code class="nb">super</code><code class="p">()</code><code class="o">.</code><code class="nf-Magic">__init__</code><code class="p">(</code><code class="o">**</code><code class="n">kwargs</code><code class="p">)</code> <code class="c1"># handles base args (e.g., dtype)</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">threshold</code> <code class="o">=</code> <code class="n">threshold</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">huber_fn</code> <code class="o">=</code> <code class="n">create_huber</code><code class="p">(</code><code class="n">threshold</code><code class="p">)</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">total</code> <code class="o">=</code> <code class="bp">self</code><code class="o">.</code><code class="n">add_weight</code><code class="p">(</code><code class="s2">"total"</code><code class="p">,</code> <code class="n">initializer</code><code class="o">=</code><code class="s2">"zeros"</code><code class="p">)</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">count</code> <code class="o">=</code> <code class="bp">self</code><code class="o">.</code><code class="n">add_weight</code><code class="p">(</code><code class="s2">"count"</code><code class="p">,</code> <code class="n">initializer</code><code class="o">=</code><code class="s2">"zeros"</code><code class="p">)</code>
    <code class="k">def</code> <code class="nf">update_state</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">y_true</code><code class="p">,</code> <code class="n">y_pred</code><code class="p">,</code> <code class="n">sample_weight</code><code class="o">=</code><code class="bp">None</code><code class="p">):</code>
        <code class="n">metric</code> <code class="o">=</code> <code class="bp">self</code><code class="o">.</code><code class="n">huber_fn</code><code class="p">(</code><code class="n">y_true</code><code class="p">,</code> <code class="n">y_pred</code><code class="p">)</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">total</code><code class="o">.</code><code class="n">assign_add</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">reduce_sum</code><code class="p">(</code><code class="n">metric</code><code class="p">))</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">count</code><code class="o">.</code><code class="n">assign_add</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">cast</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">size</code><code class="p">(</code><code class="n">y_true</code><code class="p">),</code> <code class="n">tf</code><code class="o">.</code><code class="n">float32</code><code class="p">))</code>
    <code class="k">def</code> <code class="nf">result</code><code class="p">(</code><code class="bp">self</code><code class="p">):</code>
        <code class="k">return</code> <code class="bp">self</code><code class="o">.</code><code class="n">total</code> <code class="o">/</code> <code class="bp">self</code><code class="o">.</code><code class="n">count</code>
    <code class="k">def</code> <code class="nf">get_config</code><code class="p">(</code><code class="bp">self</code><code class="p">):</code>
        <code class="n">base_config</code> <code class="o">=</code> <code class="nb">super</code><code class="p">()</code><code class="o">.</code><code class="n">get_config</code><code class="p">()</code>
        <code class="k">return</code> <code class="p">{</code><code class="o">**</code><code class="n">base_config</code><code class="p">,</code> <code class="s2">"threshold"</code><code class="p">:</code> <code class="bp">self</code><code class="o">.</code><code class="n">threshold</code><code class="p">}</code></pre>

<p>Let’s walk through this code:<sup><a data-type="noteref" id="idm46263507600632-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#idm46263507600632" class="totri-footnote">7</a></sup></p>

<ul>
<li>
<p>The constructor uses the <code>add_weight()</code> method to create the variables needed to keep track of the metric’s state over multiple batches, in this case the sum of all Huber losses (<code>total</code>) and the number of instances seen so far (<code>count</code>). You could just create variables manually if you preferred. Keras tracks any <code>tf.Variable</code> that is set as an attribute (and more generally, any “trackable” object, such as layers or models).</p>
</li>
<li>
<p>The <code>update_state()</code> method is called when you use an instance of this class as a function (as we did with the <code>Precision</code> object). It updates the variables, given the labels and predictions for one batch (and sample weights, but in this case we ignore them).</p>
</li>
<li>
<p>The <code>result()</code> method computes and returns the final result, in this case the mean Huber metric over all instances. When you use the metric as a function, the <code>update_state()</code> method gets called first, then the <code>result()</code> method is called, and its output is returned.</p>
</li>
<li>
<p>We also implement the <code>get_config()</code> method to ensure the <code>threshold</code> gets saved along with the model.</p>
</li>
<li>
<p>The default implementation of the <code>reset_states()</code> method resets all variables to 0.0 (but you can override it if needed).</p>
</li>
</ul>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>Keras will take care of variable persistence seamlessly; no action is required.</p>
</div>

<p>When you define a metric using a simple function, Keras automatically calls it for each batch, and it keeps track of the mean during each epoch, just like we did manually. So the only benefit of our <code>HuberMetric</code> class is that the <code>threshold</code> will be saved. But of course, some metrics, like precision, cannot simply be averaged over batches: in thoses cases, there’s no other option than to implement a streaming metric.</p>

<p>Now that we have built a streaming metric, building a custom layer will seem like a walk in the park!</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Custom Layers"><div class="sect2" id="idm46263507792536">
<h2>Custom Layers</h2>

<p>You may occasionally want to build an architecture that contains an exotic layer for which TensorFlow does not provide a default implementation. In this case, you will need to create a custom layer. Or sometimes you may simply want to build a very repetitive architecture, containing identical blocks of layers repeated many times, and it would be convenient to treat each block of layers as a single layer. For example, if the model is a sequence of layers A, B, C, A, B, C, A, B, C, then you might want to define a custom layer D containing layers A, B, C, and your model would then simply be D, D, D. Let’s see how to build custom layers.</p>

<p>First, some layers have no weights, such as <code>keras.layers.Flatten</code> or <code>keras.layers.ReLU</code>. If you want to create a custom layer without any weights, the simplest option is to write a function and wrap it in a <code>keras.layers.Lambda</code> layer. For example, the following layer will apply the exponential function to its inputs:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">exponential_layer</code> <code class="o">=</code> <code class="n">keras</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">Lambda</code><code class="p">(</code><code class="k">lambda</code> <code class="n">x</code><code class="p">:</code> <code class="n">tf</code><code class="o">.</code><code class="n">exp</code><code class="p">(</code><code class="n">x</code><code class="p">))</code></pre>

<p>This custom layer can then be used like any other layer, using the Sequential API, the Functional API, or the Subclassing API. You can also use it as an activation function (or you could use <code>activation=tf.exp</code> or <code>activation=keras.activations.exponential</code> or simply <code>activation="exponential"</code>). The exponential layer is sometimes used in the output layer of a regression model when the values to predict have very different scales (e.g., 0.001, 10., 1,000.).</p>

<p>As you’ve probably guessed by now, to build a custom stateful layer (i.e., a layer with weights), you need to create a subclass of the <code>keras.layers.Layer</code> class. For example, the following class implements a simplified version of the <code>Dense</code> layer:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">class</code> <code class="nc">MyDense</code><code class="p">(</code><code class="n">keras</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">Layer</code><code class="p">):</code>
    <code class="k">def</code> <code class="nf-Magic">__init__</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">units</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="bp">None</code><code class="p">,</code> <code class="o">**</code><code class="n">kwargs</code><code class="p">):</code>
        <code class="nb">super</code><code class="p">()</code><code class="o">.</code><code class="nf-Magic">__init__</code><code class="p">(</code><code class="o">**</code><code class="n">kwargs</code><code class="p">)</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">units</code> <code class="o">=</code> <code class="n">units</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">activation</code> <code class="o">=</code> <code class="n">keras</code><code class="o">.</code><code class="n">activations</code><code class="o">.</code><code class="n">get</code><code class="p">(</code><code class="n">activation</code><code class="p">)</code>

    <code class="k">def</code> <code class="nf">build</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">batch_input_shape</code><code class="p">):</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">kernel</code> <code class="o">=</code> <code class="bp">self</code><code class="o">.</code><code class="n">add_weight</code><code class="p">(</code>
            <code class="n">name</code><code class="o">=</code><code class="s2">"kernel"</code><code class="p">,</code> <code class="n">shape</code><code class="o">=</code><code class="p">[</code><code class="n">batch_input_shape</code><code class="p">[</code><code class="o">-</code><code class="mi">1</code><code class="p">],</code> <code class="bp">self</code><code class="o">.</code><code class="n">units</code><code class="p">],</code>
            <code class="n">initializer</code><code class="o">=</code><code class="s2">"glorot_normal"</code><code class="p">)</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">bias</code> <code class="o">=</code> <code class="bp">self</code><code class="o">.</code><code class="n">add_weight</code><code class="p">(</code>
            <code class="n">name</code><code class="o">=</code><code class="s2">"bias"</code><code class="p">,</code> <code class="n">shape</code><code class="o">=</code><code class="p">[</code><code class="bp">self</code><code class="o">.</code><code class="n">units</code><code class="p">],</code> <code class="n">initializer</code><code class="o">=</code><code class="s2">"zeros"</code><code class="p">)</code>
        <code class="nb">super</code><code class="p">()</code><code class="o">.</code><code class="n">build</code><code class="p">(</code><code class="n">batch_input_shape</code><code class="p">)</code> <code class="c1"># must be at the end</code>

    <code class="k">def</code> <code class="nf">call</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">X</code><code class="p">):</code>
        <code class="k">return</code> <code class="bp">self</code><code class="o">.</code><code class="n">activation</code><code class="p">(</code><code class="n">X</code> <code class="err">@</code> <code class="bp">self</code><code class="o">.</code><code class="n">kernel</code> <code class="o">+</code> <code class="bp">self</code><code class="o">.</code><code class="n">bias</code><code class="p">)</code>

    <code class="k">def</code> <code class="nf">compute_output_shape</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">batch_input_shape</code><code class="p">):</code>
        <code class="k">return</code> <code class="n">tf</code><code class="o">.</code><code class="n">TensorShape</code><code class="p">(</code><code class="n">batch_input_shape</code><code class="o">.</code><code class="n">as_list</code><code class="p">()[:</code><code class="o">-</code><code class="mi">1</code><code class="p">]</code> <code class="o">+</code> <code class="p">[</code><code class="bp">self</code><code class="o">.</code><code class="n">units</code><code class="p">])</code>

    <code class="k">def</code> <code class="nf">get_config</code><code class="p">(</code><code class="bp">self</code><code class="p">):</code>
        <code class="n">base_config</code> <code class="o">=</code> <code class="nb">super</code><code class="p">()</code><code class="o">.</code><code class="n">get_config</code><code class="p">()</code>
        <code class="k">return</code> <code class="p">{</code><code class="o">**</code><code class="n">base_config</code><code class="p">,</code> <code class="s2">"units"</code><code class="p">:</code> <code class="bp">self</code><code class="o">.</code><code class="n">units</code><code class="p">,</code>
                <code class="s2">"activation"</code><code class="p">:</code> <code class="n">keras</code><code class="o">.</code><code class="n">activations</code><code class="o">.</code><code class="n">serialize</code><code class="p">(</code><code class="bp">self</code><code class="o">.</code><code class="n">activation</code><code class="p">)}</code></pre>

<p>Let’s walk through this code:</p>

<ul>
<li>
<p>The constructor takes all the hyperparameters as arguments (in this example, <code>units</code> and <code>activation</code>), and importantly it also takes a <code>**kwargs</code> argument. It calls the parent constructor, passing it the <code>kwargs</code>: this takes care of standard arguments such as <code>input_shape</code>, <code>trainable</code>, and <code>name</code>. Then it saves the hyperparameters as attributes, converting the <code>activation</code> argument to the appropriate activation function, using the <code>keras.activations.get()</code> function (it accepts functions, standard strings like <code>"relu"</code> or <code>"selu"</code> or simply <code>None</code>).<sup><a data-type="noteref" id="idm46263507058568-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#idm46263507058568" class="totri-footnote">8</a></sup></p>
</li>
<li>
<p>The <code>build()</code> method’s role is to create the layer’s variables by calling the <code>add_weight()</code> method for each weight. The <code>build()</code> method is called the first time the layer is used. At that point, Keras will know the shape of this layer’s inputs, and it will pass it to the <code>build()</code> method,<sup><a data-type="noteref" id="idm46263507054968-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#idm46263507054968" class="totri-footnote">9</a></sup> which is often necessary to create some of the weights. For example, we need to know the number of neurons in the previous layer in order to create the connection weights matrix (i.e., the <code>"kernel"</code>): this corresponds to the size of the last dimension of the inputs. At the end of the <code>build()</code> method (and only at the end), you must call the parent’s <code>build()</code> method: this tells Keras that the layer is built (it just sets <code>self.built = True</code>).</p>
</li>
<li>
<p>The <code>call()</code> method performs the desired operations. In this case, we compute the matrix multiplication of the inputs <code>X</code> and the layer’s kernel, we add the bias vector, we apply the activation function to the result, and this gives us the output of the layer.</p>
</li>
<li>
<p>The <code>compute_output_shape()</code> method simply returns the shape of this layer’s outputs. In this case, it is the same shape as the inputs, except the last dimension is replaced with the number of neurons in the layer. Note that in tf.keras, shapes are instances of the <code>tf.TensorShape</code> class, which you can convert to Python lists using <code>as_list()</code>.</p>
</li>
<li>
<p>The <code>get_config()</code> method is just like in the previous custom classes. Note that we save the activation function’s full configuration by calling <code>keras.activations.serialize()</code>.</p>
</li>
</ul>

<p>You can now use a <code>MyDense</code> layer just like any other layer!</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>You can generally omit the <code>compute_output_shape()</code> method, as tf.keras automatically infers the output shape, except when the layer is dynamic (as we will see shortly). In other Keras implementations, this method is either required or its default implementation assumes the output shape is the same as the input shape.</p>
</div>

<p>To create a layer with multiple inputs (e.g., <code>Concatenate</code>), the argument to the <code>call()</code> method should be a tuple containing all the inputs, and similarly the argument to the <code>compute_output_shape()</code> method should be a tuple containing each input’s batch shape. To create a layer with multiple outputs, the <code>call()</code> method should return the list of outputs, and the <code>compute_output_shape()</code> should return the list of batch output shapes (one per output). For example, the following toy layer takes two inputs and returns three outputs:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">class</code> <code class="nc">MyMultiLayer</code><code class="p">(</code><code class="n">keras</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">Layer</code><code class="p">):</code>
    <code class="k">def</code> <code class="nf">call</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">X</code><code class="p">):</code>
        <code class="n">X1</code><code class="p">,</code> <code class="n">X2</code> <code class="o">=</code> <code class="n">X</code>
        <code class="k">return</code> <code class="p">[</code><code class="n">X1</code> <code class="o">+</code> <code class="n">X2</code><code class="p">,</code> <code class="n">X1</code> <code class="o">*</code> <code class="n">X2</code><code class="p">,</code> <code class="n">X1</code> <code class="o">/</code> <code class="n">X2</code><code class="p">]</code>

    <code class="k">def</code> <code class="nf">compute_output_shape</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">batch_input_shape</code><code class="p">):</code>
        <code class="n">b1</code><code class="p">,</code> <code class="n">b2</code> <code class="o">=</code> <code class="n">batch_input_shape</code>
        <code class="k">return</code> <code class="p">[</code><code class="n">b1</code><code class="p">,</code> <code class="n">b1</code><code class="p">,</code> <code class="n">b1</code><code class="p">]</code> <code class="c1"># should probably handle broadcasting rules</code></pre>

<p>This layer may now be used like any other layer, but of course only using the Functional and Subclassing APIs, not the Sequential API (which only accepts layers with one input and one output).</p>

<p>If your layer needs to have a different behavior during training and during testing (e.g., if it uses <code>Dropout</code> or <code>BatchNormalization</code> layers), then you must add a <code>training</code> argument to the <code>call()</code> method and use this argument to decide what to do. For example, let’s create a layer that adds Gaussian noise during training (for regularization) but does nothing during testing (Keras has a layer that does the same thing: <code>keras.layers.GaussianNoise</code>):</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">class</code> <code class="nc">MyGaussianNoise</code><code class="p">(</code><code class="n">keras</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">Layer</code><code class="p">):</code>
    <code class="k">def</code> <code class="nf-Magic">__init__</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">stddev</code><code class="p">,</code> <code class="o">**</code><code class="n">kwargs</code><code class="p">):</code>
        <code class="nb">super</code><code class="p">()</code><code class="o">.</code><code class="nf-Magic">__init__</code><code class="p">(</code><code class="o">**</code><code class="n">kwargs</code><code class="p">)</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">stddev</code> <code class="o">=</code> <code class="n">stddev</code>

    <code class="k">def</code> <code class="nf">call</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">X</code><code class="p">,</code> <code class="n">training</code><code class="o">=</code><code class="bp">None</code><code class="p">):</code>
        <code class="k">if</code> <code class="n">training</code><code class="p">:</code>
            <code class="n">noise</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">normal</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">shape</code><code class="p">(</code><code class="n">X</code><code class="p">),</code> <code class="n">stddev</code><code class="o">=</code><code class="bp">self</code><code class="o">.</code><code class="n">stddev</code><code class="p">)</code>
            <code class="k">return</code> <code class="n">X</code> <code class="o">+</code> <code class="n">noise</code>
        <code class="k">else</code><code class="p">:</code>
            <code class="k">return</code> <code class="n">X</code>

    <code class="k">def</code> <code class="nf">compute_output_shape</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">batch_input_shape</code><code class="p">):</code>
        <code class="k">return</code> <code class="n">batch_input_shape</code></pre>

<p>With that, you can now build any custom layer you need! Now let’s create custom models.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Custom Models"><div class="sect2" id="idm46263507326824">
<h2>Custom Models</h2>

<p>We already looked at custom model classes in <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch10.html#ann_chapter">Chapter&nbsp;10</a>, when we discussed the Subclassing API.<sup><a data-type="noteref" id="idm46263506780328-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#idm46263506780328">10</a></sup> It’s straightforward: subclass the <code>keras.Model</code> class, create layers and variables in the constructor, and implement the <code>call()</code> method to do whatever you want the model to do. Suppose you want to build the model represented in <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#custom_model_diagram">Figure&nbsp;12-3</a>.</p>

<figure><div id="custom_model_diagram" class="figure">
<img src="./Chapter12_files/mls2_1203.png" alt="mls2 1203" width="1440" height="1017" data-mfp-src="/library/view/hands-on-machine-learning/9781492032632/assets/mls2_1203.png">
<h6><span class="label">Figure 12-3. </span>Custom model example: an arbitrary model with a custom ResidualBlock layer containing a skip connection</h6>
</div></figure>

<p>The inputs go through a first dense layer, then through a <em>residual block</em> composed of two dense layers and an addition operation (as we will see in <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch14.html#cnn_chapter">Chapter&nbsp;14</a>, a residual block adds its inputs to its outputs), then through this same residual block three more times, then through a second residual block, and the final result goes through a dense output layer. Note that this model does not make much sense; it’s just an example to illustrate the fact that you can easily build any kind of model you want, even one that contains loops and skip connections. To implement this model, it is best to first create a <code>ResidualBlock</code> layer, since we are going to create a couple identical blocks (and we might want to reuse it in another model):</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">class</code> <code class="nc">ResidualBlock</code><code class="p">(</code><code class="n">keras</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">Layer</code><code class="p">):</code>
    <code class="k">def</code> <code class="nf-Magic">__init__</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">n_layers</code><code class="p">,</code> <code class="n">n_neurons</code><code class="p">,</code> <code class="o">**</code><code class="n">kwargs</code><code class="p">):</code>
        <code class="nb">super</code><code class="p">()</code><code class="o">.</code><code class="nf-Magic">__init__</code><code class="p">(</code><code class="o">**</code><code class="n">kwargs</code><code class="p">)</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">hidden</code> <code class="o">=</code> <code class="p">[</code><code class="n">keras</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">Dense</code><code class="p">(</code><code class="n">n_neurons</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="s2">"elu"</code><code class="p">,</code>
                                          <code class="n">kernel_initializer</code><code class="o">=</code><code class="s2">"he_normal"</code><code class="p">)</code>
                       <code class="k">for</code> <code class="n">_</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="n">n_layers</code><code class="p">)]</code>

    <code class="k">def</code> <code class="nf">call</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">inputs</code><code class="p">):</code>
        <code class="n">Z</code> <code class="o">=</code> <code class="n">inputs</code>
        <code class="k">for</code> <code class="n">layer</code> <code class="ow">in</code> <code class="bp">self</code><code class="o">.</code><code class="n">hidden</code><code class="p">:</code>
            <code class="n">Z</code> <code class="o">=</code> <code class="n">layer</code><code class="p">(</code><code class="n">Z</code><code class="p">)</code>
        <code class="k">return</code> <code class="n">inputs</code> <code class="o">+</code> <code class="n">Z</code></pre>

<p>This layer is a bit special since it contains other layers. This is handled transparently by Keras: it automatically detects that the <code>hidden</code> attribute contains trackable objects (layers in this case), so their variables are automatically added to this layer’s list of variables. The rest of this class is self-explanatory. Next, let’s use the Subclassing API to define the model itself:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">class</code> <code class="nc">ResidualRegressor</code><code class="p">(</code><code class="n">keras</code><code class="o">.</code><code class="n">Model</code><code class="p">):</code>
    <code class="k">def</code> <code class="nf-Magic">__init__</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">output_dim</code><code class="p">,</code> <code class="o">**</code><code class="n">kwargs</code><code class="p">):</code>
        <code class="nb">super</code><code class="p">()</code><code class="o">.</code><code class="nf-Magic">__init__</code><code class="p">(</code><code class="o">**</code><code class="n">kwargs</code><code class="p">)</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">hidden1</code> <code class="o">=</code> <code class="n">keras</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">Dense</code><code class="p">(</code><code class="mi">30</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="s2">"elu"</code><code class="p">,</code>
                                          <code class="n">kernel_initializer</code><code class="o">=</code><code class="s2">"he_normal"</code><code class="p">)</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">block1</code> <code class="o">=</code> <code class="n">ResidualBlock</code><code class="p">(</code><code class="mi">2</code><code class="p">,</code> <code class="mi">30</code><code class="p">)</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">block2</code> <code class="o">=</code> <code class="n">ResidualBlock</code><code class="p">(</code><code class="mi">2</code><code class="p">,</code> <code class="mi">30</code><code class="p">)</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">out</code> <code class="o">=</code> <code class="n">keras</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">Dense</code><code class="p">(</code><code class="n">output_dim</code><code class="p">)</code>

    <code class="k">def</code> <code class="nf">call</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">inputs</code><code class="p">):</code>
        <code class="n">Z</code> <code class="o">=</code> <code class="bp">self</code><code class="o">.</code><code class="n">hidden1</code><code class="p">(</code><code class="n">inputs</code><code class="p">)</code>
        <code class="k">for</code> <code class="n">_</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">1</code> <code class="o">+</code> <code class="mi">3</code><code class="p">):</code>
            <code class="n">Z</code> <code class="o">=</code> <code class="bp">self</code><code class="o">.</code><code class="n">block1</code><code class="p">(</code><code class="n">Z</code><code class="p">)</code>
        <code class="n">Z</code> <code class="o">=</code> <code class="bp">self</code><code class="o">.</code><code class="n">block2</code><code class="p">(</code><code class="n">Z</code><code class="p">)</code>
        <code class="k">return</code> <code class="bp">self</code><code class="o">.</code><code class="n">out</code><code class="p">(</code><code class="n">Z</code><code class="p">)</code></pre>

<p>We create the layers in the constructor and use them in the <code>call()</code> method. This model can then be used like any other model (compile it, fit it, evaluate it, and use it to make predictions). If you also want to be able to save the model using the <code>save()</code> method and load it using the <code>keras.models.load_model()</code> function, you must implement the <code>get_config()</code> method (as we did earlier) in both the <code>ResidualBlock</code> class and the <code>ResidualRegressor</code> class. Alternatively, you can save and load the weights using the <code>save_weights()</code> and <code>load_weights()</code> methods.</p>

<p>The <code>Model</code> class is a subclass of the <code>Layer</code> class, so models can be defined and used exactly like layers. But a model has some extra functionalities, including of course its <code>compile()</code>, <code>fit()</code>, <code>evaluate()</code>, and <code>predict()</code> methods (and a few variants), plus the <code>get_layers()</code> method (which can return any of the model’s layers by name or by index), and the <code>save()</code> method (and support for <code>keras.models.load_model()</code> and <code>keras.models.clone_model()</code>).</p>
<div data-type="tip"><h6>Tip</h6>
<p>If models provide more functionalities than layers, why not just define every layer as a model? Well, technically you could, but it is usually cleaner to distinguish the internal components of your model (i.e., layers or reusable blocks of layers) from the model itself (i.e., the object you will train). The former should subclass the <code>Layer</code> class, while the latter should subclass the <code>Model</code> class.</p>
</div>

<p>With that, you can naturally and concisely build almost any model that you find in a paper, either using the Sequential API, the Functional API, the Subclassing API, or even a mix of these. “Almost” any model? Yes, there are still a couple things that we need to look at: first, how to define losses or metrics based on model internals; and second, how to build a custom training loop.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Losses and Metrics Based on Model Internals"><div class="sect2" id="idm46263506971336">
<h2>Losses and Metrics Based on Model Internals</h2>

<p>The custom losses and metrics we defined earlier were all based on the labels and the predictions (and optionally sample weights). There will be times when you want to define losses based on other parts of your model, such as the weights or activations of its hidden layers. This may be useful for regularization purposes or to monitor some internal aspect of your model.</p>

<p>To define a custom loss based on model internals, compute it based on any part of the model you want, then pass the result to the <code>add_loss()</code> method. For example, the following custom model represents a standard MLP regressor with five hidden layers, plus an auxiliary output which is trained to reconstruct the inputs. The loss associated to this auxiliary output is called the <em>reconstruction loss</em> (see <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch17.html#autoencoders_chapter">Chapter&nbsp;17</a>): it is the mean squared difference between the reconstruction and the inputs. By adding this reconstruction loss to the main loss, we will encourage the model to preserve as much information as possible through the hidden layers, even information that is not directly useful for the regression task itself. In practice, this loss sometimes improves generalization (it is a regularization loss). Here is the code for this custom model with a custom reconstruction loss:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">class</code> <code class="nc">ReconstructingRegressor</code><code class="p">(</code><code class="n">keras</code><code class="o">.</code><code class="n">Model</code><code class="p">):</code>
    <code class="k">def</code> <code class="nf-Magic">__init__</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">output_dim</code><code class="p">,</code> <code class="o">**</code><code class="n">kwargs</code><code class="p">):</code>
        <code class="nb">super</code><code class="p">()</code><code class="o">.</code><code class="nf-Magic">__init__</code><code class="p">(</code><code class="o">**</code><code class="n">kwargs</code><code class="p">)</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">hidden</code> <code class="o">=</code> <code class="p">[</code><code class="n">keras</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">Dense</code><code class="p">(</code><code class="mi">30</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="s2">"selu"</code><code class="p">,</code>
                                          <code class="n">kernel_initializer</code><code class="o">=</code><code class="s2">"lecun_normal"</code><code class="p">)</code>
                       <code class="k">for</code> <code class="n">_</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">5</code><code class="p">)]</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">out</code> <code class="o">=</code> <code class="n">keras</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">Dense</code><code class="p">(</code><code class="n">output_dim</code><code class="p">)</code>

    <code class="k">def</code> <code class="nf">build</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">batch_input_shape</code><code class="p">):</code>
        <code class="n">n_inputs</code> <code class="o">=</code> <code class="n">batch_input_shape</code><code class="p">[</code><code class="o">-</code><code class="mi">1</code><code class="p">]</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">reconstruct</code> <code class="o">=</code> <code class="n">keras</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">Dense</code><code class="p">(</code><code class="n">n_inputs</code><code class="p">)</code>
        <code class="nb">super</code><code class="p">()</code><code class="o">.</code><code class="n">build</code><code class="p">(</code><code class="n">batch_input_shape</code><code class="p">)</code>

    <code class="k">def</code> <code class="nf">call</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">inputs</code><code class="p">):</code>
        <code class="n">Z</code> <code class="o">=</code> <code class="n">inputs</code>
        <code class="k">for</code> <code class="n">layer</code> <code class="ow">in</code> <code class="bp">self</code><code class="o">.</code><code class="n">hidden</code><code class="p">:</code>
            <code class="n">Z</code> <code class="o">=</code> <code class="n">layer</code><code class="p">(</code><code class="n">Z</code><code class="p">)</code>
        <code class="n">reconstruction</code> <code class="o">=</code> <code class="bp">self</code><code class="o">.</code><code class="n">reconstruct</code><code class="p">(</code><code class="n">Z</code><code class="p">)</code>
        <code class="n">recon_loss</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">reduce_mean</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">square</code><code class="p">(</code><code class="n">reconstruction</code> <code class="o">-</code> <code class="n">inputs</code><code class="p">))</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">add_loss</code><code class="p">(</code><code class="mf">0.05</code> <code class="o">*</code> <code class="n">recon_loss</code><code class="p">)</code>
        <code class="k">return</code> <code class="bp">self</code><code class="o">.</code><code class="n">out</code><code class="p">(</code><code class="n">Z</code><code class="p">)</code></pre>

<p>Let’s go through this code:</p>

<ul>
<li>
<p>The constructor creates the DNN with five dense hidden layers and one dense output layer.</p>
</li>
<li>
<p>The <code>build()</code> method creates an extra dense layer which will be used to reconstruct the inputs of the model. It must be created here because its number of units must be equal to the number of inputs, and this number is unknown before the <code>build()</code> method is called.</p>
</li>
<li>
<p>The <code>call()</code> method processes the inputs through all five hidden layers, then passes the result through the reconstruction layer, which produces the reconstruction.</p>
</li>
<li>
<p>Then the <code>call()</code> method computes the reconstruction loss (the mean squared difference between the reconstruction and the inputs), and it adds it to the model’s list of losses using the <code>add_loss()</code> method.<sup><a data-type="noteref" id="idm46263506242968-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#idm46263506242968">11</a></sup> Notice that we scale down the reconstruction loss by multiplying it by <code>0.05</code> (this is a hyperparameter you can tune). This ensures that the reconstruction loss does not dominate the main loss.</p>
</li>
<li>
<p>Finally, the <code>call()</code> method passes the output of the hidden layers to the output layer and returns its output.</p>
</li>
</ul>

<p>Similarly, you can add a custom metric based on model internals by computing it in any way you want, as long as the result is the output of a metric object. For example, you can create a <code>keras.metrics.Mean()</code> object in the constructor, then call it in the <code>call()</code> method, passing it the <code>recon_loss</code>, and finally add it to the model by calling the model’s <code>add_metric()</code> method. This way, when you train the model, Keras will display both the mean loss over each epoch (the loss is the sum of the main loss plus 0.05 times the reconstruction loss) and the mean reconstruction error over each epoch. Both will go down during training:</p>

<pre data-type="programlisting">Epoch 1/5
11610/11610 [=============] [...] loss: 4.3092 - reconstruction_error: 1.7360
Epoch 2/5
11610/11610 [=============] [...] loss: 1.1232 - reconstruction_error: 0.8964
[...]</pre>

<p>In over 99% of cases, everything we have discussed so far will be sufficient to implement whatever model you want to build, even with complex architectures, losses, and metrics. However, in some rare cases you may need to customize the training loop itself. Before we get there, we need to look at how to compute gradients automatically in TensorFlow.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Computing Gradients Using Autodiff"><div class="sect2" id="idm46263506235272">
<h2>Computing Gradients Using Autodiff</h2>

<p>To understand how to use autodiff (see <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch10.html#ann_chapter">Chapter&nbsp;10</a> and <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/app04.html#autodiff_appendix">Appendix&nbsp;D</a>) to compute gradients automatically, let’s consider a simple toy function:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">f</code><code class="p">(</code><code class="n">w1</code><code class="p">,</code> <code class="n">w2</code><code class="p">):</code>
    <code class="k">return</code> <code class="mi">3</code> <code class="o">*</code> <code class="n">w1</code> <code class="o">**</code> <code class="mi">2</code> <code class="o">+</code> <code class="mi">2</code> <code class="o">*</code> <code class="n">w1</code> <code class="o">*</code> <code class="n">w2</code></pre>

<p>If you know calculus, you can analytically find that the partial derivative of this function with regard to <code>w1</code> is <code>6 * w1</code> <code>+</code> <code>2 * w2</code>. You can also find that its partial derivative with regard to <code>w2</code> is <code>2 * w1</code>. For example, at the point <code>(w1, w2)</code> <code>=</code> <code>(5, 3)</code>, these partial derivatives are equal to 36 and 10, respectively, so the gradient vector at this point is (36, 10). But if this were a neural network, the function would be much more complex, typically with tens of thousands of parameters, and finding the partial derivatives analytically by hand would be an almost impossible task. One solution could be to compute an approximation of each partial derivative by measuring how much the function’s output changes when you tweak the corresponding parameter:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">w1</code><code class="p">,</code> <code class="n">w2</code> <code class="o">=</code> <code class="mi">5</code><code class="p">,</code> <code class="mi">3</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">eps</code> <code class="o">=</code> <code class="mf">1e-6</code>
<code class="gp">&gt;&gt;&gt; </code><code class="p">(</code><code class="n">f</code><code class="p">(</code><code class="n">w1</code> <code class="o">+</code> <code class="n">eps</code><code class="p">,</code> <code class="n">w2</code><code class="p">)</code> <code class="o">-</code> <code class="n">f</code><code class="p">(</code><code class="n">w1</code><code class="p">,</code> <code class="n">w2</code><code class="p">))</code> <code class="o">/</code> <code class="n">eps</code>
<code class="go">36.000003007075065</code>
<code class="gp">&gt;&gt;&gt; </code><code class="p">(</code><code class="n">f</code><code class="p">(</code><code class="n">w1</code><code class="p">,</code> <code class="n">w2</code> <code class="o">+</code> <code class="n">eps</code><code class="p">)</code> <code class="o">-</code> <code class="n">f</code><code class="p">(</code><code class="n">w1</code><code class="p">,</code> <code class="n">w2</code><code class="p">))</code> <code class="o">/</code> <code class="n">eps</code>
<code class="go">10.000000003174137</code></pre>

<p>Looks about right! This works rather well and it is easy to implement, but it is just an approximation, and importantly you need to call <code>f()</code> at least once per parameter (not twice, since we could compute <code>f(w1, w2)</code> just once). Needing to call <code>f()</code> at least once per parameter makes this approach intractable for large neural networks. So instead we should use autodiff (see <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch10.html#ann_chapter">Chapter&nbsp;10</a> and <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/app04.html#autodiff_appendix">Appendix&nbsp;D</a>). TensorFlow makes this pretty simple:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">w1</code><code class="p">,</code> <code class="n">w2</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">Variable</code><code class="p">(</code><code class="mf">5.</code><code class="p">),</code> <code class="n">tf</code><code class="o">.</code><code class="n">Variable</code><code class="p">(</code><code class="mf">3.</code><code class="p">)</code>
<code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">GradientTape</code><code class="p">()</code> <code class="k">as</code> <code class="n">tape</code><code class="p">:</code>
    <code class="n">z</code> <code class="o">=</code> <code class="n">f</code><code class="p">(</code><code class="n">w1</code><code class="p">,</code> <code class="n">w2</code><code class="p">)</code>

<code class="n">gradients</code> <code class="o">=</code> <code class="n">tape</code><code class="o">.</code><code class="n">gradient</code><code class="p">(</code><code class="n">z</code><code class="p">,</code> <code class="p">[</code><code class="n">w1</code><code class="p">,</code> <code class="n">w2</code><code class="p">])</code></pre>

<p>We first define two variables <code>w1</code> and <code>w2</code>, then we create a <code>tf.GradientTape</code> context that will automatically record every operation that involves a variable, and finally we ask this tape to compute the gradients of the result <code>z</code> with regard to both variables <code>[w1, w2]</code>. Let’s take a look at the gradients that TensorFlow computed:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">gradients</code>
<code class="go">[&lt;tf.Tensor: id=828234, shape=(), dtype=float32, numpy=36.0&gt;,</code>
<code class="go"> &lt;tf.Tensor: id=828229, shape=(), dtype=float32, numpy=10.0&gt;]</code></pre>

<p>Perfect! Not only is the result accurate (the precision is only limited by the floating point errors), but the <code>gradient()</code> method only goes through the recorded computations once (in reverse order), no matter how many variables there are, so it is incredibly efficient. It’s like magic!</p>
<div data-type="tip"><h6>Tip</h6>
<p>To save memory, only put the strict minimum inside the <code>tf.GradientTape()</code> block. Alternatively, pause recording by creating a <code>with tape.stop_recording()</code> block inside the <code>tf.GradientTape()</code> block.</p>
</div>

<p>The tape is automatically erased immediately after you call its <code>gradient()</code> method, so you will get an exception if you try to call <code>gradient()</code> twice:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">GradientTape</code><code class="p">()</code> <code class="k">as</code> <code class="n">tape</code><code class="p">:</code>
    <code class="n">z</code> <code class="o">=</code> <code class="n">f</code><code class="p">(</code><code class="n">w1</code><code class="p">,</code> <code class="n">w2</code><code class="p">)</code>

<code class="n">dz_dw1</code> <code class="o">=</code> <code class="n">tape</code><code class="o">.</code><code class="n">gradient</code><code class="p">(</code><code class="n">z</code><code class="p">,</code> <code class="n">w1</code><code class="p">)</code> <code class="c1"># =&gt; tensor 36.0</code>
<code class="n">dz_dw2</code> <code class="o">=</code> <code class="n">tape</code><code class="o">.</code><code class="n">gradient</code><code class="p">(</code><code class="n">z</code><code class="p">,</code> <code class="n">w2</code><code class="p">)</code> <code class="c1"># RuntimeError!</code></pre>

<p>If you need to call <code>gradient()</code> more than once, you must make the tape persistent and delete it when you are done with it to free resources:<sup><a data-type="noteref" id="idm46263505885384-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#idm46263505885384">12</a></sup></p>

<pre data-type="programlisting" data-code-language="python"><code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">GradientTape</code><code class="p">(</code><code class="n">persistent</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code> <code class="k">as</code> <code class="n">tape</code><code class="p">:</code>
    <code class="n">z</code> <code class="o">=</code> <code class="n">f</code><code class="p">(</code><code class="n">w1</code><code class="p">,</code> <code class="n">w2</code><code class="p">)</code>

<code class="n">dz_dw1</code> <code class="o">=</code> <code class="n">tape</code><code class="o">.</code><code class="n">gradient</code><code class="p">(</code><code class="n">z</code><code class="p">,</code> <code class="n">w1</code><code class="p">)</code> <code class="c1"># =&gt; tensor 36.0</code>
<code class="n">dz_dw2</code> <code class="o">=</code> <code class="n">tape</code><code class="o">.</code><code class="n">gradient</code><code class="p">(</code><code class="n">z</code><code class="p">,</code> <code class="n">w2</code><code class="p">)</code> <code class="c1"># =&gt; tensor 10.0, works fine now!</code>
<code class="k">del</code> <code class="n">tape</code></pre>

<p>By default, the tape will only track operations involving variables, so if you try to compute the gradient of <code>z</code> with regard to anything else than a variable, the result will be <code>None</code>:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">c1</code><code class="p">,</code> <code class="n">c2</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">constant</code><code class="p">(</code><code class="mf">5.</code><code class="p">),</code> <code class="n">tf</code><code class="o">.</code><code class="n">constant</code><code class="p">(</code><code class="mf">3.</code><code class="p">)</code>
<code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">GradientTape</code><code class="p">()</code> <code class="k">as</code> <code class="n">tape</code><code class="p">:</code>
    <code class="n">z</code> <code class="o">=</code> <code class="n">f</code><code class="p">(</code><code class="n">c1</code><code class="p">,</code> <code class="n">c2</code><code class="p">)</code>

<code class="n">gradients</code> <code class="o">=</code> <code class="n">tape</code><code class="o">.</code><code class="n">gradient</code><code class="p">(</code><code class="n">z</code><code class="p">,</code> <code class="p">[</code><code class="n">c1</code><code class="p">,</code> <code class="n">c2</code><code class="p">])</code> <code class="c1"># returns [None, None]</code></pre>

<p>However, you can force the tape to watch any tensors you like, to record every operation that involves them. You can then compute gradients with regard to these tensors, as if they were variables:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">GradientTape</code><code class="p">()</code> <code class="k">as</code> <code class="n">tape</code><code class="p">:</code>
    <code class="n">tape</code><code class="o">.</code><code class="n">watch</code><code class="p">(</code><code class="n">c1</code><code class="p">)</code>
    <code class="n">tape</code><code class="o">.</code><code class="n">watch</code><code class="p">(</code><code class="n">c2</code><code class="p">)</code>
    <code class="n">z</code> <code class="o">=</code> <code class="n">f</code><code class="p">(</code><code class="n">c1</code><code class="p">,</code> <code class="n">c2</code><code class="p">)</code>

<code class="n">gradients</code> <code class="o">=</code> <code class="n">tape</code><code class="o">.</code><code class="n">gradient</code><code class="p">(</code><code class="n">z</code><code class="p">,</code> <code class="p">[</code><code class="n">c1</code><code class="p">,</code> <code class="n">c2</code><code class="p">])</code> <code class="c1"># returns [tensor 36., tensor 10.]</code></pre>

<p>This can be useful in some cases, like if you want to implement a regularization loss that penalizes activations that vary a lot when the inputs vary little: the loss will be based on the gradient of the activations with regard to the inputs. Since the inputs are not variables, you would need to tell the tape to watch them.</p>

<p>Most of the time a gradient tape is used to compute the gradients of a single value (usually the loss) with regard to a set of values (usually the model parameters). This is where reverse-mode autodiff shines, as it just needs to do one forward pass and one reverse pass to get all the gradients at once. If you try to compute the gradients of a vector, for example a vector containing multiple losses, then TensorFlow will compute the gradients of the vector’s sum. So if you ever need to get the individual gradients (e.g., the gradients of each loss with regard to the model parameters), then you must call the tape’s <code>jabobian()</code> method: it will perform reverse-mode autodiff once for each loss in the vector (all in parallel by default). It is even possible to compute second order partial derivatives (the Hessians, i.e., the partial derivatives of the partial derivatives), but this is rarely needed in practice (see the notebook for an example).</p>

<p>In some cases you may want to stop gradients from backpropagating through some part of your neural network. To do this, you must use the <code>tf.stop_gradient()</code> function. The function returns its inputs during the forward pass (like <code>tf.identity()</code>), but it does not let gradients through during backpropagation (it acts like a constant):</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">f</code><code class="p">(</code><code class="n">w1</code><code class="p">,</code> <code class="n">w2</code><code class="p">):</code>
    <code class="k">return</code> <code class="mi">3</code> <code class="o">*</code> <code class="n">w1</code> <code class="o">**</code> <code class="mi">2</code> <code class="o">+</code> <code class="n">tf</code><code class="o">.</code><code class="n">stop_gradient</code><code class="p">(</code><code class="mi">2</code> <code class="o">*</code> <code class="n">w1</code> <code class="o">*</code> <code class="n">w2</code><code class="p">)</code>

<code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">GradientTape</code><code class="p">()</code> <code class="k">as</code> <code class="n">tape</code><code class="p">:</code>
    <code class="n">z</code> <code class="o">=</code> <code class="n">f</code><code class="p">(</code><code class="n">w1</code><code class="p">,</code> <code class="n">w2</code><code class="p">)</code> <code class="c1"># same result as without stop_gradient()</code>

<code class="n">gradients</code> <code class="o">=</code> <code class="n">tape</code><code class="o">.</code><code class="n">gradient</code><code class="p">(</code><code class="n">z</code><code class="p">,</code> <code class="p">[</code><code class="n">w1</code><code class="p">,</code> <code class="n">w2</code><code class="p">])</code> <code class="c1"># =&gt; returns [tensor 30., None]</code></pre>

<p>Finally, you may occasionally run into some numerical issues when computing gradients. For example, if you compute the gradients of the <code>my_softplus()</code> function for large inputs, the result will be NaN:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">x</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">Variable</code><code class="p">([</code><code class="mf">100.</code><code class="p">])</code>
<code class="gp">&gt;&gt;&gt; </code><code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">GradientTape</code><code class="p">()</code> <code class="k">as</code> <code class="n">tape</code><code class="p">:</code>
<code class="gp">... </code>    <code class="n">z</code> <code class="o">=</code> <code class="n">my_softplus</code><code class="p">(</code><code class="n">x</code><code class="p">)</code>
<code class="gp">...</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">tape</code><code class="o">.</code><code class="n">gradient</code><code class="p">(</code><code class="n">z</code><code class="p">,</code> <code class="p">[</code><code class="n">x</code><code class="p">])</code>
<code class="go">&lt;tf.Tensor: [...] numpy=array([nan], dtype=float32)&gt;</code></pre>

<p>This is because computing the gradients of this function using autodiff leads to some numerical difficulties: due to floating point precision errors, autodiff ends up computing infinity divided by infinity (which returns NaN). Fortunately, we can analytically find that the derivative of the softplus function is just 1&nbsp;/&nbsp;(1&nbsp;+&nbsp;1&nbsp;/&nbsp;exp(x)), which is numerically stable. Next, we can tell TensorFlow to use this stable function when computing the gradients of the <code>my_softplus()</code> function by decorating it with <code>@tf.custom_gradient</code> and making it return both its normal output and the function that computes the derivatives (note that it will receive as input the gradients that were backpropagated so far, down to the softplus function; and according to the chain rule, we should multiply them with this function’s gradients):</p>

<pre data-type="programlisting" data-code-language="python"><code class="nd">@tf.custom_gradient</code>
<code class="k">def</code> <code class="nf">my_better_softplus</code><code class="p">(</code><code class="n">z</code><code class="p">):</code>
    <code class="n">exp</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">exp</code><code class="p">(</code><code class="n">z</code><code class="p">)</code>
    <code class="k">def</code> <code class="nf">my_softplus_gradients</code><code class="p">(</code><code class="n">grad</code><code class="p">):</code>
        <code class="k">return</code> <code class="n">grad</code> <code class="o">/</code> <code class="p">(</code><code class="mi">1</code> <code class="o">+</code> <code class="mi">1</code> <code class="o">/</code> <code class="n">exp</code><code class="p">)</code>
    <code class="k">return</code> <code class="n">tf</code><code class="o">.</code><code class="n">math</code><code class="o">.</code><code class="n">log</code><code class="p">(</code><code class="n">exp</code> <code class="o">+</code> <code class="mi">1</code><code class="p">),</code> <code class="n">my_softplus_gradients</code></pre>

<p>Now when we compute the gradients of the <code>my_better_softplus()</code> function, we get the proper result, even for large input values (however, the main output still explodes because of the exponential: one workaround is to use <code>tf.where()</code> to return the inputs when they are large).</p>

<p>Congratulations! You can now compute the gradients of any function (provided it is differentiable at the point where you compute it). The function even block backpropagation when needed and write your own gradient functions! This is probably more flexibility than you will ever need, even if you build your own custom training loops, as we will see now.</p>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Custom Training Loops"><div class="sect2" id="idm46263506234328">
<h2>Custom Training Loops</h2>

<p>In some rare cases, the <code>fit()</code> method may not be flexible enough for what you need to do. For example, the Wide and Deep paper we discussed in <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch10.html#ann_chapter">Chapter&nbsp;10</a> uses two different optimizers: one for the wide path and the other for the deep path. Since the <code>fit()</code> method only uses one optimizer (the one that we specify when compiling the model), implementing this paper requires writing your own custom loop.</p>

<p>You may also like to write custom training loops simply to feel more confident that they do precisely what you intend them to do (perhaps you are unsure about some details of the <code>fit()</code> method). It can sometimes feel safer to make everything explicit. However, remember that writing a custom training loop will make your code longer, more error prone, and harder to maintain.</p>
<div data-type="tip"><h6>Tip</h6>
<p>Unless you really need the extra flexibility, you should prefer using the <code>fit()</code> method rather than implementing your own training loop, especially if you work in a team.</p>
</div>

<p>First, let’s build a simple model. No need to compile it, since we will handle the training loop manually:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">l2_reg</code> <code class="o">=</code> <code class="n">keras</code><code class="o">.</code><code class="n">regularizers</code><code class="o">.</code><code class="n">l2</code><code class="p">(</code><code class="mf">0.05</code><code class="p">)</code>
<code class="n">model</code> <code class="o">=</code> <code class="n">keras</code><code class="o">.</code><code class="n">models</code><code class="o">.</code><code class="n">Sequential</code><code class="p">([</code>
    <code class="n">keras</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">Dense</code><code class="p">(</code><code class="mi">30</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="s2">"elu"</code><code class="p">,</code> <code class="n">kernel_initializer</code><code class="o">=</code><code class="s2">"he_normal"</code><code class="p">,</code>
                       <code class="n">kernel_regularizer</code><code class="o">=</code><code class="n">l2_reg</code><code class="p">),</code>
    <code class="n">keras</code><code class="o">.</code><code class="n">layers</code><code class="o">.</code><code class="n">Dense</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code> <code class="n">kernel_regularizer</code><code class="o">=</code><code class="n">l2_reg</code><code class="p">)</code>
<code class="p">])</code></pre>

<p>Next, let’s create a tiny function that will randomly sample a batch of instances from the training set (in <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html#data_chapter">Chapter&nbsp;13</a> we will discuss the Data API, which offers a much better alternative):</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">random_batch</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">y</code><code class="p">,</code> <code class="n">batch_size</code><code class="o">=</code><code class="mi">32</code><code class="p">):</code>
    <code class="n">idx</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">randint</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">X</code><code class="p">),</code> <code class="n">size</code><code class="o">=</code><code class="n">batch_size</code><code class="p">)</code>
    <code class="k">return</code> <code class="n">X</code><code class="p">[</code><code class="n">idx</code><code class="p">],</code> <code class="n">y</code><code class="p">[</code><code class="n">idx</code><code class="p">]</code></pre>

<p>Let’s also define a function that will display the training status, including the number of steps, the total number of steps, the mean loss since the start of the epoch (i.e., we will use the <code>Mean</code> metric to compute it), and other metrics:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">print_status_bar</code><code class="p">(</code><code class="n">iteration</code><code class="p">,</code> <code class="n">total</code><code class="p">,</code> <code class="n">loss</code><code class="p">,</code> <code class="n">metrics</code><code class="o">=</code><code class="bp">None</code><code class="p">):</code>
    <code class="n">metrics</code> <code class="o">=</code> <code class="s2">" - "</code><code class="o">.</code><code class="n">join</code><code class="p">([</code><code class="s2">"{}: {:.4f}"</code><code class="o">.</code><code class="n">format</code><code class="p">(</code><code class="n">m</code><code class="o">.</code><code class="n">name</code><code class="p">,</code> <code class="n">m</code><code class="o">.</code><code class="n">result</code><code class="p">())</code>
                         <code class="k">for</code> <code class="n">m</code> <code class="ow">in</code> <code class="p">[</code><code class="n">loss</code><code class="p">]</code> <code class="o">+</code> <code class="p">(</code><code class="n">metrics</code> <code class="ow">or</code> <code class="p">[])])</code>
    <code class="n">end</code> <code class="o">=</code> <code class="s2">""</code> <code class="k">if</code> <code class="n">iteration</code> <code class="o">&lt;</code> <code class="n">total</code> <code class="k">else</code> <code class="s2">"</code><code class="se">\n</code><code class="s2">"</code>
    <code class="k">print</code><code class="p">(</code><code class="s2">"</code><code class="se">\r</code><code class="s2">{}/{} - "</code><code class="o">.</code><code class="n">format</code><code class="p">(</code><code class="n">iteration</code><code class="p">,</code> <code class="n">total</code><code class="p">)</code> <code class="o">+</code> <code class="n">metrics</code><code class="p">,</code>
          <code class="n">end</code><code class="o">=</code><code class="n">end</code><code class="p">)</code></pre>

<p>This code is self-explanatory, unless you are unfamiliar with Python string formatting: <code>{:.4f}</code> will format a float with four digits after the decimal point. Moreover, using <code>\r</code> (carriage return) along with <code>end=""</code> ensures that the status bar always gets printed on the same line. In the notebook, the <code>print_status_bar()</code> function includes a progress bar, but you could use the handy tqdm library instead.</p>

<p>With that, let’s get down to business! First, we need to define some hyperparameters and choose the optimizer, the loss function, and the metrics (just the MAE in this example):</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">n_epochs</code> <code class="o">=</code> <code class="mi">5</code>
<code class="n">batch_size</code> <code class="o">=</code> <code class="mi">32</code>
<code class="n">n_steps</code> <code class="o">=</code> <code class="nb">len</code><code class="p">(</code><code class="n">X_train</code><code class="p">)</code> <code class="o">//</code> <code class="n">batch_size</code>
<code class="n">optimizer</code> <code class="o">=</code> <code class="n">keras</code><code class="o">.</code><code class="n">optimizers</code><code class="o">.</code><code class="n">Nadam</code><code class="p">(</code><code class="n">lr</code><code class="o">=</code><code class="mf">0.01</code><code class="p">)</code>
<code class="n">loss_fn</code> <code class="o">=</code> <code class="n">keras</code><code class="o">.</code><code class="n">losses</code><code class="o">.</code><code class="n">mean_squared_error</code>
<code class="n">mean_loss</code> <code class="o">=</code> <code class="n">keras</code><code class="o">.</code><code class="n">metrics</code><code class="o">.</code><code class="n">Mean</code><code class="p">()</code>
<code class="n">metrics</code> <code class="o">=</code> <code class="p">[</code><code class="n">keras</code><code class="o">.</code><code class="n">metrics</code><code class="o">.</code><code class="n">MeanAbsoluteError</code><code class="p">()]</code></pre>

<p>And now we are ready to build the custom loop!</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">for</code> <code class="n">epoch</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code> <code class="n">n_epochs</code> <code class="o">+</code> <code class="mi">1</code><code class="p">):</code>
    <code class="k">print</code><code class="p">(</code><code class="s2">"Epoch {}/{}"</code><code class="o">.</code><code class="n">format</code><code class="p">(</code><code class="n">epoch</code><code class="p">,</code> <code class="n">n_epochs</code><code class="p">))</code>
    <code class="k">for</code> <code class="n">step</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code> <code class="n">n_steps</code> <code class="o">+</code> <code class="mi">1</code><code class="p">):</code>
        <code class="n">X_batch</code><code class="p">,</code> <code class="n">y_batch</code> <code class="o">=</code> <code class="n">random_batch</code><code class="p">(</code><code class="n">X_train_scaled</code><code class="p">,</code> <code class="n">y_train</code><code class="p">)</code>
        <code class="k">with</code> <code class="n">tf</code><code class="o">.</code><code class="n">GradientTape</code><code class="p">()</code> <code class="k">as</code> <code class="n">tape</code><code class="p">:</code>
            <code class="n">y_pred</code> <code class="o">=</code> <code class="n">model</code><code class="p">(</code><code class="n">X_batch</code><code class="p">,</code> <code class="n">training</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>
            <code class="n">main_loss</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">reduce_mean</code><code class="p">(</code><code class="n">loss_fn</code><code class="p">(</code><code class="n">y_batch</code><code class="p">,</code> <code class="n">y_pred</code><code class="p">))</code>
            <code class="n">loss</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">add_n</code><code class="p">([</code><code class="n">main_loss</code><code class="p">]</code> <code class="o">+</code> <code class="n">model</code><code class="o">.</code><code class="n">losses</code><code class="p">)</code>
        <code class="n">gradients</code> <code class="o">=</code> <code class="n">tape</code><code class="o">.</code><code class="n">gradient</code><code class="p">(</code><code class="n">loss</code><code class="p">,</code> <code class="n">model</code><code class="o">.</code><code class="n">trainable_variables</code><code class="p">)</code>
        <code class="n">optimizer</code><code class="o">.</code><code class="n">apply_gradients</code><code class="p">(</code><code class="nb">zip</code><code class="p">(</code><code class="n">gradients</code><code class="p">,</code> <code class="n">model</code><code class="o">.</code><code class="n">trainable_variables</code><code class="p">))</code>
        <code class="n">mean_loss</code><code class="p">(</code><code class="n">loss</code><code class="p">)</code>
        <code class="k">for</code> <code class="n">metric</code> <code class="ow">in</code> <code class="n">metrics</code><code class="p">:</code>
            <code class="n">metric</code><code class="p">(</code><code class="n">y_batch</code><code class="p">,</code> <code class="n">y_pred</code><code class="p">)</code>
        <code class="n">print_status_bar</code><code class="p">(</code><code class="n">step</code> <code class="o">*</code> <code class="n">batch_size</code><code class="p">,</code> <code class="nb">len</code><code class="p">(</code><code class="n">y_train</code><code class="p">),</code> <code class="n">mean_loss</code><code class="p">,</code> <code class="n">metrics</code><code class="p">)</code>
    <code class="n">print_status_bar</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">y_train</code><code class="p">),</code> <code class="nb">len</code><code class="p">(</code><code class="n">y_train</code><code class="p">),</code> <code class="n">mean_loss</code><code class="p">,</code> <code class="n">metrics</code><code class="p">)</code>
    <code class="k">for</code> <code class="n">metric</code> <code class="ow">in</code> <code class="p">[</code><code class="n">mean_loss</code><code class="p">]</code> <code class="o">+</code> <code class="n">metrics</code><code class="p">:</code>
        <code class="n">metric</code><code class="o">.</code><code class="n">reset_states</code><code class="p">()</code></pre>

<p>There’s a lot going on in this code, so let’s walk through it:</p>

<ul>
<li>
<p>We create two nested loops: one for the epochs, the other for the batches within an epoch.</p>
</li>
<li>
<p>Then we sample a random batch from the training set.</p>
</li>
<li>
<p>Inside the <code>tf.GradientTape()</code> block, we make a prediction for one batch (using the model as a function), and we compute the loss: it is equal to the main loss plus the other losses (in this model, there is one regularization loss per layer). Since the <code>mean_squared_error()</code> function returns one loss per instance, we compute the mean over the batch using <code>tf.reduce_mean()</code> (if you wanted to apply different weights to each instance, this is where you would do it). The regularization losses are already reduced to a single scalar each, so we just need to sum them (using <code>tf.add_n()</code>, which sums multiple tensors of the same shape and data type).</p>
</li>
<li>
<p>Next, we ask the <code>tape</code> to compute the gradient of the loss with regard to each trainable variable (<em>not</em> all variables!), and we apply them to the optimizer to perform a Gradient Descent step.</p>
</li>
<li>
<p>Next we update the mean loss and the metrics (over the current epoch), and we display the status bar.</p>
</li>
<li>
<p>At the end of each epoch, we display the status bar again to make it look complete<sup><a data-type="noteref" id="idm46263504829560-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#idm46263504829560">13</a></sup> and to print a line feed, and we reset the states of the mean loss and the metrics.</p>
</li>
</ul>

<p>If you set the optimizer’s <code>clipnorm</code> or <code>clipvalue</code> hyperparameters, it will take care of this for you. If you want to apply any other transformation to the gradients, simply do so before calling the <code>apply_gradients()</code> method.</p>

<p>If you add weight constraints to your model (e.g., by setting <code>kernel_constraint</code> or <code>bias_constraint</code> when creating a layer), you should update the training loop to apply these constraints just after <code>apply_gradients()</code>:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">for</code> <code class="n">variable</code> <code class="ow">in</code> <code class="n">model</code><code class="o">.</code><code class="n">variables</code><code class="p">:</code>
    <code class="k">if</code> <code class="n">variable</code><code class="o">.</code><code class="n">constraint</code> <code class="ow">is</code> <code class="ow">not</code> <code class="bp">None</code><code class="p">:</code>
        <code class="n">variable</code><code class="o">.</code><code class="n">assign</code><code class="p">(</code><code class="n">variable</code><code class="o">.</code><code class="n">constraint</code><code class="p">(</code><code class="n">variable</code><code class="p">))</code></pre>

<p>Most importantly, this training loop does not handle layers that behave differently during training and testing (e.g., <code>BatchNormalization</code> or <code>Dropout</code>). To handle these, you need to call the model with <code>training=True</code> and make sure it propagates this to every layer that needs it.</p>

<p>As you can see, there are quite a lot of things you need to get right, and it’s easy to make a mistake. But on the bright side, you get full control, so it’s your call.</p>

<p>Now that you know how to customize any part of your models<sup><a data-type="noteref" id="idm46263504799032-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#idm46263504799032">14</a></sup> and training algorithms, let’s see how you can use TensorFlow’s automatic graph generation feature: it can speed up your custom code considerably, and it will also make it portable to any platform supported by TensorFlow (see <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch19.html#deployment_chapter">Chapter&nbsp;19</a>).</p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="TensorFlow Functions and Graphs"><div class="sect1" id="idm46263508959688">
<h1>TensorFlow Functions and Graphs</h1>

<p>In TensorFlow&nbsp;1, graphs were unavoidable (as were the complexities that came with them) because they were a central part of TensorFlow’s API. In TensorFlow&nbsp;2, they are still there, but not as central, and they’re much (much!) simpler to use. To show just how simple, let’s start with a trivial function that computes the cube of its input:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">cube</code><code class="p">(</code><code class="n">x</code><code class="p">):</code>
    <code class="k">return</code> <code class="n">x</code> <code class="o">**</code> <code class="mi">3</code></pre>

<p>We can obviously call this function with a Python value, such as an int or a float, or we can call it with a tensor:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">cube</code><code class="p">(</code><code class="mi">2</code><code class="p">)</code>
<code class="go">8</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">cube</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">constant</code><code class="p">(</code><code class="mf">2.0</code><code class="p">))</code>
<code class="go">&lt;tf.Tensor: id=18634148, shape=(), dtype=float32, numpy=8.0&gt;</code></pre>

<p>Now, let’s use <code>tf.function()</code> to convert this Python function to a <em>TensorFlow Function</em>:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">tf_cube</code> <code class="o">=</code> <code class="n">tf</code><code class="o">.</code><code class="n">function</code><code class="p">(</code><code class="n">cube</code><code class="p">)</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">tf_cube</code>
<code class="go">&lt;tensorflow.python.eager.def_function.Function at 0x1546fc080&gt;</code></pre>

<p>This TF Function can then be used exactly like the original Python function, and it will return the same result (but as tensors):</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">tf_cube</code><code class="p">(</code><code class="mi">2</code><code class="p">)</code>
<code class="go">&lt;tf.Tensor: id=18634201, shape=(), dtype=int32, numpy=8&gt;</code>
<code class="gp">&gt;&gt;&gt; </code><code class="n">tf_cube</code><code class="p">(</code><code class="n">tf</code><code class="o">.</code><code class="n">constant</code><code class="p">(</code><code class="mf">2.0</code><code class="p">))</code>
<code class="go">&lt;tf.Tensor: id=18634211, shape=(), dtype=float32, numpy=8.0&gt;</code></pre>

<p>Under the hood, <code>tf.function()</code> analyzed the computations performed by the <code>cube()</code> function and generated an equivalent computation graph! As you can see, it was rather painless (we will see how this works shortly). Alternatively, we could have used <code>tf.function</code> as a decorator; this is actually more common:</p>

<pre data-type="programlisting" data-code-language="python"><code class="nd">@tf.function</code>
<code class="k">def</code> <code class="nf">tf_cube</code><code class="p">(</code><code class="n">x</code><code class="p">):</code>
    <code class="k">return</code> <code class="n">x</code> <code class="o">**</code> <code class="mi">3</code></pre>

<p>The original Python function is still available via the TF Function’s <code>python_function</code> attribute, in case you ever need it:</p>

<pre data-type="programlisting" data-code-language="pycon"><code class="gp">&gt;&gt;&gt; </code><code class="n">tf_cube</code><code class="o">.</code><code class="n">python_function</code><code class="p">(</code><code class="mi">2</code><code class="p">)</code>
<code class="go">8</code></pre>

<p>TensorFlow optimizes the computation graph, pruning unused nodes, simplifying expressions (e.g., 1 + 2 would get replaced with 3), and more. Once the optimized graph is ready, the TF Function efficiently executes the operations in the graph, in the appropriate order (and in parallel when it can). As a result, a TF Function will usually run much faster than the original Python function, especially if it performs complex computations.<sup><a data-type="noteref" id="idm46263504604728-marker" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#idm46263504604728">15</a></sup> Most of the time you will not really need to know more than that: when you want to boost a Python function, just transform it into a TF Function. That’s all!</p>

<p>Moreover, when you write a custom loss function, a custom metric, a custom layer, or any other custom function and you use it in a Keras model (as we did throughout this chapter), Keras automatically converts your function into a TF Function—no need to use <code>tf.function()</code>. So most of the time, all this magic is 100% transparent.</p>
<div data-type="tip"><h6>Tip</h6>
<p>You can tell Keras <em>not</em> to convert your Python functions to TF Functions by setting <code>dynamic=True</code> when creating a custom layer or a custom model. Alternatively, you can set <code>run_eagerly=True</code> when calling the model’s <code>compile()</code> method.</p>
</div>

<p>By default, TF Function generates a new graph for every unique set of input shapes and data types, and it caches it for subsequent calls. For example, if you call <code>tf_cube(tf.constant(10))</code>, a graph will be generated for int32 tensors of shape []. Then if you call <code>tf_cube(tf.constant(20))</code>, the same graph will be reused. But if you then call <code>tf_cube(tf.constant([10, 20]))</code>, a new graph will be generated for int32 tensors of shape [2]. This is how TF Functions handle polymorphism (i.e., varying argument types and shapes). However, this is only true for tensor arguments: if you pass numerical Python values to a TF Function, a new graph will be generated for every distinct value: for example, calling <code>tf_cube(10)</code> and <code>tf_cube(20)</code> will generate two graphs.</p>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>If you call a TF Function many times with different numerical Python values, then many graphs will be generated, slowing down your program and using up a lot of RAM (you must delete the TF Function to release it). Python values should be reserved for arguments that will have few unique values, such as hyperparameters like the number of neurons per layer. This allows TensorFlow to better optimize each variant of your model.</p>
</div>








<section data-type="sect2" data-pdf-bookmark="Autograph and Tracing"><div class="sect2" id="idm46263504543096">
<h2>Autograph and Tracing</h2>

<p>So, how does TensorFlow generate graphs? Well, first it starts by analyzing the Python function’s source code to capture all the control flow statements, such as <code>for</code> loops, <code>while</code> loops and <code>if</code> statements, as well as <code>break</code>, <code>continue</code>, and <code>return</code> statements. This first step is called <em>autograph</em>. The reason TensorFlow has to analyze the source code is that Python does not provide any other way to capture control flow statements: it offers magic methods like <code>__add__()</code> or <code>__mul__()</code> to capture operators like <code>+</code> and <code>*</code>, but there are no <code>__while__()</code> or <code>__if__()</code> magic methods. After analyzing the function’s code, autograph outputs an upgraded version of that function in which all the control flow statements are replaced by the appropriate TensorFlow operations, such as <code>tf.while_loop()</code> for loops and <code>tf.cond()</code> for <code>if</code> statements. For example, in <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#autograph_tracing_diagram">Figure&nbsp;12-4</a>, autograph analyzes the source code of the <code>sum_squares()</code> Python function, and it generates the <code>tf__sum_squares()</code> function. In this function, the <code>for</code> loop is replaced by the definition of the <code>loop_body()</code> function (containing the body of the original <code>for</code> loop), followed by a call to the <code>for_stmt()</code> function. This call will build the appropriate <code>tf.while_loop()</code> operation in the computation graph.</p>

<figure><div id="autograph_tracing_diagram" class="figure">
<img src="./Chapter12_files/mls2_1204.png" alt="mls2 1204" width="1440" height="773" data-mfp-src="/library/view/hands-on-machine-learning/9781492032632/assets/mls2_1204.png">
<h6><span class="label">Figure 12-4. </span>How TensorFlow generates graphs using autograph and tracing</h6>
</div></figure>

<p>Next, TensorFlow calls this “upgraded” function, but instead of passing the argument, it passes a <em>symbolic tensor</em>, a tensor without any actual value, only a name, a data type, and a shape. For example, if you call <code>sum_squares(tf.constant(10))</code>, then the <code>tf__sum_squares()</code> function will be called with a symbolic tensor of type int32 and shape []. The function will run in <em>graph mode</em>, meaning that each TensorFlow operation will add a node in the graph to represent itself and its output tensor(s) (as opposed to the regular mode, called <em>eager execution</em>, or <em>eager mode</em>). In graph mode, TF operations do not perform any computations. This should feel familiar if you know TensorFlow&nbsp;1, as graph mode was the default mode. In <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#autograph_tracing_diagram">Figure&nbsp;12-4</a>, you can see the <code>tf__sum_squares()</code> function being called with a symbolic tensor as argument (in this case, an int32 tensor of shape []) and the final graph being generated during tracing. The nodes represent operations, and the arrows represent tensors (both the generated function and the graph are simplified).</p>
<div data-type="tip"><h6>Tip</h6>
<p>To view the generated function’s source code, you can call <code>tf.autograph.to_code(sum_squares.python_function)</code>. The code is not meant to be pretty, but it can sometimes help for debugging.</p>
</div>
</div></section>













<section data-type="sect2" data-pdf-bookmark="TF Function Rules"><div class="sect2" id="idm46263504504696">
<h2>TF Function Rules</h2>

<p>Most of the time, converting a Python function that performs TensorFlow operations into a TF Function is trivial: decorate it with <code>@tf.function</code> or let Keras take care of it for you. However, there are a few rules to respect:</p>

<ul>
<li>
<p>If you call any external library, including NumPy or even the standard library, this call will run only during tracing; it will not be part of the graph. Indeed, a TensorFlow graph can only include TensorFlow constructs (tensors, operations, variables, datasets, and so on). So make sure you use <code>tf.reduce_sum()</code> instead of <code>np.sum()</code>, and <code>tf.sort()</code> instead of the built-in <code>sorted()</code> function, and so on (unless you really want the code to run only during tracing).</p>

<ul>
<li>
<p>For example, if you define a TF function <code>f(x)</code> that just returns <code>np.random.rand()</code>, a random number will only be generated when the function is traced, so <code>f(tf.constant(2.))</code> and <code>f(tf.constant(3.))</code> will return the same random number, but <code>f(tf.constant([2., 3.]))</code> will return a different one. If you replace <code>np.random.rand()</code> with <code>tf.random.uniform([])</code>, then a new random number will be generated upon every call, since the operation will be part of the graph.</p>
</li>
<li>
<p>If your non-TensorFlow code has side-effects (such as logging something or updating a Python counter), then you should not expect those side effects to occur every time you call the TF Function, as they will only occur when the function is traced.</p>
</li>
<li>
<p>You can wrap arbitrary Python code in a <code>tf.py_function()</code> operation, but doing so will hinder performance, as TensorFlow will not be able to do any graph optimization on this code, and it will also reduce portability, as the graph will only run on platforms where Python is available (and where the right libraries are installed).</p>
</li>
</ul>
</li>
<li>
<p>You can call other Python functions or TF Functions, but they should follow the same rules, as TensorFlow will capture their operations in the computation graph. Note that these other functions do not need to be decorated with <code>@tf.function</code>.</p>
</li>
<li>
<p>If the function creates a TensorFlow variable (or any other stateful TensorFlow object, such as a dataset or a queue), it must do so upon the very first call, and only then, or else you will get an exception. It is usually preferable to create variables outside of the TF Function (e.g., in the <code>build()</code> method of a custom layer). If you want to assign a new value to the variable, make sure you call its <code>assign()</code> method, instead of using the <code>=</code> operator.</p>
</li>
<li>
<p>The source code of your Python function should be available to TensorFlow. If the source code is unavailable (for example, if you define your function in the Python shell, which does not give access to the source code, or if you deploy only the compiled Python files <code>*.pyc</code> to production), then the graph generation process will fail or have limited functionality.</p>
</li>
<li>
<p>TensorFlow will only capture <code>for</code> loops that iterate over a tensor or a <code>Dataset</code>. So make sure you use <code>for i in tf.range(10)</code> rather than <code>for i in range(10)</code>, or else the loop will not be captured in the graph. Instead, it will run during tracing. This may be what you want, if the <code>for</code> loop is meant to build the graph, for example to create each layer in a neural network.</p>
</li>
<li>
<p>And as always, for performance reasons, you should prefer a vectorized implementation whenever you can, rather than using loops.</p>
</li>
</ul>

<p>It’s time to sum up! In this chapter we started with a brief overview of TensorFlow, then we looked at TensorFlow’s low-level API, including tensors, operations, variables, and special data structures. We then used these tools to customize almost every component in tf.keras. Finally, we looked at how TF Functions can boost performance, how graphs are generated using autograph and tracing, and what rules to follow when you write TF Functions (if you would like to open the black box a bit further, for example to explore the generated graphs, you will find technical details in <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/app07.html#tffunctions_appendix">Appendix&nbsp;G</a>).</p>

<p>In the next chapter, we will look at how to efficiently load and preprocess data with TensorFlow.</p>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Exercises"><div class="sect1" id="idm46263504796264">
<h1>Exercises</h1>
<ol>
<li>
<p>How would you describe TensorFlow in a short sentence? What are its main features? Can you name other popular Deep Learning libraries?</p>
</li>
<li>
<p>Is TensorFlow a drop-in replacement for NumPy? What are the main differences between the two?</p>
</li>
<li>
<p>Do you get the same result with <code>tf.range(10)</code> and with <code>tf.constant(np.arange(10))</code>?</p>
</li>
<li>
<p>Can you name six other data structures available in TensorFlow, beyond regular tensors?</p>
</li>
<li>
<p>A custom loss function can be defined by writing a function or by subclassing the <code>keras.losses.Loss</code> class. When would you use each option?</p>
</li>
<li>
<p>Similarly, a custom metric can be defined in a function or a subclass of <code>keras.metrics.Metric</code>. When would you use each option?</p>
</li>
<li>
<p>When should you create a custom layer vs a custom model?</p>
</li>
<li>
<p>What are some use cases that require writing your own custom training loop?</p>
</li>
<li>
<p>Can custom Keras components contain arbitrary Python code, or must they be convertible to TF Functions?</p>
</li>
<li>
<p>What are the main rules to respect if you want a function to be convertible to a TF Function?</p>
</li>
<li>
<p>When would you need to create a dynamic Keras model? How do you do that? Why not make all your models dynamic?</p>
</li>
<li>
<p>Implement a custom layer that performs <em>Layer Normalization</em> (we will use this type of layer in <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch15.html#rnn_chapter">Chapter&nbsp;15</a>):</p>
<ol>
<li>
<p>The build() method should define two trainable weights <strong>α</strong> and <strong>β</strong>, both of shape <code>input_shape[-1:]</code> and data type <code>tf.float32</code>. <strong>α</strong> should be initialized with 1s, and <strong>β</strong> with 0s.</p>
</li>
<li>
<p>The <code>call()</code> method should compute the mean <em>μ</em> and standard deviation <em>σ</em> of each instance’s features. For this, you can use <code>tf.nn.moments(inputs, axes=-1, keepdims=True)</code>, which returns the mean <em>μ</em> and the variance <em>σ</em><sup>2</sup> of all instances (compute the square root of the variance to get the standard deviation). Then the function should compute and return <strong>α</strong>⊗(<strong>X</strong> - <em>μ</em>)/(<em>σ</em> + <em>ε</em>) + <strong>β</strong>, where ⊗ represents itemwise multiplication (<code>*</code>) and <em>ε</em> is a smoothing term (small constant to avoid division by zero, e.g., 0.001).</p>
</li>
<li>
<p>Ensure that your custom layer produces the same output as the <code>keras.layers.LayerNormalization</code> layer (or very close).</p>
</li>

</ol>
</li>
<li>
<p>Train a model using a custom training loop to tackle the Fashion MNIST dataset (see <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch10.html#ann_chapter">Chapter&nbsp;10</a>).</p>
<ol>
<li>
<p>Display the epoch, iteration, mean training loss, and mean accuracy over each epoch (updated at each iteration), as well as the validation loss and accuracy at the end of each epoch.</p>
</li>
<li>
<p>Try using a different optimizer with a different learning rate for the upper layers and the lower layers.</p>
</li>

</ol>
</li>

</ol>

<p>Solutions to these exercises are available in <a data-type="xref" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/app01.html#solutions_appendix">Appendix&nbsp;A</a>.</p>
</div></section>







<div data-type="footnotes"><p data-type="footnote" id="idm46263509690504"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#idm46263509690504-marker" class="totri-footnote">1</a></sup> TensorFlow includes another Deep Learning API called the <em>Estimators API</em>, but the TensorFlow team recommends using tf.keras instead.</p><p data-type="footnote" id="idm46263509684072"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#idm46263509684072-marker" class="totri-footnote">2</a></sup> If you ever need to (but you probably won’t), you can write your own operations using the C++ API.</p><p data-type="footnote" id="idm46263509681576"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#idm46263509681576-marker" class="totri-footnote">3</a></sup> To learn more about TPUs and how they work, check out <a href="https://homl.info/tpus"><em class="hyperlink">https://homl.info/tpus</em></a>.</p><p data-type="footnote" id="idm46263509408760"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#idm46263509408760-marker" class="totri-footnote">4</a></sup> A notable exception is <code>tf.math.log()</code>, which is commonly used but doesn’t have a <code>tf.log()</code> alias (as it might be confused with logging).</p><p data-type="footnote" id="idm46263508450888"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#idm46263508450888-marker" class="totri-footnote">5</a></sup> It would not be a good idea to use a weighted mean: if we did, then two instances with the same weight but in different batches would have a different impact on training, depending on the total weight of each batch.</p><p data-type="footnote" id="idm46263507789496"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#idm46263507789496-marker" class="totri-footnote">6</a></sup> However, the Huber loss is seldom used as a metric (the MAE or MSE are preferred).</p><p data-type="footnote" id="idm46263507600632"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#idm46263507600632-marker" class="totri-footnote">7</a></sup> This class is for illustration purposes only. A simpler and better implementation would just subclass the <code>keras.metrics.Mean</code> class see the notebook for an example.</p><p data-type="footnote" id="idm46263507058568"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#idm46263507058568-marker" class="totri-footnote">8</a></sup> This function is specific to tf.keras. You could use <code>keras.activations.Activation</code> instead.</p><p data-type="footnote" id="idm46263507054968"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#idm46263507054968-marker" class="totri-footnote">9</a></sup> The Keras API calls this argument <code>input_shape</code>, but since it also includes the batch dimension, I prefer to call it <code>batch_input_shape</code>. Same for <code>compute_output_shape()</code>.</p><p data-type="footnote" id="idm46263506780328"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#idm46263506780328-marker">10</a></sup> The name “Subclassing API” usually refers only to the creation of custom models by subclassing, although many other things can be created by subclassing, as we saw in this chapter.</p><p data-type="footnote" id="idm46263506242968"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#idm46263506242968-marker">11</a></sup> You can also call <code>add_loss()</code> on any layer inside the model, as the model recursively gathers losses from all of its layers.</p><p data-type="footnote" id="idm46263505885384"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#idm46263505885384-marker">12</a></sup> If the tape goes out of scope, for example when the function that used it returns, Python’s garbage collector will delete it for you.</p><p data-type="footnote" id="idm46263504829560"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#idm46263504829560-marker">13</a></sup> The truth is we did not process every single instance in the training set because we sampled instances randomly, so some were processed more than once, while others were not processed at all. In practice that’s fine. Moreover, if the training set size is not a multiple of the batch size, we will miss a few instances.</p><p data-type="footnote" id="idm46263504799032"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#idm46263504799032-marker">14</a></sup> With the exception of optimizers, as very few people ever customize these; see the notebook for an example.</p><p data-type="footnote" id="idm46263504604728"><sup><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#idm46263504604728-marker">15</a></sup> However, in this trivial example, the computation graph is so small that there is nothing at all to optimize, so <code>tf_cube()</code> actually runs much slower than <code>cube()</code>.</p></div></div></section><div class="annotator-outer annotator-viewer viewer annotator-hide">
  <ul class="annotator-widget annotator-listing"></ul>
</div><div class="annotator-modal-wrapper annotator-editor-modal annotator-editor annotator-hide">
	<div class="annotator-outer editor">
		<h2 class="title">Highlight</h2>
		<form class="annotator-widget">
			<ul class="annotator-listing">
			<li class="annotator-item"><textarea id="annotator-field-13" placeholder="Add a note using markdown (optional)" class="js-editor" maxlength="750"></textarea></li></ul>
			<div class="annotator-controls">
				<a class="link-to-markdown" href="https://daringfireball.net/projects/markdown/basics" target="_blank">?</a>
				<ul>
					<li class="delete annotator-hide"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#delete" class="annotator-delete-note button positive">Delete Note</a></li>
					<li class="save"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#save" class="annotator-save annotator-focus button positive">Save Note</a></li>
					<li class="cancel"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#cancel" class="annotator-cancel button">Cancel</a></li>
				</ul>
			</div>
		</form>
	</div>
</div><div class="annotator-modal-wrapper annotator-delete-confirm-modal" style="display: none;">
  <div class="annotator-outer">
    <h2 class="title">Highlight</h2>
      <a class="js-close-delete-confirm annotator-cancel close" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#close">Close</a>
      <div class="annotator-widget">
         <div class="delete-confirm">
            Are you sure you want to permanently delete this note?
         </div>
         <div class="annotator-controls">
            <a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#cancel" class="annotator-cancel button js-cancel-delete-confirm">No, I changed my mind</a>
            <a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#delete" class="annotator-delete button positive js-delete-confirm">Yes, delete it</a>
         </div>
       </div>
   </div>
</div><div class="annotator-adder" style="display: none;">
	<ul class="adders">
		
		<li class="copy"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#">Copy</a></li>
		
		<li class="add-highlight"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#">Add Highlight</a></li>
		<li class="add-note"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#">
			Add Note
		</a></li>
		
	</ul>
</div></div></div>



  <div class="t-sbo-prev sbo-prev sbo-nav-bottom">
  
    
      
        <a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch11.html" class="prev nav-link">
      
          <span aria-hidden="true" class="pagination-label t-prev-label">Prev</span>
          <span class="visuallyhidden">Previous Chapter</span>
          <div class="pagination-title t-prev-title">11. Training Deep Neural Networks</div>
        </a>
    
  
  </div>

  <div class="t-sbo-next sbo-next sbo-nav-bottom">
  
    
      
        <a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch13.html" class="next nav-link">
      
          <span aria-hidden="true" class="pagination-label t-next-label">Next</span>
          <span class="visuallyhidden">Next Chapter</span>
          <div class="pagination-title t-next-title">13. Loading and Preprocessing Data with TensorFlow</div>
        </a>
    
  
  </div>

</section>
  </div>
<section class="sbo-saved-archives"></section>



          
          
  




    
    



        
      </div>
      



  <footer class="pagefoot">
    <a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#" class="icon-up" style="display: none;"><div class="visuallyhidden">Back to top</div></a>
    <ul class="js-footer-nav">
      <li class="full-support"><a href="https://www.oreilly.com/online-learning/support/">Support</a></li>
      <li><a href="https://www.oreilly.com/online-learning/apps.html">Get the App</a></li>
      
        <li><a href="https://learning.oreilly.com/accounts/logout/">Sign Out</a></li>
      
    </ul>
    <span class="copyright">© 2019 <a href="https://learning.oreilly.com/" target="_blank">Safari</a>.</span>
    <a href="https://learning.oreilly.com/terms/">Terms of Service</a> /
    <a href="https://learning.oreilly.com/membership-agreement/">Membership Agreement</a> /
    <a href="https://www.oreilly.com/privacy.html">Privacy Policy</a>
  </footer>

<script type="text/javascript">window.NREUM||(NREUM={});NREUM.info={"applicationID":"172641827,79672898,93931619","errorBeacon":"bam.nr-data.net","agent":"","applicationTime":451,"licenseKey":"510f1a6865","transactionName":"YgdaZ0NSW0cEB0RdWltNfkZfUEFdCgofXFBHDVYdR1pQQxZeRl1QQj1aWkU=","beacon":"bam.nr-data.net","queueTime":4}</script>


    
    <script src="./Chapter12_files/saved_resource" charset="utf-8"></script><script type="text/javascript" id="">!function(b,e,f,g,a,c,d){b.fbq||(a=b.fbq=function(){a.callMethod?a.callMethod.apply(a,arguments):a.queue.push(arguments)},b._fbq||(b._fbq=a),a.push=a,a.loaded=!0,a.version="2.0",a.queue=[],c=e.createElement(f),c.async=!0,c.src=g,d=e.getElementsByTagName(f)[0],d.parentNode.insertBefore(c,d))}(window,document,"script","https://connect.facebook.net/en_US/fbevents.js");fbq("init","1732687426968531");fbq("track","PageView");</script>
<noscript><img height="1" width="1" style="display:none" src="https://www.facebook.com/tr?id=1732687426968531&amp;ev=PageView&amp;noscript=1"></noscript><script type="text/javascript" id="">(function(){window.medalliaUserIdentifier=document.documentElement.dataset.userUuid;window.medalliaUserName=document.documentElement.dataset.username})();</script>
<script type="text/javascript" id="" src="./Chapter12_files/embed.js.download"></script><script type="text/javascript" id="">adroll_adv_id="BOHFZPCX5ZAM5LXWJURNUB";adroll_pix_id="3QFV44ZHVZG53BOB75QP3D";
(function(){var a=function(){if(document.readyState&&!/loaded|complete/.test(document.readyState))setTimeout(a,10);else if(window.__adroll_loaded){var b=document.createElement("script"),c="https:"==document.location.protocol?"https://s.adroll.com":"http://a.adroll.com";b.setAttribute("async","true");b.type="text/javascript";b.src=c+"/j/roundtrip.js";((document.getElementsByTagName("head")||[null])[0]||document.getElementsByTagName("script")[0].parentNode).appendChild(b)}else __adroll_loaded=!0,setTimeout(a,
50)};window.addEventListener?window.addEventListener("load",a,!1):window.attachEvent("onload",a)})();</script><script type="text/javascript" id="">adroll_adv_id="BOHFZPCX5ZAM5LXWJURNUB";adroll_pix_id="3QFV44ZHVZG53BOB75QP3D";
(function(){var a=function(){if(document.readyState&&!/loaded|complete/.test(document.readyState))setTimeout(a,10);else if(window.__adroll_loaded){var b=document.createElement("script"),c="https:"==document.location.protocol?"https://s.adroll.com":"http://a.adroll.com";b.setAttribute("async","true");b.type="text/javascript";b.src=c+"/j/roundtrip.js";((document.getElementsByTagName("head")||[null])[0]||document.getElementsByTagName("script")[0].parentNode).appendChild(b)}else __adroll_loaded=!0,setTimeout(a,
50)};window.addEventListener?window.addEventListener("load",a,!1):window.attachEvent("onload",a)})();</script>
<script type="text/javascript" id="">!function(b,e,f,g,a,c,d){b.fbq||(a=b.fbq=function(){a.callMethod?a.callMethod.apply(a,arguments):a.queue.push(arguments)},b._fbq||(b._fbq=a),a.push=a,a.loaded=!0,a.version="2.0",a.queue=[],c=e.createElement(f),c.async=!0,c.src=g,d=e.getElementsByTagName(f)[0],d.parentNode.insertBefore(c,d))}(window,document,"script","https://connect.facebook.net/en_US/fbevents.js");fbq("init","443792972845831");fbq("set","agent","tmgoogletagmanager","443792972845831");fbq("track","PageView");</script>
<noscript><img height="1" width="1" style="display:none" src="https://www.facebook.com/tr?id=443792972845831&amp;ev=PageView&amp;noscript=1"></noscript>

<script type="text/javascript" id="">!function(b,e,f,g,a,c,d){b.fbq||(a=b.fbq=function(){a.callMethod?a.callMethod.apply(a,arguments):a.queue.push(arguments)},b._fbq||(b._fbq=a),a.push=a,a.loaded=!0,a.version="2.0",a.queue=[],c=e.createElement(f),c.async=!0,c.src=g,d=e.getElementsByTagName(f)[0],d.parentNode.insertBefore(c,d))}(window,document,"script","https://connect.facebook.net/en_US/fbevents.js");fbq("init","443792972845831");fbq("track","PageView");</script>
<noscript><img height="1" width="1" style="display:none" src="https://www.facebook.com/tr?id=443792972845831&amp;ev=PageView&amp;noscript=1"></noscript>
<div style="width:0px; height:0px; display:none; visibility:hidden;" id="batBeacon0.09556792590964802"><img style="width:0px; height:0px; display:none; visibility:hidden;" id="batBeacon0.5229133033930915" width="0" height="0" alt="" src="./Chapter12_files/0"></div>
    <script src="./Chapter12_files/saved_resource(1)" charset="utf-8"></script>
  

<script src="./Chapter12_files/saved_resource(2)" type="text/javascript"></script><script type="text/javascript" id="">window._pp=window._pp||[];if("\/library\/view\/hands-on-machine-learning\/9781492032632\/part01.html"=="/confirmation/nnv/"&&"https:\/\/learning.oreilly.com\/library\/view\/hands-on-machine-learning\/9781492032632\/"=="https://learning.oreilly.com/register/")_pp.targetUrl="/confirm/trial";else if("\/library\/view\/hands-on-machine-learning\/9781492032632\/part01.html"=="/confirmation/nv/"&&"https:\/\/learning.oreilly.com\/library\/view\/hands-on-machine-learning\/9781492032632\/"=="https://learning.oreilly.com/subscribe/")_pp.targetUrl="/confirm/paid";else if("\/library\/view\/hands-on-machine-learning\/9781492032632\/part01.html"=="/confirmation/nnv/"&&"https:\/\/learning.oreilly.com\/library\/view\/hands-on-machine-learning\/9781492032632\/"=="https://learning.oreilly.com/signup/")_pp.targetUrl="/confirm/paid";_pp.siteId="2508";
_pp.siteUId="d59baa21-c0cd-4fcf-9c68-a2b8d4f52a79";_pp.orderValue="undefined";_pp.orderId="undefined";(function(){var ppjs=document.createElement("script");ppjs.type="text/javascript";ppjs.async=true;ppjs.src=("https:"==document.location.protocol?"https:":"http:")+"//cdn.pbbl.co/r/"+_pp.siteId+".js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(ppjs,s)})();</script><div class="annotator-notice"></div><div class="font-flyout" style="top: 201px; left: 1194px;"><div class="font-controls-panel">
	<div class="nightmodes">
		<ul>
			<li class="day"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#" id="day-mode" title="Day Mode">
				<i class="fa fa-sun-o"></i>
				<span>Day Mode</span></a></li>
			<li class="cloudy"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#" id="cloudy-mode" title="Cloudy Mode">
				<i class="fa fa-cloud"></i>
				<span>Cloud Mode</span>
			</a></li>
			<li class="night"><a href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#" id="night-mode" title="Night Mode">
				<i class="fa fa-moon-o"></i>
				<span>Night Mode</span>
			</a></li>
		</ul>
	</div>

	<div class="font-resizer resizer">
		<div class="draggable-containment-wrapper">
			<i class="fa fa-font left"></i>
			<span class="filler" style="width: 50%;"></span>
			<div id="js-font-size-draggable" class="draggable ui-widget-content ui-draggable ui-draggable-handle" style="position: relative; left: 80px;"></div>
			<i class="fa fa-font right"></i>
		</div>
	</div>

	<div class="column-resizer resizer">
		<div class="draggable-containment-wrapper">
			<i class="fa fa-compress left"></i>
			<span class="filler" style="width: 50%;"></span>
			<div id="js-column-size-draggable" class="draggable ui-widget-content ui-draggable ui-draggable-handle" style="position: relative; left: 80px;"></div>
			<i class="fa fa-expand right"></i>
		</div>
	</div>

	<a id="reset" class="button" href="https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch12.html#">Reset</a>
</div>
</div><script type="text/javascript" async="" src="./Chapter12_files/generic1566415868241.js.download" charset="UTF-8"></script><div style="display: none; visibility: hidden;"><script>(function(){if(null!==document.querySelector('iframe[title\x3d"fb:share_button Facebook Social Plugin"]')&&void 0!==document.querySelector('iframe[title\x3d"fb:share_button Facebook Social Plugin"]')){var a=!1;window.addEventListener("blur",function(){a&&dataLayer.push({event:"eventTracker",eventCat:"social",eventAct:"share",eventLbl:"facebook",eventVal:0,nonInteraction:0})});document.querySelector('iframe[title\x3d"fb:share_button Facebook Social Plugin"]').addEventListener("mouseover",function(){window.focus();
a=!0});document.querySelector('iframe[title\x3d"fb:share_button Facebook Social Plugin"]').addEventListener("mouseout",function(){a=!1})}try{window.twttr=function(b,a,d){var c,e=b.getElementsByTagName(a)[0];if(!b.getElementById(d))return b=b.createElement(a),b.id=d,b.src="//platform.twitter.com/widgets.js",e.parentNode.insertBefore(b,e),window.twttr||(c={_e:[],ready:function(a){c._e.push(a)}})}(document,"script","twitter-wjs"),twttr.ready(function(a){a.events.bind("tweet",trackTwitter)})}catch(b){}})();
null!==document.querySelector(".IN-widget")&&void 0!==document.querySelector(".IN-widget")&&document.querySelector(".IN-widget").addEventListener("click",function(){dataLayer.push({event:"eventTracker",eventCat:"social",eventAct:"share",eventLbl:"linkedin",eventVal:0,nonInteraction:0})});
function trackTwitter(a){a&&(a.target&&"IFRAME"==a.target.nodeName&&(opt_target=extractParamFromUri(a.target.src,"url")),dataLayer.push({event:"eventTracker",eventCat:"social",eventAct:"share",eventLbl:"twitter",eventVal:0,nonInteraction:0}))}function extractParamFromUri(a,b){if(a){var c=new RegExp("[\\?\x26#]"+b+"\x3d([^\x26#]*)");c=c.exec(a);if(null!=c)return unescape(c[1])}};</script></div><span><div id="KampyleAnimationContainer" style="z-index: 2147483000; border: 0px; position: fixed; display: block; width: 0px; height: 0px;"></div></span><iframe scrolling="no" frameborder="0" allowtransparency="true" src="./Chapter12_files/widget_iframe.097c1f5038f9e8a0d62a39a892838d66.html" title="Twitter settings iframe" style="display: none;"></iframe><div style="position: absolute; width: 0px; height: 0px; overflow: hidden; padding: 0px; border: 0px; margin: 0px;"><div id="MathJax_Font_Test" style="position: absolute; visibility: hidden; top: 0px; left: 0px; width: auto; padding: 0px; border: 0px; margin: 0px; white-space: nowrap; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; font-size: 40px; font-weight: normal; font-style: normal; font-family: MathJax_AMS, sans-serif;"></div></div></body></html>